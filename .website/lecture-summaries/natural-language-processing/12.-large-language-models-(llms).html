<!DOCTYPE html> <html lang="en"><head>
<title>12. Large Language Models (LLMs)</title>
<base href="../..">
<meta name="pathname" content="lecture-summaries/natural-language-processing/12.-large-language-models-(llms).html">
<meta name="description" content="vault - 12. Large Language Models (LLMs)">
<meta property="og:title" content="12. Large Language Models (LLMs)">
<meta property="og:description" content="vault - 12. Large Language Models (LLMs)">
<meta property="og:type" content="website">
<meta property="og:url" content="lecture-summaries/natural-language-processing/12.-large-language-models-(llms).html">
<meta property="og:image" content="undefined">
<meta charset="UTF-8"><meta property="og:site_name" content="vault"><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes, minimum-scale=1.0, maximum-scale=5.0"><link rel="alternate" type="application/rss+xml" title="RSS Feed" href="site-lib/rss.xml"><script async="" id="webpage-script" src="site-lib/scripts/webpage.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><script async="" id="graph-wasm-script" src="site-lib/scripts/graph-wasm.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><script async="" id="graph-render-worker-script" src="site-lib/scripts/graph-render-worker.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><link rel="icon" href="site-lib/media/favicon.png"><link rel="stylesheet" href="site-lib/styles/obsidian.css"><link rel="preload" href="site-lib/styles/global-variable-styles.css" as="style" onload="this.onload=null;this.rel='stylesheet'"><noscript><link rel="stylesheet" href="site-lib/styles/global-variable-styles.css"></noscript><link rel="preload" href="site-lib/styles/main-styles.css" as="style" onload="this.onload=null;this.rel='stylesheet'"><noscript><link rel="stylesheet" href="site-lib/styles/main-styles.css"></noscript><style>body{--line-width:40em;--line-width-adaptive:40em;--file-line-width:40em;--sidebar-width:min(20em, 80vw);--collapse-arrow-size:11px;--tree-vertical-spacing:1.3em;--sidebar-margin:12px}:root{background-color:#202124}.sidebar{height:100%;font-size:14px;z-index:10;min-width:calc(var(--sidebar-width) + var(--divider-width-hover));max-width:calc(var(--sidebar-width) + var(--divider-width-hover));position:relative;overflow:hidden;overflow:clip;transition:min-width ease-in-out,max-width ease-in-out;transition-duration:.2s;contain:size}#left-sidebar{left:0}#right-sidebar{right:0}.sidebar.is-collapsed{min-width:0;max-width:0}.sidebar.floating{position:absolute}.sidebar .leaf-content{height:100%;min-width:calc(var(--sidebar-width) - var(--divider-width-hover));top:0;padding:var(--sidebar-margin);padding-top:4em;line-height:var(--line-height-tight);background-color:var(--background-secondary);transition:background-color,border-right,border-left,box-shadow;transition-duration:var(--color-fade-speed);transition-timing-function:ease-in-out;position:absolute;display:flex;flex-direction:column}.sidebar:not(.is-collapsed) .leaf-content{min-width:calc(max(100%,var(--sidebar-width)) - 3px);max-width:calc(max(100%,var(--sidebar-width)) - 3px)}#left-sidebar-content{left:0;border-top-right-radius:var(--radius-l);border-bottom-right-radius:var(--radius-l)}#right-sidebar-content{right:0;border-top-left-radius:var(--radius-l);border-bottom-left-radius:var(--radius-l)}.sidebar #left-sidebar-content,.sidebar #right-sidebar-content{contain:none!important;container-type:normal!important;animation:none!important}.sidebar:has(.leaf-content:empty):has(.topbar-content:empty){display:none}.sidebar-topbar{height:calc(2.3em + 2 * var(--sidebar-margin));width:var(--sidebar-width);padding:var(--sidebar-margin);z-index:1;position:fixed;display:flex;align-items:center;transition:width ease-in-out;transition-duration:inherit}.sidebar.is-collapsed .sidebar-topbar{width:calc(2.3em + var(--sidebar-margin) * 2)}.sidebar .sidebar-topbar.is-collapsed{width:0}#left-sidebar .sidebar-topbar{left:0;flex-direction:row;border-top-right-radius:var(--radius-l)}#right-sidebar .sidebar-topbar{right:0;flex-direction:row-reverse;border-top-left-radius:var(--radius-l)}#left-sidebar .topbar-content{margin-right:calc(2.3em + var(--sidebar-margin));flex-direction:row}#right-sidebar .topbar-content{margin-left:calc(2.3em + var(--sidebar-margin));flex-direction:row-reverse}.topbar-content{overflow:hidden visible;overflow:clip visible;width:100%;height:100%;display:flex;align-items:center;transition:inherit}.sidebar.is-collapsed .topbar-content{width:0;transition:inherit}.clickable-icon.sidebar-collapse-icon{background-color:transparent;color:var(--icon-color-focused);padding:2px!important;margin:0!important;height:100%!important;width:2.3em!important;margin-inline:0.14em!important;position:absolute}#left-sidebar .clickable-icon.sidebar-collapse-icon{transform:rotateY(180deg);right:var(--sidebar-margin)}#right-sidebar .clickable-icon.sidebar-collapse-icon{transform:rotateY(180deg);left:var(--sidebar-margin)}.clickable-icon.sidebar-collapse-icon svg.svg-icon{width:100%;height:100%}.feature-title{margin-left:1px;text-transform:uppercase;letter-spacing:.06em;margin-top:.75em;margin-bottom:.75em}.feature-header{display:flex;align-items:center;padding-top:0;font-size:1em;padding-left:0}body.floating-sidebars .sidebar{position:absolute}body{transition:background-color var(--color-fade-speed) ease-in-out}#navbar:not(:empty){display:flex;align-items:center;justify-content:space-between;padding:.5em 1em;width:100%}#main{display:flex;flex-direction:column;height:100%;width:100%;align-items:stretch;justify-content:center}#main-horizontal{display:flex;flex-direction:row;flex-grow:1;width:100%;align-items:stretch;justify-content:center}#center-content{flex-basis:100%;max-width:100%;width:100%;height:100%;display:flex;flex-direction:column;align-items:center;transition:opacity .2s ease-in-out;contain:inline-size}.hide{opacity:0!important;transition:opacity .2s ease-in-out;pointer-events:none}#center-content>.obsidian-document{padding-left:2em;padding-right:1em;margin-bottom:0;width:100%;width:-webkit-fill-available;width:-moz-available;width:fill-available;transition:background-color var(--color-fade-speed) ease-in-out;border-top-right-radius:var(--window-radius,var(--radius-m));border-top-left-radius:var(--window-radius,var(--radius-m));overflow-x:hidden!important;overflow-y:auto!important;display:flex!important;flex-direction:column!important;align-items:center!important;contain:inline-size}body #center-content>.obsidian-document>.markdown-preview-sizer{padding-bottom:80vh;width:100%;max-width:var(--line-width);flex-basis:var(--line-width);transition:background-color var(--color-fade-speed) ease-in-out;contain:inline-size}#center-content>.obsidian-document>div{width:100%!important;transition:background-color var(--color-fade-speed) ease-in-out;contain:inline-size}#center-content>.obsidian-document:not([data-type=markdown]).embed{display:flex;padding:1em;height:100%;width:100%;align-items:center;justify-content:center}#center-content>.obsidian-document:not([data-type=markdown]).embed>*{max-width:100%;max-height:100%;object-fit:contain}:not(h1,h2,h3,h4,h5,h6,li):has(> :is(.math,table)){overflow-x:auto!important}#center-content>.obsidian-document:not([data-type=markdown]){overflow-x:auto;contain:content;padding:0;margin:0;height:100%}.obsidian-document[data-type=attachment]{display:flex;flex-direction:column;align-items:center;justify-content:center;height:100%;width:100%}.obsidian-document[data-type=attachment]>*{outline:0;border:none;box-shadow:none}.obsidian-document[data-type=attachment] :is(img){max-width:90%;max-height:90%;object-fit:contain}.obsidian-document[data-type=attachment]>:is(audio){width:100%;max-width:min(90%,var(--line-width))}.obsidian-document[data-type=attachment]>:is(embed,iframe,video){width:100%;height:100%;max-width:100%;max-height:100%;object-fit:contain}.canvas-wrapper>:is(.header,.footer){z-index:100;position:absolute;display:flex;justify-content:center;flex-direction:column;width:100%;align-items:center}.scroll-highlight{position:absolute;width:100%;height:100%;pointer-events:none;z-index:1000;background-color:hsla(var(--color-accent-hsl),.25);opacity:0;padding:1em;inset:50%;translate:-50% -50%;border-radius:var(--radius-s)}</style><script defer="">async function loadIncludes(){let e=document.querySelectorAll("link[itemprop='include']");for(const t of e){let e=t.getAttribute("href");try{let o="";if(e.startsWith("https:")||e.startsWith("http:")||"file:"!=window.location.protocol){const n=await fetch(e);if(!n.ok){console.log("Could not include file: "+e),t?.remove();continue}o=await n.text()}else{const t=document.getElementById(btoa(encodeURI(e)));if(t){const e=JSON.parse(decodeURI(atob(t.getAttribute("value")??"")));o=e?.data??""}}let n=document.createRange().createContextualFragment(o);t.before(n),t.remove(),console.log("Included text: "+o),console.log("Included file: "+e)}catch(o){t?.remove(),console.log("Could not include file: "+e,o);continue}}}document.addEventListener("DOMContentLoaded",(()=>{loadIncludes()}));let isFileProtocol="file:"==location.protocol;function waitLoadScripts(e,t){let o=e.map((e=>document.getElementById(e+"-script")));!function e(n){let l=o[n],c=n+1;l?(l&&"true"!=l.getAttribute("loaded")||n<o.length&&e(c),n<o.length&&l.addEventListener("load",(()=>e(c)))):n<o.length?e(c):t()}(0)}</script></head><body class="publish css-settings-manager show-inline-title show-ribbon is-focused"><script defer="">let theme=localStorage.getItem("theme")||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light");"dark"==theme?(document.body.classList.add("theme-dark"),document.body.classList.remove("theme-light")):(document.body.classList.add("theme-light"),document.body.classList.remove("theme-dark")),window.innerWidth<480?document.body.classList.add("is-phone"):window.innerWidth<768?document.body.classList.add("is-tablet"):window.innerWidth<1024?document.body.classList.add("is-small-screen"):document.body.classList.add("is-large-screen")</script><div class="parsed-feature-container" style="display: contents;"><link itemprop="include" href="site-lib/html/custom-head-content-content.html"></div><div id="main"><div id="navbar"></div><div id="main-horizontal"><div id="left-content" class="leaf" style="--sidebar-width: var(--sidebar-width-left);"><div id="left-sidebar" class="sidebar"><div class="sidebar-handle"></div><div class="sidebar-topbar"><div class="topbar-content"><div id="search-container"><div id="search-wrapper"><input enterkeyhint="search" type="search" spellcheck="false" placeholder="Search..."><div aria-label="Clear search" id="search-clear-button"></div></div></div></div><div class="clickable-icon sidebar-collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="100%" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round" class="svg-icon"><path d="M21 3H3C1.89543 3 1 3.89543 1 5V19C1 20.1046 1.89543 21 3 21H21C22.1046 21 23 20.1046 23 19V5C23 3.89543 22.1046 3 21 3Z"></path><path d="M10 4V20"></path><path d="M4 7H7"></path><path d="M4 10H7"></path><path d="M4 13H7"></path></svg></div></div><div class="sidebar-content-wrapper"><div id="left-sidebar-content" class="leaf-content"><link itemprop="include" href="site-lib/html/file-tree-content.html"></div></div><script defer="">let ls = document.querySelector("#left-sidebar"); ls.classList.toggle("is-collapsed", window.innerWidth < 768); ls.style.setProperty("--sidebar-width", localStorage.getItem("sidebar-left-width"));</script></div></div><div id="center-content" class="leaf"><div class="obsidian-document markdown-preview-view markdown-rendered node-insert-event is-readable-line-width allow-fold-headings allow-fold-lists show-indentation-guide show-properties" data-type="markdown"><style id="MJX-CHTML-styles">mjx-c.mjx-c58::before{padding:.683em .75em 0 0;content:"X"}mjx-c.mjx-c5A::before{padding:.683em .611em 0 0;content:"Z"}mjx-c.mjx-c5E::before{padding:.694em .5em 0 0;content:"^"}mjx-c.mjx-c1D450.TEX-I::before{padding:.442em .433em .011em 0;content:"c"}mjx-c.mjx-c59::before{padding:.683em .75em 0 0;content:"Y"}mjx-c.mjx-c3E::before{padding:.54em .778em .04em 0;content:">"}mjx-c.mjx-c30::before{padding:.666em .5em .022em 0;content:"0"}mjx-mrow{display:inline-block;text-align:left}mjx-c.mjx-c1D44A.TEX-I::before{padding:.683em 1.048em .022em 0;content:"W"}mjx-c.mjx-c1D437.TEX-I::before{padding:.683em .828em 0 0;content:"D"}mjx-c.mjx-c67::before{padding:.453em .5em .206em 0;content:"g"}mjx-c.mjx-c64::before{padding:.694em .556em .011em 0;content:"d"}mjx-c.mjx-c1D467.TEX-I::before{padding:.442em .465em .011em 0;content:"z"}mjx-c.mjx-c1D6FD.TEX-I::before{padding:.705em .566em .194em 0;content:"β"}mjx-c.mjx-c1D6FC.TEX-I::before{padding:.442em .64em .011em 0;content:"α"}mjx-c.mjx-c2211.TEX-S1::before{padding:.75em 1.056em .25em 0;content:"∑"}mjx-c.mjx-c1D702.TEX-I::before{padding:.442em .497em .216em 0;content:"η"}mjx-munderover{display:inline-block;text-align:left}mjx-munderover:not([limits=false]){padding-top:.1em}mjx-munderover:not([limits=false])>*{display:block}mjx-msubsup{display:inline-block;text-align:left}mjx-script{display:inline-block;padding-right:.05em;padding-left:.033em}mjx-script>mjx-spacer{display:block}mjx-mtable{display:inline-block;text-align:center;vertical-align:.25em;position:relative;box-sizing:border-box;border-spacing:0px;border-collapse:collapse}mjx-mstyle[size="s"] mjx-mtable{vertical-align:.354em}mjx-labels{position:absolute;left:0;top:0}mjx-table{display:inline-block;vertical-align:-.5ex;box-sizing:border-box}mjx-table>mjx-itable{vertical-align:middle;text-align:left;box-sizing:border-box}mjx-labels>mjx-itable{position:absolute;top:0}mjx-mtable[justify=left]{text-align:left}mjx-mtable[justify=right]{text-align:right}mjx-mtable[justify=left][side=left]{padding-right:0!important}mjx-mtable[justify=left][side=right]{padding-left:0!important}mjx-mtable[justify=right][side=left]{padding-right:0!important}mjx-mtable[justify=right][side=right]{padding-left:0!important}mjx-mtable[align]{vertical-align:baseline}mjx-mtable[align=top]>mjx-table{vertical-align:top}mjx-mtable[align=bottom]>mjx-table{vertical-align:bottom}mjx-mtable[side=right] mjx-labels{min-width:100%}mjx-mtr{display:table-row;text-align:left}mjx-mtr[rowalign=top]>mjx-mtd{vertical-align:top}mjx-mtr[rowalign=center]>mjx-mtd{vertical-align:middle}mjx-mtr[rowalign=bottom]>mjx-mtd{vertical-align:bottom}mjx-mtr[rowalign=baseline]>mjx-mtd{vertical-align:baseline}mjx-mtr[rowalign=axis]>mjx-mtd{vertical-align:.25em}mjx-mtd{display:table-cell;text-align:center;padding:.215em .4em}mjx-mtd:first-child{padding-left:0}mjx-mtd:last-child{padding-right:0}mjx-mtable>*>mjx-itable>:first-child>mjx-mtd{padding-top:0}mjx-mtable>*>mjx-itable>:last-child>mjx-mtd{padding-bottom:0}mjx-tstrut{display:inline-block;height:1em;vertical-align:-.25em}mjx-labels[align=left]>mjx-mtr>mjx-mtd{text-align:left}mjx-labels[align=right]>mjx-mtr>mjx-mtd{text-align:right}mjx-mtd[extra]{padding:0}mjx-mtd[rowalign=top]{vertical-align:top}mjx-mtd[rowalign=center]{vertical-align:middle}mjx-mtd[rowalign=bottom]{vertical-align:bottom}mjx-mtd[rowalign=baseline]{vertical-align:baseline}mjx-mtd[rowalign=axis]{vertical-align:.25em}mjx-c.mjx-c1D441.TEX-I::before{padding:.683em .888em 0 0;content:"N"}mjx-c.mjx-c2F::before{padding:.75em .5em .25em 0;content:"/"}mjx-c.mjx-c3B::before{padding:.43em .278em .194em 0;content:";"}mjx-c.mjx-c1D464.TEX-I::before{padding:.443em .716em .011em 0;content:"w"}mjx-c.mjx-c2026::before{padding:.12em 1.172em 0 0;content:"…"}mjx-c.mjx-c220F.TEX-S2::before{padding:.95em 1.278em .45em 0;content:"∏"}mjx-c.mjx-c2223::before{padding:.75em .278em .249em 0;content:"∣"}mjx-c.mjx-c201C::before{padding:.694em .5em 0 0;content:"“"}mjx-c.mjx-c20::before{padding:0 .25em 0 0;content:" "}mjx-c.mjx-c77::before{padding:.431em .722em .011em 0;content:"w"}mjx-c.mjx-c201D::before{padding:.694em .5em 0 0;content:"”"}mjx-c.mjx-c1D460.TEX-I::before{padding:.442em .469em .01em 0;content:"s"}mjx-c.mjx-c1D44E.TEX-I::before{padding:.441em .529em .01em 0;content:"a"}mjx-c.mjx-c1D45F.TEX-I::before{padding:.442em .451em .011em 0;content:"r"}mjx-c.mjx-cA0::before{padding:0 .25em 0 0;content:" "}mjx-c.mjx-c1D45C.TEX-I::before{padding:.441em .485em .011em 0;content:"o"}mjx-c.mjx-c1D45D.TEX-I::before{padding:.442em .503em .194em 0;content:"p"}mjx-c.mjx-c1D70E.TEX-I::before{padding:.431em .571em .011em 0;content:"σ"}mjx-c.mjx-c1D445.TEX-I::before{padding:.683em .759em .021em 0;content:"R"}mjx-mfrac{display:inline-block;text-align:left}mjx-frac{display:inline-block;vertical-align:.17em;padding:0 .22em}mjx-frac[type="d"]{vertical-align:.04em}mjx-frac[delims]{padding:0 .1em}mjx-frac[atop]{padding:0 .12em}mjx-frac[atop][delims]{padding:0}mjx-dtable{display:inline-table;width:100%}mjx-dtable>*{font-size:2000%}mjx-dbox{display:block;font-size:5%}mjx-num{display:block;text-align:center}mjx-den{display:block;text-align:center}mjx-mfrac[bevelled]>mjx-num{display:inline-block}mjx-mfrac[bevelled]>mjx-den{display:inline-block}mjx-den[align=right],mjx-num[align=right]{text-align:right}mjx-den[align=left],mjx-num[align=left]{text-align:left}mjx-nstrut{display:inline-block;height:.054em;width:0;vertical-align:-.054em}mjx-nstrut[type="d"]{height:.217em;vertical-align:-.217em}mjx-dstrut{display:inline-block;height:.505em;width:0}mjx-dstrut[type="d"]{height:.726em}mjx-line{display:block;box-sizing:border-box;min-height:1px;height:.06em;border-top:.06em solid;margin:.06em -.1em;overflow:hidden}mjx-line[type="d"]{margin:.18em -.1em}mjx-msqrt{display:inline-block;text-align:left}mjx-root{display:inline-block;white-space:nowrap}mjx-surd{display:inline-block;vertical-align:top}mjx-sqrt{display:inline-block;padding-top:.07em}mjx-sqrt>mjx-box{border-top:.07em solid}mjx-sqrt.mjx-tall>mjx-box{padding-left:.3em;margin-left:-.3em}mjx-c.mjx-c221A.TEX-S1::before{padding:.85em 1.02em .35em 0;content:"√"}mjx-c.mjx-c1D458.TEX-I::before{padding:.694em .521em .011em 0;content:"k"}mjx-c.mjx-c6F::before{padding:.448em .5em .01em 0;content:"o"}mjx-c.mjx-c66::before{padding:.705em .372em 0 0;content:"f"}mjx-c.mjx-c1D466.TEX-I::before{padding:.442em .49em .205em 0;content:"y"}mjx-c.mjx-c2225::before{padding:.75em .5em .25em 0;content:"∥"}mjx-c.mjx-c1D444.TEX-I::before{padding:.704em .791em .194em 0;content:"Q"}mjx-c.mjx-c1D706.TEX-I::before{padding:.694em .583em .012em 0;content:"λ"}mjx-c.mjx-c1D434.TEX-I::before{padding:.716em .75em 0 0;content:"A"}mjx-c.mjx-c1D435.TEX-I::before{padding:.683em .759em 0 0;content:"B"}mjx-c.mjx-c1D703.TEX-I::before{padding:.705em .469em .01em 0;content:"θ"}mjx-c.mjx-c44::before{padding:.683em .764em 0 0;content:"D"}mjx-c.mjx-c45::before{padding:.68em .681em 0 0;content:"E"}mjx-c.mjx-c54::before{padding:.677em .722em 0 0;content:"T"}mjx-c.mjx-c2032::before{padding:.56em .275em 0 0;content:"′"}mjx-c.mjx-c4E::before{padding:.683em .75em 0 0;content:"N"}mjx-c.mjx-c22::before{padding:.694em .5em 0 0;content:"\""}mjx-c.mjx-c74::before{padding:.615em .389em .01em 0;content:"t"}mjx-c.mjx-c68::before{padding:.694em .556em 0 0;content:"h"}mjx-c.mjx-c63::before{padding:.448em .444em .011em 0;content:"c"}mjx-c.mjx-c6E::before{padding:.442em .556em 0 0;content:"n"}mjx-c.mjx-c70::before{padding:.442em .556em .194em 0;content:"p"}mjx-c.mjx-c72::before{padding:.442em .392em 0 0;content:"r"}mjx-c.mjx-c75::before{padding:.442em .556em .011em 0;content:"u"}mjx-c.mjx-c1D44C.TEX-I::before{padding:.683em .763em 0 0;content:"Y"}mjx-c.mjx-c43::before{padding:.705em .722em .021em 0;content:"C"}mjx-c.mjx-c69::before{padding:.669em .278em 0 0;content:"i"}mjx-c.mjx-c73::before{padding:.448em .394em .011em 0;content:"s"}mjx-c.mjx-c50::before{padding:.683em .681em 0 0;content:"P"}mjx-munder{display:inline-block;text-align:left}mjx-over{text-align:left}mjx-munder:not([limits=false]){display:inline-table}mjx-munder>mjx-row{text-align:left}mjx-under{padding-bottom:.1em}mjx-mover{display:inline-block;text-align:left}mjx-mover:not([limits=false]){padding-top:.1em}mjx-mover:not([limits=false])>*{display:block;text-align:left}mjx-c.mjx-c1D457.TEX-I::before{padding:.661em .412em .204em 0;content:"j"}mjx-c.mjx-c6D::before{padding:.442em .833em 0 0;content:"m"}mjx-c.mjx-c61::before{padding:.448em .5em .011em 0;content:"a"}mjx-c.mjx-c78::before{padding:.431em .528em 0 0;content:"x"}mjx-c.mjx-c65::before{padding:.448em .444em .011em 0;content:"e"}mjx-c.mjx-c62::before{padding:.694em .556em .011em 0;content:"b"}mjx-c.mjx-c1D461.TEX-I::before{padding:.626em .361em .011em 0;content:"t"}mjx-c.mjx-c1D43C.TEX-I::before{padding:.683em .504em 0 0;content:"I"}mjx-c.mjx-c7E::before{padding:.318em .5em 0 0;content:"~"}mjx-c.mjx-c1D442.TEX-I::before{padding:.704em .763em .022em 0;content:"O"}mjx-c.mjx-c1D410.TEX-B::before{padding:.696em .864em .193em 0;content:"Q"}mjx-c.mjx-c1D40A.TEX-B::before{padding:.686em .901em 0 0;content:"K"}mjx-c.mjx-c1D415.TEX-B::before{padding:.686em .869em .007em 0;content:"V"}mjx-c.mjx-c1D465.TEX-I::before{padding:.442em .572em .011em 0;content:"x"}mjx-c.mjx-c1D439.TEX-I::before{padding:.68em .749em 0 0;content:"F"}mjx-c.mjx-c210E.TEX-I::before{padding:.694em .576em .011em 0;content:"h"}mjx-c.mjx-c3A3::before{padding:.683em .722em 0 0;content:"Σ"}mjx-c.mjx-c38::before{padding:.666em .5em .022em 0;content:"8"}mjx-c.mjx-c1D6FF.TEX-I::before{padding:.717em .444em .01em 0;content:"δ"}mjx-c.mjx-c1D705.TEX-I::before{padding:.442em .576em .011em 0;content:"κ"}mjx-c.mjx-c1D446.TEX-I::before{padding:.705em .645em .022em 0;content:"S"}mjx-c.mjx-c1D43B.TEX-I::before{padding:.683em .888em 0 0;content:"H"}mjx-c.mjx-c1D45E.TEX-I::before{padding:.442em .46em .194em 0;content:"q"}mjx-c.mjx-c2209::before{padding:.716em .667em .215em 0;content:"∉"}mjx-c.mjx-c1D456.TEX-I::before{padding:.661em .345em .011em 0;content:"i"}mjx-c.mjx-c1D447.TEX-I::before{padding:.677em .704em 0 0;content:"T"}mjx-c.mjx-c1D440.TEX-I::before{padding:.683em 1.051em 0 0;content:"M"}mjx-c.mjx-c227C.TEX-A::before{padding:.58em .778em .153em 0;content:"≼"}mjx-c.mjx-c1D43E.TEX-I::before{padding:.683em .889em 0 0;content:"K"}mjx-c.mjx-c1D462.TEX-I::before{padding:.442em .572em .011em 0;content:"u"}mjx-c.mjx-c2192::before{padding:.511em 1em .011em 0;content:"→"}mjx-c.mjx-c1D438.TEX-I::before{padding:.68em .764em 0 0;content:"E"}mjx-c.mjx-c2264::before{padding:.636em .778em .138em 0;content:"≤"}mjx-c.mjx-c35::before{padding:.666em .5em .022em 0;content:"5"}mjx-c.mjx-c2C::before{padding:.121em .278em .194em 0;content:","}mjx-c.mjx-c1D451.TEX-I::before{padding:.694em .52em .01em 0;content:"d"}mjx-c.mjx-c1D454.TEX-I::before{padding:.442em .477em .205em 0;content:"g"}mjx-c.mjx-c1D463.TEX-I::before{padding:.443em .485em .011em 0;content:"v"}mjx-c.mjx-c2208::before{padding:.54em .667em .04em 0;content:"∈"}mjx-c.mjx-c2203::before{padding:.694em .556em 0 0;content:"∃"}mjx-c.mjx-c34::before{padding:.677em .5em 0 0;content:"4"}mjx-c.mjx-c36::before{padding:.666em .5em .022em 0;content:"6"}mjx-c.mjx-c2265::before{padding:.636em .778em .138em 0;content:"≥"}mjx-c.mjx-c2E::before{padding:.12em .278em 0 0;content:"."}mjx-c.mjx-c2032::before{padding:.56em .275em 0 0;content:"′"}mjx-c.mjx-c228B.TEX-A::before{padding:.635em .778em .241em 0;content:"⊋"}mjx-mtext{display:inline-block;text-align:left}mjx-c.mjx-c1D428.TEX-B::before{padding:.452em .575em .005em 0;content:"o"}mjx-c.mjx-c1D42B.TEX-B::before{padding:.45em .474em 0 0;content:"r"}mjx-c.mjx-c1D41D.TEX-B::before{padding:.694em .639em .006em 0;content:"d"}mjx-c.mjx-c1D41E.TEX-B::before{padding:.452em .527em .006em 0;content:"e"}mjx-c.mjx-c7C::before{padding:.75em .278em .249em 0;content:"|"}mjx-c.mjx-c3A::before{padding:.43em .278em 0 0;content:":"}mjx-c.mjx-c1D449.TEX-I::before{padding:.683em .769em .022em 0;content:"V"}mjx-c.mjx-c5B::before{padding:.75em .278em .25em 0;content:"["}mjx-c.mjx-c5D::before{padding:.75em .278em .25em 0;content:"]"}mjx-c.mjx-c1D436.TEX-I::before{padding:.705em .76em .022em 0;content:"C"}mjx-msup{display:inline-block;text-align:left}mjx-c.mjx-c2286::before{padding:.636em .778em .138em 0;content:"⊆"}mjx-c.mjx-c1D45B.TEX-I::before{padding:.442em .6em .011em 0;content:"n"}mjx-c.mjx-c2212::before{padding:.583em .778em .082em 0;content:"−"}mjx-c.mjx-c1D45A.TEX-I::before{padding:.442em .878em .011em 0;content:"m"}mjx-c.mjx-c2B::before{padding:.583em .778em .082em 0;content:"+"}mjx-c.mjx-c1D453.TEX-I::before{padding:.705em .55em .205em 0;content:"f"}mjx-c.mjx-c3D::before{padding:.583em .778em .082em 0;content:"="}mjx-c.mjx-c1D44B.TEX-I::before{padding:.683em .852em 0 0;content:"X"}mjx-c.mjx-cD7::before{padding:.491em .778em 0 0;content:"×"}mjx-c.mjx-c1D452.TEX-I::before{padding:.442em .466em .011em 0;content:"e"}mjx-c.mjx-c1D43A.TEX-I::before{padding:.705em .786em .022em 0;content:"G"}mjx-container[jax=CHTML]{line-height:0}mjx-container [space="1"]{margin-left:.111em}mjx-container [space="2"]{margin-left:.167em}mjx-container [space="3"]{margin-left:.222em}mjx-container [space="4"]{margin-left:.278em}mjx-container [space="5"]{margin-left:.333em}mjx-container [rspace="1"]{margin-right:.111em}mjx-container [rspace="2"]{margin-right:.167em}mjx-container [rspace="3"]{margin-right:.222em}mjx-container [rspace="4"]{margin-right:.278em}mjx-container [rspace="5"]{margin-right:.333em}mjx-container [size="s"]{font-size:70.7%}mjx-container [size=ss]{font-size:50%}mjx-container [size=Tn]{font-size:60%}mjx-container [size=sm]{font-size:85%}mjx-container [size=lg]{font-size:120%}mjx-container [size=Lg]{font-size:144%}mjx-container [size=LG]{font-size:173%}mjx-container [size=hg]{font-size:207%}mjx-container [size=HG]{font-size:249%}mjx-container [width=full]{width:100%}mjx-box{display:inline-block}mjx-block{display:block}mjx-itable{display:inline-table}mjx-row{display:table-row}mjx-row>*{display:table-cell}mjx-mtext{display:inline-block}mjx-mstyle{display:inline-block}mjx-merror{display:inline-block;color:red;background-color:#ff0}mjx-mphantom{visibility:hidden}mjx-assistive-mml{top:0;left:0;clip:rect(1px,1px,1px,1px);user-select:none;position:absolute!important;padding:1px 0 0!important;border:0!important;display:block!important;width:auto!important;overflow:hidden!important}mjx-assistive-mml[display=block]{width:100%!important}mjx-math{display:inline-block;text-align:left;line-height:0;text-indent:0;font-style:normal;font-weight:400;font-size:100%;font-size-adjust:none;letter-spacing:normal;border-collapse:collapse;overflow-wrap:normal;word-spacing:normal;white-space:nowrap;direction:ltr;padding:1px 0}mjx-container[jax=CHTML][display=true]{display:block;text-align:center;margin:1em 0}mjx-container[jax=CHTML][display=true][width=full]{display:flex}mjx-container[jax=CHTML][display=true] mjx-math{padding:0}mjx-container[jax=CHTML][justify=left]{text-align:left}mjx-container[jax=CHTML][justify=right]{text-align:right}mjx-msub{display:inline-block;text-align:left}mjx-mi{display:inline-block;text-align:left}mjx-c{display:inline-block}mjx-utext{display:inline-block;padding:.75em 0 .2em}mjx-mn{display:inline-block;text-align:left}mjx-texatom{display:inline-block;text-align:left}mjx-mo{display:inline-block;text-align:left}mjx-stretchy-h{display:inline-table;width:100%}mjx-stretchy-h>*{display:table-cell;width:0}mjx-stretchy-h>*>mjx-c{display:inline-block;transform:scaleX(1)}mjx-stretchy-h>*>mjx-c::before{display:inline-block;width:initial}mjx-stretchy-h>mjx-ext{overflow:clip visible;width:100%}mjx-stretchy-h>mjx-ext>mjx-c::before{transform:scaleX(500)}mjx-stretchy-h>mjx-ext>mjx-c{width:0}mjx-stretchy-h>mjx-beg>mjx-c{margin-right:-.1em}mjx-stretchy-h>mjx-end>mjx-c{margin-left:-.1em}mjx-stretchy-v{display:inline-block}mjx-stretchy-v>*{display:block}mjx-stretchy-v>mjx-beg{height:0}mjx-stretchy-v>mjx-end>mjx-c{display:block}mjx-stretchy-v>*>mjx-c{transform:scaleY(1);transform-origin:left center;overflow:hidden}mjx-stretchy-v>mjx-ext{display:block;height:100%;box-sizing:border-box;border:0 solid transparent;overflow:visible clip}mjx-stretchy-v>mjx-ext>mjx-c::before{width:initial;box-sizing:border-box}mjx-stretchy-v>mjx-ext>mjx-c{transform:scaleY(500) translateY(.075em);overflow:visible}mjx-mark{display:inline-block;height:0}mjx-c::before{display:block;width:0}.MJX-TEX{font-family:MJXZERO,MJXTEX}.TEX-B{font-family:MJXZERO,MJXTEX-B}.TEX-I{font-family:MJXZERO,MJXTEX-I}.TEX-MI{font-family:MJXZERO,MJXTEX-MI}.TEX-BI{font-family:MJXZERO,MJXTEX-BI}.TEX-S1{font-family:MJXZERO,MJXTEX-S1}.TEX-S2{font-family:MJXZERO,MJXTEX-S2}.TEX-S3{font-family:MJXZERO,MJXTEX-S3}.TEX-S4{font-family:MJXZERO,MJXTEX-S4}.TEX-A{font-family:MJXZERO,MJXTEX-A}.TEX-C{font-family:MJXZERO,MJXTEX-C}.TEX-CB{font-family:MJXZERO,MJXTEX-CB}.TEX-FR{font-family:MJXZERO,MJXTEX-FR}.TEX-FRB{font-family:MJXZERO,MJXTEX-FRB}.TEX-SS{font-family:MJXZERO,MJXTEX-SS}.TEX-SSB{font-family:MJXZERO,MJXTEX-SSB}.TEX-SSI{font-family:MJXZERO,MJXTEX-SSI}.TEX-SC{font-family:MJXZERO,MJXTEX-SC}.TEX-T{font-family:MJXZERO,MJXTEX-T}.TEX-V{font-family:MJXZERO,MJXTEX-V}.TEX-VB{font-family:MJXZERO,MJXTEX-VB}mjx-stretchy-h mjx-c,mjx-stretchy-v mjx-c{font-family:MJXZERO,MJXTEX-S1,MJXTEX-S4,MJXTEX,MJXTEX-A!important}@font-face{font-family:MJXZERO;src:url("site-lib/fonts/mathjax_zero.woff") format("woff")}@font-face{font-family:MJXTEX;src:url("site-lib/fonts/mathjax_main-regular.woff") format("woff")}@font-face{font-family:MJXTEX-B;src:url("site-lib/fonts/mathjax_main-bold.woff") format("woff")}@font-face{font-family:MJXTEX-I;src:url("site-lib/fonts/mathjax_math-italic.woff") format("woff")}@font-face{font-family:MJXTEX-MI;src:url("site-lib/fonts/mathjax_main-italic.woff") format("woff")}@font-face{font-family:MJXTEX-BI;src:url("site-lib/fonts/mathjax_math-bolditalic.woff") format("woff")}@font-face{font-family:MJXTEX-S1;src:url("site-lib/fonts/mathjax_size1-regular.woff") format("woff")}@font-face{font-family:MJXTEX-S2;src:url("site-lib/fonts/mathjax_size2-regular.woff") format("woff")}@font-face{font-family:MJXTEX-S3;src:url("site-lib/fonts/mathjax_size3-regular.woff") format("woff")}@font-face{font-family:MJXTEX-S4;src:url("site-lib/fonts/mathjax_size4-regular.woff") format("woff")}@font-face{font-family:MJXTEX-A;src:url("site-lib/fonts/mathjax_ams-regular.woff") format("woff")}@font-face{font-family:MJXTEX-C;src:url("site-lib/fonts/mathjax_calligraphic-regular.woff") format("woff")}@font-face{font-family:MJXTEX-CB;src:url("site-lib/fonts/mathjax_calligraphic-bold.woff") format("woff")}@font-face{font-family:MJXTEX-FR;src:url("site-lib/fonts/mathjax_fraktur-regular.woff") format("woff")}@font-face{font-family:MJXTEX-FRB;src:url("site-lib/fonts/mathjax_fraktur-bold.woff") format("woff")}@font-face{font-family:MJXTEX-SS;src:url("site-lib/fonts/mathjax_sansserif-regular.woff") format("woff")}@font-face{font-family:MJXTEX-SSB;src:url("site-lib/fonts/mathjax_sansserif-bold.woff") format("woff")}@font-face{font-family:MJXTEX-SSI;src:url("site-lib/fonts/mathjax_sansserif-italic.woff") format("woff")}@font-face{font-family:MJXTEX-SC;src:url("site-lib/fonts/mathjax_script-regular.woff") format("woff")}@font-face{font-family:MJXTEX-T;src:url("site-lib/fonts/mathjax_typewriter-regular.woff") format("woff")}@font-face{font-family:MJXTEX-V;src:url("site-lib/fonts/mathjax_vector-regular.woff") format("woff")}@font-face{font-family:MJXTEX-VB;src:url("site-lib/fonts/mathjax_vector-bold.woff") format("woff")}mjx-c.mjx-c1D443.TEX-I::before{padding:.683em .751em 0 0;content:"P"}mjx-c.mjx-c31::before{padding:.666em .5em 0 0;content:"1"}mjx-c.mjx-c32::before{padding:.666em .5em 0 0;content:"2"}mjx-c.mjx-c33::before{padding:.665em .5em .022em 0;content:"3"}mjx-c.mjx-c211D.TEX-A::before{padding:.683em .722em 0 0;content:"R"}mjx-c.mjx-c2216::before{padding:.75em .5em .25em 0;content:"∖"}mjx-c.mjx-c28::before{padding:.75em .389em .25em 0;content:"("}mjx-c.mjx-c222A::before{padding:.598em .667em .022em 0;content:"∪"}mjx-c.mjx-c29::before{padding:.75em .389em .25em 0;content:")"}</style><div class="markdown-preview-sizer markdown-preview-section"><div class="header"><h1 class="page-title heading inline-title" id="12._Large_Language_Models_(LLMs)_0">12. Large Language Models (LLMs)</h1><div class="data-bar"></div></div><div class="markdown-preview-pusher" style="width: 1px; height: 0.1px; margin-bottom: 0px;"></div><div class="el-h2"><h2 data-heading="1 Introduction" dir="auto" class="heading" id="1_Introduction_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>1 Introduction</h2></div><div class="el-h3"><h3 data-heading="Natural Language Processing (NLP) Overview" dir="auto" class="heading" id="Natural_Language_Processing_(NLP)_Overview_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>Natural Language Processing (NLP) Overview</h3></div><div class="el-p"><p dir="auto">Natural Language Processing (NLP) is a sub-field of artificial intelligence that deals with the <strong>automatic analysis, processing, and generation of natural language</strong>. NLP encompasses tasks such as text classification, translation, text summarization, text generation, and text analysis. Applications include voice control, automatic chatbots, machine learning, and search engines.</p></div><div class="el-h3"><h3 data-heading="Evolution of NLP Methods" dir="auto" class="heading" id="Evolution_of_NLP_Methods_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>Evolution of NLP Methods</h3></div><div class="el-p"><p dir="auto">The methodology of NLP has evolved significantly:</p></div><div class="el-ul"><ul class="has-list-bullet">
<li data-line="0" dir="auto"><span class="list-bullet"></span><strong>1960 (Rule-based):</strong> Used manually created rules.</li>
<li data-line="1" dir="auto"><span class="list-bullet"></span><strong>1990 (Statistical):</strong> Employed corpus-based Machine-learning methods to learn from data.</li>
<li data-line="2" dir="auto"><span class="list-bullet"></span><strong>2010 (Neural)</strong>.</li>
<li data-line="3" dir="auto"><span class="list-bullet"></span><strong>2020 (LLM):</strong> Large Language Models represent a new paradigm for performing NLP tasks.</li>
</ul></div><div class="el-h3"><h3 data-heading="1.1 Multitasking and LLM Properties" dir="auto" class="heading" id="1.1_Multitasking_and_LLM_Properties_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>1.1 Multitasking and LLM Properties</h3></div><div class="el-p"><p dir="auto">LLMs possess distinct properties that allow them to perform NLP tasks under a new paradigm:</p></div><div class="el-ul"><ul class="has-list-bullet">
<li data-line="0" dir="auto"><span class="list-bullet"></span>Ability to <strong>perform multiple tasks</strong>.</li>
<li data-line="1" dir="auto"><span class="list-bullet"></span>Reliance on <strong>natural language task description</strong>.</li>
<li data-line="2" dir="auto"><span class="list-bullet"></span><strong>Zero-shot capability</strong>, meaning they can perform unknown tasks without examples or gradient updates.</li>
<li data-line="3" dir="auto"><span class="list-bullet"></span>LLMs are <strong>pre-trained on large amounts of data</strong>.</li>
</ul></div><div class="el-p"><p dir="auto">This contrasts with older <strong>Single Task Models</strong>, which required dedicated models for specific tasks (e.g., Named-Entity Recognition, Machine Translation) and necessitated learning everything for each task individually.</p></div><div class="el-h3"><h3 data-heading="Knowledge Sharing Evolution" dir="auto" class="heading" id="Knowledge_Sharing_Evolution_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>Knowledge Sharing Evolution</h3></div><div class="el-p"><p dir="auto">The approach to sharing information between tasks developed through several methods:</p></div><div class="el-ul"><ul class="has-list-bullet">
<li data-line="0" dir="auto"><span class="list-bullet"></span><strong>Feature Representation:</strong> Using cascaded models or adding annotations (like Named Entity annotations) to the input for downstream tasks.</li>
<li data-line="1" dir="auto"><span class="list-bullet"></span><strong>Shared Architecture:</strong> Training parts of the network jointly across tasks.</li>
<li data-line="2" dir="auto"><span class="list-bullet"></span><strong>Specify Task in Input:</strong> Including a discrete task description or a natural language description (the latter being characteristic of LLMs) within the input.</li>
</ul></div><div class="el-h3"><h3 data-heading="1.2 Application of LLMs" dir="auto" class="heading" id="1.2_Application_of_LLMs_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>1.2 Application of LLMs</h3></div><div class="el-p"><p dir="auto">LLMs can be deployed in front-end or back-end configurations, each with different technical implications:</p></div><div class="el-ul"><ul class="has-list-bullet">
<li data-line="0" dir="auto"><span class="list-bullet"></span><strong>Back-end (Internal use):</strong> The LLM performs a single task with a clear definition provided by the front-end. The developer optimizes the natural language prompt and must parse the LLM's response to generate the final output.</li>
<li data-line="1" dir="auto"><span class="list-bullet"></span><strong>Front-end (User facing):</strong> Typically involves multi-turn conversations. The user has no direct influence on the prompt; control is exerted mainly through a system prompt.</li>
</ul></div><div class="el-hr"><hr></div><div class="el-h2"><h2 data-heading="2 Model" dir="auto" class="heading" id="2_Model_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>2 Model</h2></div><div class="el-h3"><h3 data-heading="2.1 Architecture" dir="auto" class="heading" id="2.1_Architecture_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>2.1 Architecture</h3></div><div class="el-p"><p dir="auto">The sources highlight several sequence-to-sequence views used in LLMs:</p></div><div class="el-ul"><ul class="has-list-bullet">
<li data-line="0" dir="auto"><span class="list-bullet"></span><strong>Decoder-based models (Language Model):</strong> Unidirectional models where the loss function is based on next word prediction.</li>
<li data-line="1" dir="auto"><span class="list-bullet"></span><strong>Prefix LM:</strong> A variation where attention is bidirectional for the prefix (input) but causal (unidirectional) for the generated output.</li>
<li data-line="2" dir="auto"><span class="list-bullet"></span><strong>Encoder-Decoder models:</strong> Feature a bidirectional Encoder and a unidirectional Decoder. The loss is based on next word prediction.</li>
<li data-line="3" dir="auto"><span class="list-bullet"></span><strong>Decoder-only Architecture:</strong> Relies on self-supervised learning, specifically next word prediction. This architecture allows for efficient training with several feedbacks per example. While it inherently lacks input/output separation and uses unidirectional processing, these limitations are mitigated by the use of large models.</li>
</ul></div><div class="el-h3"><h3 data-heading="2.2 Training (Unsupervised Pretraining)" dir="auto" class="heading" id="2.2_Training_(Unsupervised_Pretraining)_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>2.2 Training (Unsupervised Pretraining)</h3></div><div class="el-p"><p dir="auto">LLMs are created by pre-training on vast amounts of data. Various unsupervised pretraining techniques exist for Encoder-Decoder architectures:</p></div><div class="el-ul"><ul class="has-list-bullet">
<li data-line="0" dir="auto"><span class="list-bullet"></span><strong>BART:</strong> This approach involves <strong>corruption of the input sequence</strong> (e.g., Token Masking, Token Deletion, Text Infilling, Sentence Permutation, Document Rotation) and subsequent auto-regressive generation in the target text.</li>
<li data-line="1" dir="auto"><span class="list-bullet"></span><strong>PEGASUS:</strong> This model utilizes an Encoder-Decoder structure that incorporates both a Masked Language Model (MLM) objective and <strong>Gap Sentence Generation (GSG)</strong>. Gap sentences can be selected randomly, by taking the first <span class="math math-inline is-loaded"><mjx-container class="MathJax" jax="CHTML"><mjx-math class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45A TEX-I"></mjx-c></mjx-mi></mjx-math></mjx-container></span> sentences (Lead), or by using the top-<span class="math math-inline is-loaded"><mjx-container class="MathJax" jax="CHTML"><mjx-math class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45A TEX-I"></mjx-c></mjx-mi></mjx-math></mjx-container></span> scored sentences (Principal), where importance is approximated by token overlap.</li>
</ul></div><div class="el-hr"><hr></div><div class="el-h2"><h2 data-heading="3 Prompting" dir="auto" class="heading" id="3_Prompting_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>3 Prompting</h2></div><div class="el-p"><p dir="auto"><strong>Prompting</strong> involves encouraging a pre-trained model to make specific predictions by providing a prompt that describes the task. This technique reformulates the traditional NLP task (Input X, Output Y) into a <strong>sequence completion task</strong>.</p></div><div class="el-h3"><h3 data-heading="Zero-shot Abilities" dir="auto" class="heading" id="Zero-shot_Abilities_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>Zero-shot Abilities</h3></div><div class="el-p"><p dir="auto">In zero-shot settings, LLMs perform tasks with <strong>no examples</strong> and <strong>no gradient updates</strong>, relying solely on their ability to predict the most probable next token.</p></div><div class="el-ul"><ul class="has-list-bullet">
<li data-line="0" dir="auto"><span class="list-bullet"></span><strong>Generative Tasks:</strong> The task is transformed into a completion task (e.g., "The sentence 'I fly to New York' mentioned the city …").</li>
<li data-line="1" dir="auto"><span class="list-bullet"></span><strong>Discriminative Tasks:</strong> This involves comparing the probability of different possible text sequences.</li>
</ul></div><div class="el-h3"><h3 data-heading="Prompting Process Flow" dir="auto" class="heading" id="Prompting_Process_Flow_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>Prompting Process Flow</h3></div><div class="el-p"><p dir="auto">The typical prompting workflow involves several stages:</p></div><div class="el-ol"><ol>
<li data-line="0" dir="auto"><strong>Example X</strong></li>
<li data-line="1" dir="auto"><strong>Prompt Addition</strong></li>
<li data-line="2" dir="auto"><strong>Prompt</strong></li>
<li data-line="3" dir="auto"><strong>Answer Prediction</strong></li>
<li data-line="4" dir="auto"><strong>Prediction</strong></li>
<li data-line="5" dir="auto"><strong>Mapping</strong></li>
<li data-line="6" dir="auto"><strong>Answer</strong></li>
</ol></div><div class="el-h3"><h3 data-heading="3.1 Prompt Addition" dir="auto" class="heading" id="3.1_Prompt_Addition_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>3.1 Prompt Addition</h3></div><div class="el-p"><p dir="auto">This step involves generating a prompt using a template—a natural language description with defined slots for the Input (<span class="math math-inline is-loaded"><mjx-container class="MathJax" jax="CHTML"><mjx-math class="MJX-TEX"><mjx-mtext class="mjx-n"><mjx-c class="mjx-c5B"></mjx-c><mjx-c class="mjx-c58"></mjx-c><mjx-c class="mjx-c5D"></mjx-c></mjx-mtext></mjx-math></mjx-container></span>) and the Answer (<span class="math math-inline is-loaded"><mjx-container class="MathJax" jax="CHTML"><mjx-math class="MJX-TEX"><mjx-mtext class="mjx-n"><mjx-c class="mjx-c5B"></mjx-c><mjx-c class="mjx-c5A"></mjx-c><mjx-c class="mjx-c5D"></mjx-c></mjx-mtext></mjx-math></mjx-container></span>).</p></div><div class="el-ul"><ul class="has-list-bullet">
<li data-line="0" dir="auto"><span class="list-bullet"></span><span class="list-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span><strong>Prompt Types</strong>:
<ul class="has-list-bullet">
<li data-line="1" dir="auto"><span class="list-bullet"></span><strong>Prefix prompt:</strong> The input text appears entirely before the answer slot <span class="math math-inline is-loaded"><mjx-container class="MathJax" jax="CHTML"><mjx-math class="MJX-TEX"><mjx-mtext class="mjx-n"><mjx-c class="mjx-c5B"></mjx-c><mjx-c class="mjx-c5A"></mjx-c><mjx-c class="mjx-c5D"></mjx-c></mjx-mtext></mjx-math></mjx-container></span> (e.g., "English: [X] German: [Z]"). This is typically used for sequence-to-sequence tasks like translation.</li>
<li data-line="2" dir="auto"><span class="list-bullet"></span><strong>Cloze prompt:</strong> The answer slot <span class="math math-inline is-loaded"><mjx-container class="MathJax" jax="CHTML"><mjx-math class="MJX-TEX"><mjx-mtext class="mjx-n"><mjx-c class="mjx-c5B"></mjx-c><mjx-c class="mjx-c5A"></mjx-c><mjx-c class="mjx-c5D"></mjx-c></mjx-mtext></mjx-math></mjx-container></span> is positioned in the middle of the prompt (e.g., "[x] Overall, it was a [z] movie").</li>
</ul>
</li>
</ul></div><div class="el-h3"><h3 data-heading="3.2 Answer Prediction" dir="auto" class="heading" id="3.2_Answer_Prediction_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>3.2 Answer Prediction</h3></div><div class="el-p"><p dir="auto">The LLM is used to predict the content of the answer slot <span class="math math-inline is-loaded"><mjx-container class="MathJax" jax="CHTML"><mjx-math class="MJX-TEX"><mjx-mtext class="mjx-n"><mjx-c class="mjx-c5B"></mjx-c><mjx-c class="mjx-c5A"></mjx-c><mjx-c class="mjx-c5D"></mjx-c></mjx-mtext></mjx-math></mjx-container></span>.</p></div><div class="el-ul"><ul class="has-list-bullet">
<li data-line="0" dir="auto"><span class="list-bullet"></span><strong>Answer Space:</strong> Possible answers <span class="math math-inline is-loaded"><mjx-container class="MathJax" jax="CHTML"><mjx-math class="MJX-TEX"><mjx-mtext class="mjx-n"><mjx-c class="mjx-c5A"></mjx-c></mjx-mtext></mjx-math></mjx-container></span> can be the entire vocabulary or a restricted, small subset (e.g., "Excellent, good, OK, bad, horrible").</li>
<li data-line="1" dir="auto"><span class="list-bullet"></span><strong>Scoring Function:</strong> The predicted likelihood of the language model is the most common scoring metric used to find the best filled prompt (<span class="math math-inline is-loaded"><mjx-container class="MathJax" jax="CHTML"><mjx-math class="MJX-TEX"><mjx-texatom texclass="ORD"><mjx-mover><mjx-over style="padding-bottom: 0.105em; padding-left: 0.288em; margin-bottom: -0.531em;"><mjx-mo class="mjx-n" style="width: 0px; margin-left: -0.25em;"><mjx-c class="mjx-c5E"></mjx-c></mjx-mo></mjx-over><mjx-base><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D467 TEX-I"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-texatom></mjx-math></mjx-container></span>). Additional scoring methods include Perplexity and the Channel method (conditional probability of the reverse direction, <span class="math math-inline is-loaded"><mjx-container class="MathJax" jax="CHTML"><mjx-math class="MJX-TEX"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c7C"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D450 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="2"><mjx-c class="mjx-c1D467 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math></mjx-container></span>).</li>
</ul></div><div class="el-h3"><h3 data-heading="3.3 Answer Extraction" dir="auto" class="heading" id="3.3_Answer_Extraction_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>3.3 Answer Extraction</h3></div><div class="el-p"><p dir="auto">This step involves mapping the model's prediction <span class="math math-inline is-loaded"><mjx-container class="MathJax" jax="CHTML"><mjx-math class="MJX-TEX"><mjx-mtext class="mjx-n"><mjx-c class="mjx-c5B"></mjx-c><mjx-c class="mjx-c5A"></mjx-c><mjx-c class="mjx-c5D"></mjx-c></mjx-mtext></mjx-math></mjx-container></span> back to the desired output answer <span class="math math-inline is-loaded"><mjx-container class="MathJax" jax="CHTML"><mjx-math class="MJX-TEX"><mjx-mtext class="mjx-n"><mjx-c class="mjx-c5B"></mjx-c><mjx-c class="mjx-c59"></mjx-c><mjx-c class="mjx-c5D"></mjx-c></mjx-mtext></mjx-math></mjx-container></span>.</p></div><div class="el-ul"><ul class="has-list-bullet">
<li data-line="0" dir="auto"><span class="list-bullet"></span><strong>Answer Shape:</strong> The predicted output can take the form of tokens (a single token), a span (short multi-token, common with cloze prompts), or a sentence (long prediction, common with prefix prompts for generation).</li>
<li data-line="1" dir="auto"><span class="list-bullet"></span><strong>Mapping:</strong> The prediction <span class="math math-inline is-loaded"><mjx-container class="MathJax" jax="CHTML"><mjx-math class="MJX-TEX"><mjx-mtext class="mjx-n"><mjx-c class="mjx-c5B"></mjx-c><mjx-c class="mjx-c5A"></mjx-c><mjx-c class="mjx-c5D"></mjx-c></mjx-mtext></mjx-math></mjx-container></span> is mapped to the final answer (Y). This can be a simple identity mapping or a complex mapping (e.g., mapping "fantastic," "interesting," or "happy" to the final sentiment label "Positive"). This process is sometimes referred to as <strong>Answer Engineering</strong>.</li>
<li data-line="2" dir="auto"><span class="list-bullet"></span><strong>Discrete Answer Search:</strong> Techniques to improve answer robustness include <strong>Answer Paraphrasing</strong> (summing the prediction probability over all paraphrases of the target answer, <span class="math math-inline is-loaded"><mjx-container class="MathJax" jax="CHTML"><mjx-math class="MJX-TEX"><mjx-munder limits="false"><mjx-mo class="mjx-sop"><mjx-c class="mjx-c2211 TEX-S1"></mjx-c></mjx-mo><mjx-script style="vertical-align: -0.285em;"><mjx-texatom size="s" texclass="ORD"><mjx-msup><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D467 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: 0.289em;"><mjx-mo class="mjx-var" size="s"><mjx-c class="mjx-c2032"></mjx-c></mjx-mo></mjx-script></mjx-msup><mjx-mo class="mjx-n"><mjx-c class="mjx-c2208"></mjx-c></mjx-mo><mjx-mtext class="mjx-n"><mjx-c class="mjx-c70"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c72"></mjx-c><mjx-c class="mjx-c61"></mjx-c></mjx-mtext><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D467 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-texatom></mjx-script></mjx-munder><mjx-mi class="mjx-i" space="2"><mjx-c class="mjx-c1D443 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-msup><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D467 TEX-I"></mjx-c></mjx-mi><mjx-script style="vertical-align: 0.363em;"><mjx-mo class="mjx-var" size="s"><mjx-c class="mjx-c2032"></mjx-c></mjx-mo></mjx-script></mjx-msup><mjx-mo class="mjx-n"><mjx-c class="mjx-c7C"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-math></mjx-container></span>), <strong>Prune-to-search</strong> (automatically finding restricted sets of possible answers or "verbalizations"), and <strong>Label Decomposition</strong>.</li>
</ul></div><div class="el-h3"><h3 data-heading="3.4 Expansion" dir="auto" class="heading" id="3.4_Expansion_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>3.4 Expansion</h3></div><div class="el-p"><p dir="auto">Expanding the prompt provides additional context to improve prediction. Techniques include:</p></div><div class="el-ul"><ul class="has-list-bullet">
<li data-line="0" dir="auto"><span class="list-bullet"></span><strong>Prompt Ensemble:</strong> Using multiple prompts in parallel to stabilize results and combine complementary strengths. Methods for combination include uniform averaging, weighted averaging, and majority vote for classification, or joint decoding for generation.</li>
<li data-line="1" dir="auto"><span class="list-bullet"></span><strong>Prompt Decomposition:</strong> Dividing a complex task into multiple sub-tasks and performing them using individual prompts.</li>
<li data-line="2" dir="auto"><span class="list-bullet"></span><strong>Prompt Composition:</strong> Using subprompts for sub-tasks within a composable task, such as relation extraction.</li>
</ul></div><div class="el-hr"><hr></div><div class="el-h2"><h2 data-heading="4 In-context Learning (ICL)" dir="auto" class="heading" id="4_In-context_Learning_(ICL)_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>4 In-context Learning (ICL)</h2></div><div class="el-p"><p dir="auto"><strong>In-context Learning (ICL)</strong>, often referred to as <strong>Few-shot learning</strong>, involves demonstrating the answer with examples directly in the context. The model learns how to perform the task based on the provided examples, without requiring gradient updates.</p></div><div class="el-ul"><ul class="has-list-bullet">
<li data-line="0" dir="auto"><span class="list-bullet"></span><strong>Challenges:</strong> The effectiveness of ICL depends on <strong>sample selection</strong> and <strong>sample ordering</strong>.</li>
<li data-line="1" dir="auto"><span class="list-bullet"></span><strong>Sample Selection:</strong> Choosing good examples for ICL can be done via unsupervised learning (e.g., L2 distance/cosine similarity between example and input), supervised learning (e.g., Dense Passage Retriever), or Reinforcement learning.</li>
<li data-line="2" dir="auto"><span class="list-bullet"></span><strong>Sample Ordering:</strong> Unsupervised methods suggest placing the most similar examples closest to the right (near the target prompt).</li>
<li data-line="3" dir="auto"><span class="list-bullet"></span>ICL using few examples can achieve good performance on language understanding tasks like SuperGLUE.</li>
</ul></div><div class="el-hr"><hr></div><div class="el-h2"><h2 data-heading="5 Chain-of-Thought (COT)" dir="auto" class="heading" id="5_Chain-of-Thought_(COT)_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>5 Chain-of-Thought (COT)</h2></div><div class="el-p"><p dir="auto">Reasoning problems, such as Arithmetic Reasoning (AR), Symbolic Reasoning (SR), and Commonsense Reasoning (CR), are typically difficult for LLMs.</p></div><div class="el-h3"><h3 data-heading="Chain of Thought Concept" dir="auto" class="heading" id="Chain_of_Thought_Concept_0"><span class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span>Chain of Thought Concept</h3></div><div class="el-p"><p dir="auto">A <strong>Chain of Thought (CoT)</strong> is a series of intermediate natural language reasoning steps that lead to the final output. This intuition uses <strong>&lt;input, intermediate results, output&gt; triples</strong> instead of simple &lt;input, output&gt; pairs.</p></div><div class="el-ul"><ul class="has-list-bullet">
<li data-line="0" dir="auto"><span class="list-bullet"></span><strong>Benefits of CoT:</strong> It leads to decomposition into easier intermediate problems, provides interpretability, and leverages the powerful prompting ability of LLMs.</li>
<li data-line="1" dir="auto"><span class="list-bullet"></span><span class="list-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></span><strong>Methods:</strong>
<ul class="has-list-bullet">
<li data-line="2" dir="auto"><span class="list-bullet"></span><strong>Few-shot CoT:</strong> Providing the model with examples that explicitly include the intermediate reasoning steps.</li>
<li data-line="3" dir="auto"><span class="list-bullet"></span><strong>Zero-shot CoT:</strong> This technique is activated by simply adding a phrase like <strong>"Let's think step by step."</strong> to the prompt, encouraging the model to generate the reasoning steps itself before producing the final answer. Zero-shot CoT often involves a two-step process: Reasoning Extraction followed by Answer Extraction.</li>
</ul>
</li>
</ul></div><div class="footer"><div class="data-bar"></div></div></div></div></div><div id="right-content" class="leaf" style="--sidebar-width: var(--sidebar-width-right);"><div id="right-sidebar" class="sidebar"><div class="sidebar-handle"></div><div class="sidebar-topbar"><div class="topbar-content"><label class="theme-toggle-container" for="theme-toggle-input" id=""><input class="theme-toggle-input" type="checkbox" id="theme-toggle-input"><div class="toggle-background"></div></label></div><div class="clickable-icon sidebar-collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="100%" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round" class="svg-icon"><path d="M21 3H3C1.89543 3 1 3.89543 1 5V19C1 20.1046 1.89543 21 3 21H21C22.1046 21 23 20.1046 23 19V5C23 3.89543 22.1046 3 21 3Z"></path><path d="M10 4V20"></path><path d="M4 7H7"></path><path d="M4 10H7"></path><path d="M4 13H7"></path></svg></div></div><div class="sidebar-content-wrapper"><div id="right-sidebar-content" class="leaf-content"><div class="graph-view-wrapper"><div class="feature-header"><div class="feature-title">Interactive Graph</div></div><div class="graph-view-placeholder">
		<div class="graph-view-container">
			<div class="graph-icon graph-expand" role="button" aria-label="Expand" data-tooltip-position="top"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon"><line x1="7" y1="17" x2="17" y2="7"></line><polyline points="7 7 17 7 17 17"></polyline></svg></div>
			<div class="graph-icon graph-global" role="button" aria-label="Global Graph" data-tooltip-position="top"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon lucide-git-fork"><circle cx="12" cy="18" r="3"></circle><circle cx="6" cy="6" r="3"></circle><circle cx="18" cy="6" r="3"></circle><path d="M18 9v2c0 .6-.4 1-1 1H7c-.6 0-1-.4-1-1V9"></path><path d="M12 12v3"></path></svg></div>
			<canvas id="graph-canvas" class="hide" width="512px" height="512px"></canvas>
		</div>
		</div></div><div id="outline" class=" tree-container"><div class="feature-header"><div class="feature-title">Table Of Contents</div><button class="clickable-icon nav-action-button tree-collapse-all" aria-label="Collapse All"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></svg></button></div><div class="tree-item mod-collapsible" data-depth="1"><a class="tree-item-self is-clickable mod-collapsible" href="lecture-summaries/natural-language-processing/12.-large-language-models-(llms).html#12._Large_Language_Models_(LLMs)_0" data-path="#12._Large_Language_Models_(LLMs)_0"><div class="tree-item-icon collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div><div class="tree-item-inner heading-link" heading-name="12. Large Language Models (LLMs)">12. Large Language Models (LLMs)</div></a><div class="tree-item-children"><div class="tree-item mod-collapsible" data-depth="2"><a class="tree-item-self is-clickable mod-collapsible" href="lecture-summaries/natural-language-processing/12.-large-language-models-(llms).html#1_Introduction_0" data-path="#1_Introduction_0"><div class="tree-item-icon collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div><div class="tree-item-inner heading-link" heading-name="1 Introduction">1 Introduction</div></a><div class="tree-item-children"><div class="tree-item" data-depth="3"><a class="tree-item-self is-clickable" href="lecture-summaries/natural-language-processing/12.-large-language-models-(llms).html#Natural_Language_Processing_(NLP)_Overview_0" data-path="#Natural_Language_Processing_(NLP)_Overview_0"><div class="tree-item-inner heading-link" heading-name="Natural Language Processing (NLP) Overview">Natural Language Processing (NLP) Overview</div></a><div class="tree-item-children"></div></div><div class="tree-item" data-depth="3"><a class="tree-item-self is-clickable" href="lecture-summaries/natural-language-processing/12.-large-language-models-(llms).html#Evolution_of_NLP_Methods_0" data-path="#Evolution_of_NLP_Methods_0"><div class="tree-item-inner heading-link" heading-name="Evolution of NLP Methods">Evolution of NLP Methods</div></a><div class="tree-item-children"></div></div><div class="tree-item" data-depth="3"><a class="tree-item-self is-clickable" href="lecture-summaries/natural-language-processing/12.-large-language-models-(llms).html#1.1_Multitasking_and_LLM_Properties_0" data-path="#1.1_Multitasking_and_LLM_Properties_0"><div class="tree-item-inner heading-link" heading-name="1.1 Multitasking and LLM Properties">1.1 Multitasking and LLM Properties</div></a><div class="tree-item-children"></div></div><div class="tree-item" data-depth="3"><a class="tree-item-self is-clickable" href="lecture-summaries/natural-language-processing/12.-large-language-models-(llms).html#Knowledge_Sharing_Evolution_0" data-path="#Knowledge_Sharing_Evolution_0"><div class="tree-item-inner heading-link" heading-name="Knowledge Sharing Evolution">Knowledge Sharing Evolution</div></a><div class="tree-item-children"></div></div><div class="tree-item" data-depth="3"><a class="tree-item-self is-clickable" href="lecture-summaries/natural-language-processing/12.-large-language-models-(llms).html#1.2_Application_of_LLMs_0" data-path="#1.2_Application_of_LLMs_0"><div class="tree-item-inner heading-link" heading-name="1.2 Application of LLMs">1.2 Application of LLMs</div></a><div class="tree-item-children"></div></div></div></div><div class="tree-item mod-collapsible" data-depth="2"><a class="tree-item-self is-clickable mod-collapsible" href="lecture-summaries/natural-language-processing/12.-large-language-models-(llms).html#2_Model_0" data-path="#2_Model_0"><div class="tree-item-icon collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div><div class="tree-item-inner heading-link" heading-name="2 Model">2 Model</div></a><div class="tree-item-children"><div class="tree-item" data-depth="3"><a class="tree-item-self is-clickable" href="lecture-summaries/natural-language-processing/12.-large-language-models-(llms).html#2.1_Architecture_0" data-path="#2.1_Architecture_0"><div class="tree-item-inner heading-link" heading-name="2.1 Architecture">2.1 Architecture</div></a><div class="tree-item-children"></div></div><div class="tree-item" data-depth="3"><a class="tree-item-self is-clickable" href="lecture-summaries/natural-language-processing/12.-large-language-models-(llms).html#2.2_Training_(Unsupervised_Pretraining)_0" data-path="#2.2_Training_(Unsupervised_Pretraining)_0"><div class="tree-item-inner heading-link" heading-name="2.2 Training (Unsupervised Pretraining)">2.2 Training (Unsupervised Pretraining)</div></a><div class="tree-item-children"></div></div></div></div><div class="tree-item mod-collapsible" data-depth="2"><a class="tree-item-self is-clickable mod-collapsible" href="lecture-summaries/natural-language-processing/12.-large-language-models-(llms).html#3_Prompting_0" data-path="#3_Prompting_0"><div class="tree-item-icon collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div><div class="tree-item-inner heading-link" heading-name="3 Prompting">3 Prompting</div></a><div class="tree-item-children"><div class="tree-item" data-depth="3"><a class="tree-item-self is-clickable" href="lecture-summaries/natural-language-processing/12.-large-language-models-(llms).html#Zero-shot_Abilities_0" data-path="#Zero-shot_Abilities_0"><div class="tree-item-inner heading-link" heading-name="Zero-shot Abilities">Zero-shot Abilities</div></a><div class="tree-item-children"></div></div><div class="tree-item" data-depth="3"><a class="tree-item-self is-clickable" href="lecture-summaries/natural-language-processing/12.-large-language-models-(llms).html#Prompting_Process_Flow_0" data-path="#Prompting_Process_Flow_0"><div class="tree-item-inner heading-link" heading-name="Prompting Process Flow">Prompting Process Flow</div></a><div class="tree-item-children"></div></div><div class="tree-item" data-depth="3"><a class="tree-item-self is-clickable" href="lecture-summaries/natural-language-processing/12.-large-language-models-(llms).html#3.1_Prompt_Addition_0" data-path="#3.1_Prompt_Addition_0"><div class="tree-item-inner heading-link" heading-name="3.1 Prompt Addition">3.1 Prompt Addition</div></a><div class="tree-item-children"></div></div><div class="tree-item" data-depth="3"><a class="tree-item-self is-clickable" href="lecture-summaries/natural-language-processing/12.-large-language-models-(llms).html#3.2_Answer_Prediction_0" data-path="#3.2_Answer_Prediction_0"><div class="tree-item-inner heading-link" heading-name="3.2 Answer Prediction">3.2 Answer Prediction</div></a><div class="tree-item-children"></div></div><div class="tree-item" data-depth="3"><a class="tree-item-self is-clickable" href="lecture-summaries/natural-language-processing/12.-large-language-models-(llms).html#3.3_Answer_Extraction_0" data-path="#3.3_Answer_Extraction_0"><div class="tree-item-inner heading-link" heading-name="3.3 Answer Extraction">3.3 Answer Extraction</div></a><div class="tree-item-children"></div></div><div class="tree-item" data-depth="3"><a class="tree-item-self is-clickable" href="lecture-summaries/natural-language-processing/12.-large-language-models-(llms).html#3.4_Expansion_0" data-path="#3.4_Expansion_0"><div class="tree-item-inner heading-link" heading-name="3.4 Expansion">3.4 Expansion</div></a><div class="tree-item-children"></div></div></div></div><div class="tree-item" data-depth="2"><a class="tree-item-self is-clickable" href="lecture-summaries/natural-language-processing/12.-large-language-models-(llms).html#4_In-context_Learning_(ICL)_0" data-path="#4_In-context_Learning_(ICL)_0"><div class="tree-item-inner heading-link" heading-name="4 In-context Learning (ICL)">4 In-context Learning (ICL)</div></a><div class="tree-item-children"></div></div><div class="tree-item mod-collapsible" data-depth="2"><a class="tree-item-self is-clickable mod-collapsible" href="lecture-summaries/natural-language-processing/12.-large-language-models-(llms).html#5_Chain-of-Thought_(COT)_0" data-path="#5_Chain-of-Thought_(COT)_0"><div class="tree-item-icon collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div><div class="tree-item-inner heading-link" heading-name="5 Chain-of-Thought (COT)">5 Chain-of-Thought (COT)</div></a><div class="tree-item-children"><div class="tree-item" data-depth="3"><a class="tree-item-self is-clickable" href="lecture-summaries/natural-language-processing/12.-large-language-models-(llms).html#Chain_of_Thought_Concept_0" data-path="#Chain_of_Thought_Concept_0"><div class="tree-item-inner heading-link" heading-name="Chain of Thought Concept">Chain of Thought Concept</div></a><div class="tree-item-children"></div></div></div></div></div></div></div></div></div><script defer="">let rs = document.querySelector("#right-sidebar"); rs.classList.toggle("is-collapsed", window.innerWidth < 768); rs.style.setProperty("--sidebar-width", localStorage.getItem("sidebar-right-width"));</script></div></div></div></div></body></html>