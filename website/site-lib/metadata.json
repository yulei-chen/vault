{"createdTime":1764120161180,"shownInTree":["model-driven-software-development/01.-introduction.html","model-driven-software-development/02.-metamodelling.html","model-driven-software-development/03.-advanced-uml.html","natural-language-processing/01.-introduction.html","natural-language-processing/02.-words.html","natural-language-processing/03.-neural-word-representation.html","natural-language-processing/04.-sentence-structure.html","natural-language-processing/05.-semantics.html","natural-language-processing/06.-topic-models.html","natural-language-processing/07.-sentiment-analysis.html","software-test-&-quality-management/01.-introduction.html","software-test-&-quality-management/02.-testing-process.html","software-test-&-quality-management/03.-testing-phrases.html","software-test-&-quality-management/04.-static-testing.html","software-test-&-quality-management/05.-black-box-testing.html","index.html"],"attachments":["site-lib/fonts/94f2f163d4b698242fef.otf","site-lib/fonts/72505e6a122c6acd5471.woff2","site-lib/fonts/2d5198822ab091ce4305.woff2","site-lib/fonts/c8ba52b05a9ef10f4758.woff2","site-lib/fonts/cb10ffd7684cd9836a05.woff2","site-lib/fonts/293fd13dbca5a3e450ef.woff2","site-lib/fonts/085cb93e613ba3d40d2b.woff2","site-lib/fonts/b5f0f109bc88052d4000.woff2","site-lib/fonts/cbe0ae49c52c920fd563.woff2","site-lib/fonts/535a6cf662596b3bd6a6.woff2","site-lib/fonts/70cc7ff27245e82ad414.ttf","site-lib/fonts/454577c22304619db035.ttf","site-lib/fonts/52ac8f3034507f1d9e53.ttf","site-lib/fonts/05b618077343fbbd92b7.ttf","site-lib/fonts/4bb6ac751d1c5478ff3a.woff2","site-lib/media/6155340132a851f6089e.svg","site-lib/media/2308ab1944a6bfa5c5b8.svg","site-lib/html/file-tree-content.html","site-lib/scripts/webpage.js","site-lib/media/favicon.png","site-lib/styles/obsidian.css","site-lib/styles/global-variable-styles.css","site-lib/styles/main-styles.css","attachments/pasted-image-20251126022044.png","site-lib/rss.xml","attachments/pasted-image-20251126025040.png","attachments/pasted-image-20251126025053.png","attachments/pasted-image-20251126025309.png","attachments/pasted-image-20251126025315.png","attachments/pasted-image-20251126025836.png","attachments/pasted-image-20251126025850.png","attachments/pasted-image-20251126030848.png","attachments/pasted-image-20251126031330.png","attachments/pasted-image-20251126032448.png","attachments/pasted-image-20251126032239.png","attachments/pasted-image-20251126031843.png","attachments/pasted-image-20251126031934.png","site-lib/styles/theme.css","site-lib/scripts/graph-wasm.wasm","site-lib/scripts/graph-wasm.js","site-lib/scripts/graph-render-worker.js","attachments/screenshot-2025-12-01-at-02.02.01.png","attachments/pasted-image-20251201022626.png","attachments/pasted-image-20251204035604.png","attachments/pasted-image-20251204035633.png","attachments/screenshot-2025-12-01-at-03.45.29.png","site-lib/fonts/mathjax_zero.woff","site-lib/fonts/mathjax_main-regular.woff","site-lib/fonts/mathjax_main-bold.woff","site-lib/fonts/mathjax_math-italic.woff","site-lib/fonts/mathjax_main-italic.woff","site-lib/fonts/mathjax_math-bolditalic.woff","site-lib/fonts/mathjax_size1-regular.woff","site-lib/fonts/mathjax_size2-regular.woff","site-lib/fonts/mathjax_size3-regular.woff","site-lib/fonts/mathjax_size4-regular.woff","site-lib/fonts/mathjax_ams-regular.woff","site-lib/fonts/mathjax_calligraphic-regular.woff","site-lib/fonts/mathjax_calligraphic-bold.woff","site-lib/fonts/mathjax_fraktur-regular.woff","site-lib/fonts/mathjax_fraktur-bold.woff","site-lib/fonts/mathjax_sansserif-regular.woff","site-lib/fonts/mathjax_sansserif-bold.woff","site-lib/fonts/mathjax_sansserif-italic.woff","site-lib/fonts/mathjax_script-regular.woff","site-lib/fonts/mathjax_typewriter-regular.woff","site-lib/fonts/mathjax_vector-regular.woff","site-lib/fonts/mathjax_vector-bold.woff","attachments/screenshot-2025-12-04-at-04.32.17.png"],"allFiles":["software-test-&-quality-management/05.-black-box-testing.html","attachments/screenshot-2025-12-04-at-04.32.17.png","software-test-&-quality-management/04.-static-testing.html","software-test-&-quality-management/02.-testing-process.html","software-test-&-quality-management/03.-testing-phrases.html","attachments/screenshot-2025-12-01-at-03.45.29.png","software-test-&-quality-management/01.-introduction.html","model-driven-software-development/01.-introduction.html","index.html","model-driven-software-development/03.-advanced-uml.html","model-driven-software-development/02.-metamodelling.html","natural-language-processing/07.-sentiment-analysis.html","natural-language-processing/06.-topic-models.html","natural-language-processing/05.-semantics.html","natural-language-processing/04.-sentence-structure.html","natural-language-processing/03.-neural-word-representation.html","natural-language-processing/02.-words.html","natural-language-processing/01.-introduction.html","site-lib/scripts/graph-wasm.wasm","site-lib/fonts/94f2f163d4b698242fef.otf","site-lib/fonts/72505e6a122c6acd5471.woff2","site-lib/fonts/2d5198822ab091ce4305.woff2","site-lib/fonts/c8ba52b05a9ef10f4758.woff2","site-lib/fonts/cb10ffd7684cd9836a05.woff2","site-lib/fonts/293fd13dbca5a3e450ef.woff2","site-lib/fonts/085cb93e613ba3d40d2b.woff2","site-lib/fonts/b5f0f109bc88052d4000.woff2","site-lib/fonts/cbe0ae49c52c920fd563.woff2","site-lib/fonts/535a6cf662596b3bd6a6.woff2","site-lib/fonts/70cc7ff27245e82ad414.ttf","site-lib/fonts/454577c22304619db035.ttf","site-lib/fonts/52ac8f3034507f1d9e53.ttf","site-lib/fonts/05b618077343fbbd92b7.ttf","site-lib/fonts/4bb6ac751d1c5478ff3a.woff2","site-lib/media/6155340132a851f6089e.svg","site-lib/media/2308ab1944a6bfa5c5b8.svg","site-lib/fonts/mathjax_zero.woff","site-lib/fonts/mathjax_main-regular.woff","site-lib/fonts/mathjax_main-bold.woff","site-lib/fonts/mathjax_math-italic.woff","site-lib/fonts/mathjax_main-italic.woff","site-lib/fonts/mathjax_math-bolditalic.woff","site-lib/fonts/mathjax_size1-regular.woff","site-lib/fonts/mathjax_size2-regular.woff","site-lib/fonts/mathjax_size3-regular.woff","site-lib/fonts/mathjax_size4-regular.woff","site-lib/fonts/mathjax_ams-regular.woff","site-lib/fonts/mathjax_calligraphic-regular.woff","site-lib/fonts/mathjax_calligraphic-bold.woff","site-lib/fonts/mathjax_fraktur-regular.woff","site-lib/fonts/mathjax_fraktur-bold.woff","site-lib/fonts/mathjax_sansserif-regular.woff","site-lib/fonts/mathjax_sansserif-bold.woff","site-lib/fonts/mathjax_sansserif-italic.woff","site-lib/fonts/mathjax_script-regular.woff","site-lib/fonts/mathjax_typewriter-regular.woff","site-lib/fonts/mathjax_vector-regular.woff","site-lib/fonts/mathjax_vector-bold.woff","site-lib/html/file-tree-content.html","site-lib/scripts/webpage.js","site-lib/scripts/graph-wasm.js","site-lib/scripts/graph-render-worker.js","site-lib/media/favicon.png","site-lib/styles/obsidian.css","site-lib/styles/theme.css","site-lib/styles/global-variable-styles.css","site-lib/styles/main-styles.css"],"webpages":{"natural-language-processing/01.-introduction.html":{"title":"01. Introduction","icon":"","description":"NLP: Algorithms to process, analyze and understand texts in natural language\nUnderstanding structure\nUnderstanding meaning Ambiguity, e.g., bank\nCompositionality, e.g., green thumb\nCo-reference, e.g., if the baby does not like the milk, boil it\nLiving language, e.g., Eyjafjallajökull\nRare events\n<img alt=\"Pasted image 20251126022044.png\" src=\"attachments/pasted-image-20251126022044.png\" target=\"_self\">\nCorpus = large collection of annotated texts (or speech files)\nLinguistics\nMachine learning\nNLP tasks: Information Extraction + Retrieval\nSummarization\nMachine translation\nQuestion Answering\nPersonal assistant NLP techniques (focus on deep learning-based): Data types Texts, e.g., Brown Corpus, Penn Treebank\nDictionaries/Ontologies, e.g., WordNet, GermaNet, EuroWordNet Data grows English Text Corpora (News)\nComputer MT or ASR systems train on &gt;&gt; 1GWords. News Shuffle, GigaWord, Europarl, VideoLectures, …\nHuman speaks 0.5 GigaWords in a Lifetime! Model types Classification, e.g., word sense disambiguation\nSequence Classification, e.g., sentiment analysis\nSequence labeling, e.g., named entity recognition\nSequence to Sequence model, e.g., summerization\nStructure prediction, e.g., parsing Evaluation: Human evaluation\nAutomatic evaluation ","aliases":[],"inlineTags":[],"frontmatterTags":[],"headers":[{"heading":"1. Introduction","level":1,"id":"1._Introduction_0"},{"heading":"Challenges","level":2,"id":"Challenges_0"},{"heading":"History","level":2,"id":"History_0"},{"heading":"Content","level":2,"id":"Content_0"}],"links":[],"author":"","coverImageURL":".","fullURL":"natural-language-processing/01.-introduction.html","pathToRoot":"..","attachments":["attachments/pasted-image-20251126022044.png"],"createdTime":1764119987596,"modifiedTime":1764120046435,"sourceSize":1351,"sourcePath":"Natural Language Processing/01. Introduction.md","exportPath":"natural-language-processing/01.-introduction.html","showInTree":true,"treeOrder":1,"backlinks":[],"type":"markdown"},"index.html":{"title":"Home","icon":"","description":"This is where I take notes.","aliases":[],"inlineTags":[],"frontmatterTags":[],"headers":[],"links":[],"author":"","coverImageURL":"","fullURL":"index.html","pathToRoot":".","attachments":[],"createdTime":1764119564819,"modifiedTime":1764124249620,"sourceSize":49,"sourcePath":"index.md","exportPath":"index.html","showInTree":true,"treeOrder":12,"backlinks":[],"type":"markdown"},"natural-language-processing/02.-words.html":{"title":"02. Words","icon":"","description":"Example (Chinese): 我看书 — “I read/look at a book.”. Morphemes:\n我 = I\n看 = read/look\n书 = book\nKey idea: Minimal or no inflection; morphemes usually stand alone.Example (Turkish): ev-ler-in-de — “in your houses”. Morphemes:\nev = house\n-ler = plural\n-in = your\n-de = in\nKey idea: Morphemes have clear boundaries and single meanings, attached in sequence.Example (Spanish): habl-o — “I speak”. Morphemes:\nhabl- = speak\n-o = 1st person + singular + present\nKey idea: A single morpheme typically encodes multiple grammatical features.Example (Inuktitut): tusaatsiarunnanngittualuujunga — “I really can’t hear well”. Simplified morphemes:\ntusaa- = hear\n-tsiaq- = well\n-junnaq- = be able\n-nngit- = not\n-tualuu- = very\n-junga = I\nKey idea: Many morphemes combine to express what would be a whole sentence.Example (Arabic): kitaab — “book”. Morphemes:\nk-t-b = root “write”\ni__a__ = vocalic pattern forming a noun\nKey idea: Words are formed by inserting vocalic patterns into consonantal roots.\nLexeme, e.g., SEE\nWord-form, e.g., saw, seeing, saws\nParadigm, e.g., I, my, mine, me\nWord family, e.g., act, action, actor, activate, active, activist Lexical/Content\nFunctional\nRoot Suffix\nPrefix\nInfix\nCircumfix Changes the grammatical form of a word without creating a new lexeme.\nDoes not change core meaning or word class.\nTypical categories: tense, number, case, agreement.\nExamples:\nwalk → walks (3sg)\ncat → cats (plural)\nsee → saw (past) Forms a new word (new lexeme) by adding derivational affixes.\nOften changes meaning and sometimes word class.\nExamples:\nhappy → unhappy\nnation → national\nmodern → modernize\nread → reader Combines two or more roots/words to form a new lexeme.\nThe components remain recognizable.\nExamples:\nblack + board → blackboard\nsun + light → sunlight\nice + cream → ice-cream\nHere’s a concise English note summarizing the morphological processes you listed, with clear examples:\nMaps a word form to its lemma (dictionary/base form).\nIgnores context.\nExample:\nsaw → see Lemma and Lexeme are different. Lexeme is an abstract concept, while lemma is a concrete concept. Breaks a word into (lemma + grammatical tag).\nDoes not consider context, so may produce multiple analyses.\nExample:\nsaw → {(see, verb.past), (saw, noun.sg)} Uses context to select the correct analysis.\nExample:\nSentence: Peter saw her\nsaw → {(see, verb.past)} Splits a word into its smallest meaningful units (morphemes).\nExample:\nde-nation-al-iz-ation → de + nation + al + iz + ation Produces a word form from a lemma + features.\nEssentially the reverse of lemmatization.\nExample:\n(see, verb.past) → saw\nBoth Feature Engineering (FE) and Representation Learning (RL) are methodologies designed to solve the critical challenge in machine learning models: how to map text into a fixed vector representation, or .However, they differ fundamentally in their approach, timeframe, and resulting data structure.Feature Engineering (FE) represents the dominant methods used over the last 25 years. This approach relies on manually defined templates to describe the important information of the text. FE is often decried as “costly, hand-crafted, expensive, domain-specific,” among other criticisms. While simple features typically give the bulk of the performance and can yield high accuracies, the feature set is still difficult to maintain.Representation Learning (RL) describes the methods developed over the last 10 years. The defining characteristic of RL is that the features are automatically learned. The result of this process is an approximation, meaning some information are lost, and the representation is typically task dependent.The methodologies lead to stark differences in the resulting vector format:\nFE commonly uses representations like the Bag of Words (BoW). This approach results in a Sparse matrix, where most entries are zero. BoW uses one feature per word, which can be a Binary feature (0 or 1) or a Count feature. Feature Importance and TF-IDF can help solve problems respectively about word importance and high-frequently used no-meaning words.\nRL generates a Neural representation, which is characterized as Dense. Negation: It's not a great monster movie.\nDifferent sense: There's a great deal of corny dialogue and preposterous moments.\nMultiple sentiments: A great ensemble cast can't lift this heartfelt enterprise out of the familiar.\nNumber of features: Too few. Hard to distinguish different inputs\nToo many. Overfitting Representation Learning evolved to better handle critical challenges inherent in text data that constrained Feature Engineering:\nWord Order and Length: FE methods like BoW ignore word position when dealing with variable length input. Although FE can use Higher-Order Binary Feature Templates (like bigrams or trigrams) to consider word order and maintain a fixed size vector representation, this introduces the challenge of an extremely large number of features. Conversely, RL must address the fact that word order is important and must handle variable length input.\nOpen Vocabulary: For FE, open vocabulary is a challenge that requires the use of a fixed vocab. RL also faces the open vocabulary challenge, but aims to solve it by being able to understand unknown words, such as the complex term Hippopotomonstrosesquipedaliophobia.\nGranularity: RL’s approach to solving vocabulary challenges involves identifying the best granularity—choosing among words, subwords, or characters. RL acknowledges that while using characters provides much training data and allows understanding of unknown words, it leads to long sequences for text, which is not efficient. Therefore, RL uses machine learning based subword segmentation to learn efficient representation. Techniques like Byte-Pair Encoding (BPE), which starts with an Initial vocabulary of characters to ensure every words can be represented, are employed to strike this balance.\n","aliases":[],"inlineTags":[],"frontmatterTags":[],"headers":[{"heading":"2. Words","level":1,"id":"2._Words_0"},{"heading":"Morphology","level":2,"id":"Morphology_0"},{"heading":"Morphology and Languages","level":3,"id":"Morphology_and_Languages_0"},{"heading":"1. Isolating Languages","level":4,"id":"1._Isolating_Languages_0"},{"heading":"2. Agglutinative Languages","level":4,"id":"2._Agglutinative_Languages_0"},{"heading":"3. Fusional (Inflectional) Languages","level":4,"id":"3._Fusional_(Inflectional)_Languages_0"},{"heading":"4. Polysynthetic Languages","level":4,"id":"4._Polysynthetic_Languages_0"},{"heading":"5. Root-and-Pattern Languages","level":4,"id":"5._Root-and-Pattern_Languages_0"},{"heading":"Concepts of morphology","level":3,"id":"Concepts_of_morphology_0"},{"heading":"Types of morphemes","level":3,"id":"Types_of_morphemes_0"},{"heading":"1. Stem","level":4,"id":"1._Stem_0"},{"heading":"2. Affixes","level":4,"id":"2._Affixes_0"},{"heading":"Word Formation","level":3,"id":"Word_Formation_0"},{"heading":"1. Inflection","level":4,"id":"1._Inflection_0"},{"heading":"2. Derivation","level":4,"id":"2._Derivation_0"},{"heading":"3. Compounding","level":4,"id":"3._Compounding_0"},{"heading":"Morphology Tasks","level":3,"id":"Morphology_Tasks_0"},{"heading":"1. Lemmatization","level":4,"id":"1._Lemmatization_0"},{"heading":"2. Morphological Analysis","level":4,"id":"2._Morphological_Analysis_0"},{"heading":"3. Tagging (Morphosyntactic Disambiguation)","level":4,"id":"3._Tagging_(Morphosyntactic_Disambiguation)_0"},{"heading":"4. Morpheme Segmentation","level":4,"id":"4._Morpheme_Segmentation_0"},{"heading":"5. Generation","level":4,"id":"5._Generation_0"},{"heading":"Machine Learning in NLP","level":2,"id":"Machine_Learning_in_NLP_0"},{"heading":"Feature Engineering vs. Representation Learning","level":3,"id":"Feature_Engineering_vs._Representation_Learning_0"},{"heading":"1. Core Philosophy and Timeframe","level":4,"id":"1._Core_Philosophy_and_Timeframe_0"},{"heading":"2. Representation Format and Structure","level":4,"id":"2._Representation_Format_and_Structure_0"},{"heading":"3. Issues of Feature Engineering","level":4,"id":"3._Issues_of_Feature_Engineering_0"},{"heading":"4. Handling Language Challenges","level":4,"id":"4._Handling_Language_Challenges_0"}],"links":[],"author":"","coverImageURL":"","fullURL":"natural-language-processing/02.-words.html","pathToRoot":"..","attachments":[],"createdTime":1764120293371,"modifiedTime":1764120585497,"sourceSize":6983,"sourcePath":"Natural Language Processing/02. Words.md","exportPath":"natural-language-processing/02.-words.html","showInTree":true,"treeOrder":2,"backlinks":[],"type":"markdown"},"natural-language-processing/03.-neural-word-representation.html":{"title":"03. Neural Word Representation","icon":"","description":"NLP has undergone a major transformation over the past few decades, shifting from traditional statistical methods to modern neural network-based approaches.Early NLP systems relied heavily on statistical language models (SLMs). These models estimate the probability of a word sequence based on observed frequencies in large text corpora. N-gram models is one of the most common approaches, which predict the next word given the previous n−1 words. For example, a trigram model predicts the next word based on the previous two words.However, SLMs have limitations about data sparsity, context window, and feature engineering (SLMs often required manual preprocessing and feature extraction).In the part, we will focus on neural network based methods.Word Embedding is one of Dense Embeddings. Dense vector has the following advantages: Short vectors may be easier to use as features in machine learning (less weights to tune) Dense vectors may generalize better than storing explicit counts They may do better at capturing synonymy: car and automobile are synonyms; but are distinct dimensions\na word with car as a neighbor and a word with automobile as a neighbor should be similar, but aren’t In practice, they appear to work better So can we convert one-hot (Sparse) to Dense Embeddings? Assume there is a matrix W. We can multiply our one-hot with W. This gives us the “embedding” for a word. W is what we need to learn (in the context of machine learning).\nPlease read Q&amp;A for more details. Word2Vec CBOW Skip-gram Negative sampling Fasttext character representation Glove Q: What is the relationship between the corpus-based approach and feature engineering? A: In traditional Corpus-based Approaches to NLP, feature extraction is an explicit process. This feature extraction defines the features used by the statistical model, such as the word ID, case, and POS tags (e.g., Word: 546; Case: Upper-case; POS: NN). In Deep Learning Approaches, the input text still undergoes feature extraction, but the output is a dense binary vector (e.g., 10010010010101). Therefore, feature engineering is the traditional method of explicit feature extraction from the corpus, which has been largely replaced by automatic feature learning in deep learning.Q: What is an important property of word embeddings? A: An important property of word embeddings is that semantic similar words should have similar representation. This concept is tied to J.R. Firth’s 1953 dictum: “You shall know a word by the company it keeps!”.Q: What determines the size of one-hot embeddings? A: The size, or dimension, of a one-hot encoding vector is determined by the vocabulary size.Q: What is an advantage of dense embeddings? A: Dense vectors have several advantages: they are short vectors, may generalize better, and appear to work better in practice, especially at capturing synonymy.Q: What is a problem with n-gram models? A: A major problem with statistical N-gram models is that most longer word sequences have not been seen in the corpus. This requires a non-satisfactory solution like back-off to a shorter sequence. N-gram models also operate in Discrete Space.Q: Why do we call the Feed Forward Neural Network here self-supervised? A: The Feed Forward Neural Network language model is considered self-supervised because training needs only unlabelled data (pure text). The model is trained to predict the next word given previous words. The meaning of the word is important for estimating the next word, and this meaning needs to be encoded in the embedding.Q: What is the advantage of a continuous space? A: The advantage of mapping words to a continuous word representation is generalization to similar n-grams. Unlike discrete space, which only allows for exact matching, continuous space enables the model to automatically learn optimal features and find the nearest neighbor, capturing syntactic similarities and semantic similarities.Q: Is the position of the input words important? A: For the Continuous Bag of Words Model (CBOW), the position of the input words is ignored. The model sums the surrounding words to predict the center word.Q: How many embeddings do we get for each word? A: For Word2Vec models (CBOW and Skip-gram), typically there is one embedding for each word.\nMore details: <a data-tooltip-position=\"top\" aria-label=\"https://lilianweng.github.io/posts/2017-10-15-word-embedding/\" rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://lilianweng.github.io/posts/2017-10-15-word-embedding/\" target=\"_self\">Learning Word Embedding</a> <br><a data-tooltip-position=\"top\" aria-label=\"https://medium.com/@fraidoonomarzai99/word2vec-cbow-skip-gram-in-depth-88d9cc340a50\" rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://medium.com/@fraidoonomarzai99/word2vec-cbow-skip-gram-in-depth-88d9cc340a50\" target=\"_self\">Word2Vec (CBOW, Skip-gram) In Depth</a> Q: What is the CBOW score function based on? A: The CBOW score function is based on the dot product to measure similarity.Q: What is the difference between CBOW and Skip-gram? A: CBOW and Skip-gram have opposite objectives:\nCBOW predicts the word based on surrounding words.\nSkip-gram predicts the surrounding words given the current word.\nQ: What is maximized with the Skip-gram objective? A: The Skip-gram objective is to maximize the probability of any context word given the current word. This objective uses a negative log loss.Q: Why is negative sampling necessary? A: Negative sampling is necessary because the standard Skip-gram objective requires normalization over the entire vocabulary, which is computationally demanding. Negative sampling resolves this by generating samples and summing over those samples instead of the entire vocabulary.Q: Why do we use sigmoid instead of softmax in the objective function? A: We use the Sigmoid function () because negative sampling converts the problem from a multiclass classifier to a binary classifier.Q: Where do we get negative examples from? A: Negative examples are sampled from the lexicon. The negative set typically contains 2 to 20 words sampled from some distribution, such as uniform, unigram, or a smoothed unigram. The smoothed unigram distribution is created by raising the probabilities to the power of and then renormalizing.Q: For a corpus with fixed size, are there more unique 6-grams or 3-grams? A: Based on the problem of N-gram models—that most longer word sequences have not been seen—it can be inferred that there would be more unique 6-grams than 3-grams, as longer sequences lead to higher sparsity.Q: How are context and target words represented with FastText? A: FastText uses character N-grams:A: FastText uses character N-grams:\nThe word embedding for the target word is the sum of character 3-grams to 6-grams and the whole word itself.\nThe word embedding for the context word is taken from the embedding table without adding character n-grams.\nQ: What is the difference between Word2Vec and FastText? A: FastText is an extension of Word2Vec that addresses challenges found in Word2Vec. FastText uses subword representation (character n-grams) to solve issues in morphologically rich languages and to create representations for words that have not been seen previously.Q: What is a key difference between Word2Vec and GloVe? A: The key difference lies in the perspective used for training: Word2Vec uses a Local view (predicting words within the context), while GloVe uses a Global view. GloVe leverages Word co-occurrence matrices and is motivated by the ratio of co-occurrence probabilities.Q: In which situations does GloVe likely produce unreliable word embeddings?\nRare words – too few co-occurrences to learn meaningful vectors.\nSmall corpus – global statistics are sparse and noisy.\nDomain mismatch – training domain differs from the target domain.\nPolysemous words – one vector cannot represent multiple senses.\nNo subword modeling – fails on morphology and misspellings.\nOut-of-vocabulary words – no embeddings for unseen words.\nBiased training data – co-occurrence statistics reflect and amplify bias.\n","aliases":[],"inlineTags":[],"frontmatterTags":[],"headers":[{"heading":"3. Neural Word Representation","level":1,"id":"3._Neural_Word_Representation_0"},{"heading":"Word Embeddings","level":2,"id":"Word_Embeddings_0"},{"heading":"Language Models","level":2,"id":"Language_Models_0"},{"heading":"Q&amp;A","level":2,"id":"Q&A_0"}],"links":[],"author":"","coverImageURL":"","fullURL":"natural-language-processing/03.-neural-word-representation.html","pathToRoot":"..","attachments":[],"createdTime":1764120769803,"modifiedTime":1764121486799,"sourceSize":8614,"sourcePath":"Natural Language Processing/03. Neural Word Representation.md","exportPath":"natural-language-processing/03.-neural-word-representation.html","showInTree":true,"treeOrder":3,"backlinks":[],"type":"markdown"},"natural-language-processing/04.-sentence-structure.html":{"title":"04. Sentence Structure","icon":"","description":"Part-of-Speech (POS): POS tags classify words based on their grammatical relationship and functional category (e.g., noun, verb) in context. This differs from word sense (meaning).\nClassification: Words belong to Open classes (lexical words) (Nouns, Verbs, Adjectives, etc.) or Closed classes (functional) (Determiners, Pronouns, Conjunctions).\nUniversal Tag Set: Smaller, coarser sets (like the 12-tag Universal Tag Set) are used for cross-lingual purposes.\nChallenge (Ambiguity): Many word instances are ambiguous, meaning the same word type can have multiple POS tags (e.g., \"back\" can be JJ, NN, RB, or VB). POS tagging is the process of determining the correct tag for a word given its context.\nSyntax studies how words organize into hierarchical units called constituents (phrases). Only entire phrases, such as a Prepositional Phrase (PP), can be moved within a sentence. Context Free Grammar: Introduced by Chomsky, CFG is a formal system used to generate sentences and assign parse trees. Non-terminals () are phrase variables (NP, VP), and Terminals () are the actual words. Phrase Structure Grammar: This applies CFG rules to define natural language structures (e.g., Declarative sentences are NP VP). Subcategorization: Verbs enforce constraints on the required accompanying phrases; e.g., Transitive verbs require a direct object, while Intransitive verbs do not.\nAmbiguity: A sentence can have multiple correct parse trees (Structural Ambiguity). This includes Attachment ambiguity and Coordination ambiguity. Lexicalized Grammars (e.g., Combinatory Categorial Grammar): These models use a lexicon to encode complex grammatical dependencies like Agreement, Subcategorization, and Long-distance dependencies. Words are assigned detailed categories (e.g., the verb \"Cancel\" has the category ). Forward rule application ()\nBackward rule application ()\n<img alt=\"Pasted image 20251126025040.png\" src=\"attachments/pasted-image-20251126025040.png\" target=\"_self\"> Dependency Grammar: This approach describes structure using directed binary relations (typed relations) between a head and its dependent. Graph : Vertices correspond to words\n: Arcs corresponding to relations Restrictions: Connected\nDesignated root node\n<br>Acyclic (connected acyclic graph is a tree) or planar <img alt=\"Pasted image 20251126025053.png\" src=\"attachments/pasted-image-20251126025053.png\" target=\"_self\"> Language Models automatically learn sentence structure by assigning a Probability to a sentence.Simple counting fails due to sparse data; many valid but unseen sentences are assigned a probability of zero.Solution: Chain Rule.E.g.,Estimating the probability of a word from its full history is intractable.Solution: Markov Assumption.\nThe probability of a word depends only on the previous words.N-gram Models: Unigram, Bigram, Trigram, etc. Though insufficient for capturing long-distance dependencies, they are practical.<br><img alt=\"Pasted image 20251126025309.png\" src=\"attachments/pasted-image-20251126025309.png\" target=\"_self\">MLE estimates N-gram probabilities by maximizing the likelihood of training data.<br><img alt=\"Pasted image 20251126025315.png\" src=\"attachments/pasted-image-20251126025315.png\" target=\"_self\">A key challenge persists: if an N-gram is an unseen event (count = 0), its probability is 0, making the entire sentence probability 0.If you'd like, I can also format these into a printable PDF, add color themes, or convert into study flashcards.","aliases":[],"inlineTags":[],"frontmatterTags":[],"headers":[{"heading":"4. Sentence Structure","level":1,"id":"4._Sentence_Structure_0"},{"heading":"Word Classes","level":2,"id":"Word_Classes_0"},{"heading":"Syntax","level":2,"id":"Syntax_0"},{"heading":"Language Model","level":2,"id":"Language_Model_0"},{"heading":"Challenge","level":3,"id":"Challenge_0"},{"heading":"Another Challenge","level":3,"id":"Another_Challenge_0"},{"heading":"Maximum Likelihood Estimation (MLE)","level":3,"id":"Maximum_Likelihood_Estimation_(MLE)_0"}],"links":[],"author":"","coverImageURL":".","fullURL":"natural-language-processing/04.-sentence-structure.html","pathToRoot":"..","attachments":["attachments/pasted-image-20251126025040.png","attachments/pasted-image-20251126025053.png","attachments/pasted-image-20251126025309.png","attachments/pasted-image-20251126025315.png"],"createdTime":1764121582042,"modifiedTime":1764122251824,"sourceSize":4086,"sourcePath":"Natural Language Processing/04. Sentence Structure.md","exportPath":"natural-language-processing/04.-sentence-structure.html","showInTree":true,"treeOrder":4,"backlinks":[],"type":"markdown"},"natural-language-processing/05.-semantics.html":{"title":"05. Semantics","icon":"","description":"We learned from the part 1 that there are multiple NLP tasks. Most of them require the machine to understand the meaning of the sentence and generate corresponding answers. We learned Word2Vec to generate words from part 3. So, today we are going to dive into the study of meaning.Semantics is defined as the Study of meaning. It is distinct from Morphology (how words are built) and Syntax (how words form larger units like phrases/sentences).The field is generally divided into two core branches:\nLexical Semantics: The study of word meaning.\nCompositional Semantics: The study of the meaning of sentences.\nLexical semantics (5.1) studies the meaning of words.\nLexeme: The abstract representation of a word (e.g., MOUSE, mice).\nSense: A discrete representation of one aspect of the meaning. The meaning of a word can vary based on the given context (e.g., MOUSE as an animal versus a hand-operated device). Synonyms &amp; Antonyms: Synonyms: Two words with (nearly) identical senses (e.g., couch/sofa). The Principle of contrast suggests that different linguistic forms are always associated with a difference in meaning (e.g., \"H2O\" is more scientific than \"water\").\nAntonyms: Words with opposing meaning, mostly adjectives (e.g., Long/short, Rise/fall). Taxonomic Relations: Hyponym: A word that is more specific (e.g., Car is a hyponym of vehicle).\nHypernym/Superordinate: A word that is less specific (e.g., Vehicle is a hypernym of car).\n<img alt=\"Pasted image 20251126025836.png\" src=\"attachments/pasted-image-20251126025836.png\" target=\"_self\">\nMeronym: Represents part-whole relations (e.g., Wheel is a meronym of car).\nThe Basic Level: Items are \"human-sized,\" have distinctive actions, are learned earliest in childhood, and their names are shortest and most frequent (e.g., \"chair\" vs. its hypernym \"furniture\"). Similarity &amp; Relatedness: Word similarity refers to words with different but similar meanings (e.g., Dog and cat). Word embeddings can represent these relationships (e.g., Male-Female, Country-Capital).\nWord relatedness refers to words belonging to the same semantic field (e.g., Waiter, Menu, Chef belong to the \"restaurants\" field). Homonymy: Words that share a form but have unrelated, distinct meanings (e.g., bank1: financial institution; bank2: sloping land). Homographs: Same spelling, different meanings (e.g., bank/bank).\nHomophones: Same pronunciation, different meanings (e.g., write/right). Affective meaning involves aspects of a word related to emotion.\nValence: Pleasantness of the stimulus (e.g., Happy/satisfied vs. unhappy/annoyed).\nArousal: Intensity of emotion (e.g., Excited vs. calm).\nDominance: Degree of control (e.g., Controlling vs. influenced). Description: A hierarchically organized lexical database that acts as an on-line thesaurus and dictionary.\nDefinition of Sense: Defined by a Synset (synonym set), which is a set of near-synonyms that instantiates a sense or concept, with an accompanying gloss.<br>\n<img alt=\"Pasted image 20251126025850.png\" src=\"attachments/pasted-image-20251126025850.png\" target=\"_self\">\nStructure: WordNet can be viewed as a graph where nodes are synsets and edges represent various relationships, such as \"is-a\" (hypernym/hyponym).\nSupersenses: Top-level hypernyms in the hierarchy (e.g., Noun supersenses include GROUP, PERSON, ARTIFACT).\nChallenges: Resolving Ambiguity (one form, multiple meanings split form) and Variability (multiple forms, one meaning merge forms).\nCompositional semantics (5.2) studies the meaning of sentences. The central challenge is the infinite number of sentences.\nFrege's Principle of compositionality: The meaning of an expression depends on the meaning of its parts and how they are put together.\nThis involves structuring meaning using symbols, bridging the gap between language and common-sense knowledge.\nVocabulary: Includes Non-logical (open-ended terms linked to a world model) and Logical (closed set of symbols, operators, quantifiers) elements.\nExamples of Representations: First-order logic, Abstract Meaning Representation (AMR), and Frame-based/slot-filling representation.\nRequirements: Verifiability: Ability to compare the represented state to the state of the world (e.g., checking Serves(Maharani, VegetarianFood) against a knowledge base).\nUnambiguous representations: The representation itself must be clear, even if the natural language sentence is vague.\nCanonical Form: Distinct inputs with the same meaning must yield the same representation.\nInference and Variables: Variables are needed to make general statements, and the system must use world knowledge to draw conclusions.\nExpressiveness: Must handle a wide range of expressions. This is a flexible and well-understood meaning representation. It uses Terms (objects), Functions (e.g., LocationOf(Frasca)), and Variables to make general statements.Shallow semantics aims to represent the commonality of an event despite its linguistic variability (e.g., different ways to describe a stock purchase).\nThematic Roles: Identify common roles like AGENT (often the subject) and THEME.\nChallenges: Fragmentations (e.g., multiple types of INSTRUMENTS) and difficulty in defining roles (e.g., whether an Agent must be animate).\nAlternatives: Use broader roles like PROTO-AGENT (Agent-like properties) and PROTO-PATIENT (Patient-like properties). PropBank (Proposition Bank) (5.2.4): A dataset based on Penn TreeBank annotation, focusing primarily on verbs.\nUses numbered roles (Arg0, Arg1, etc.) specific to each verb sense. Arg0 typically represents the PROTO-AGENT, and Arg1 the PROTO-PATIENT.\nArgMs represent modifications like time (TMP), location (LOC), or reason (PRP/CAU). FrameNet (5.2.5): Motivated by the need for inference about situations described by different verbs (e.g., increased vs. rose).\nDefines Frames as background knowledge structures containing common-sense information about a situation (e.g., Change_position_on_a_scale).\nUses Core roles that are specific to the frame, and Non-core roles (general properties) comparable to PropBank's Arg_M. Reasoning (5.3) takes Facts and Logic as input to generate an Answer.\nDeductive Reasoning: Moves from premise(s) to a Firm conclusion using logic (e.g., All whales are mammals All whales have kidneys). (general -&gt; special)\nInductive Reasoning: Moves from observation to a Likely conclusion (e.g., winged creatures are usually birds this winged creature is likely a bird). (special -&gt; general)\nAbductive Reasoning: Moves from observation to a Likely explanation.\nFormal Reasoning: Follows formal rules/logic and is based on axiomatic knowledge.\nInformal Reasoning: Uses intuition, experience, and common sense. Goal: An applied semantic inference task aimed at identifying the logical relationship between a pair of text sequences (a Premise and a Hypothesis).\nAlso called: Textual Entailment.\nLabels: Entailment: Hypothesis is true.\nContradiction: Hypothesis is false.\nNeutral (Undetermined): Hypothesis is undetermined. ","aliases":[],"inlineTags":[],"frontmatterTags":[],"headers":[{"heading":"5. Semantics","level":1,"id":"5._Semantics_0"},{"heading":"Foundations &amp; Motivation","level":2,"id":"Foundations_&_Motivation_0"},{"heading":"Lexical Semantics (Word Meaning)","level":2,"id":"Lexical_Semantics_(Word_Meaning)_0"},{"heading":"A. Core Concepts","level":3,"id":"A._Core_Concepts_0"},{"heading":"B. Word Relations (5.1.1)","level":3,"id":"B._Word_Relations_(5.1.1)_0"},{"heading":"C. Connotation / Affective Meaning (5.1.2)","level":3,"id":"C._Connotation_/_Affective_Meaning_(5.1.2)_0"},{"heading":"D. Lexical Resource: WordNet (5.1.3)","level":3,"id":"D._Lexical_Resource_WordNet_(5.1.3)_0"},{"heading":"Compositional Semantics (Sentence Meaning)","level":2,"id":"Compositional_Semantics_(Sentence_Meaning)_0"},{"heading":"A. The Compositionality Principle","level":3,"id":"A._The_Compositionality_Principle_0"},{"heading":"B. Formal Meaning Representation (5.2.1)","level":3,"id":"B._Formal_Meaning_Representation_(5.2.1)_0"},{"heading":"C. First-order Logic (5.2.2)","level":3,"id":"C._First-order_Logic_(5.2.2)_0"},{"heading":"D. Shallow Semantics &amp; Semantic Roles (5.2.3)","level":3,"id":"D._Shallow_Semantics_&_Semantic_Roles_(5.2.3)_0"},{"heading":"E. Semantic Role Resources","level":3,"id":"E._Semantic_Role_Resources_0"},{"heading":"Semantic Reasoning &amp; Application","level":2,"id":"Semantic_Reasoning_&_Application_0"},{"heading":"A. Types of Reasoning (5.3.1)","level":3,"id":"A._Types_of_Reasoning_(5.3.1)_0"},{"heading":"B. Natural Language Inference (NLI) (5.3.2)","level":3,"id":"B._Natural_Language_Inference_(NLI)_(5.3.2)_0"}],"links":[],"author":"","coverImageURL":".","fullURL":"natural-language-processing/05.-semantics.html","pathToRoot":"..","attachments":["attachments/pasted-image-20251126025836.png","attachments/pasted-image-20251126025850.png"],"createdTime":1764122256816,"modifiedTime":1764122620853,"sourceSize":8140,"sourcePath":"Natural Language Processing/05. Semantics.md","exportPath":"natural-language-processing/05.-semantics.html","showInTree":true,"treeOrder":5,"backlinks":[],"type":"markdown"},"natural-language-processing/06.-topic-models.html":{"title":"06. Topic Models","icon":"","description":"\nTopic models address information overload by helping to Automatically process data. Traditional NLP solutions include Summarization, Information extraction, and Question answering.\nGoals: Topic models aim to Cluster/Organize data, Discover hidden themes, and Annotate documents with themes.\nTopic Definition: A topic is characterized conceptually by frequent words, and formally as a Distribution over words.\nTask: This is an Unsupervised text clustering task. Input: Corpus and the specified Number of Topics ().\nOutput: The learned Topics (Distribution over words) and Topics per document. The dataset is defined as a Collection of documents.\nDocument Representation: Individual documents are typically represented using a Bag-of-word representation (a -dimensional vector, where is the vocabulary size).\nCollection Representation: A collection of documents is represented as a -dim matrix.\nMatrix Values: Matrix values can represent Counts, Indicator function, or TF-IDF.\nLSA is a non-probabilistic approach designed to Model which words typically co-occur using matrix representation.\nMethod: The core idea is to Perform matrix factorization, specifically using SVD (Singular Value Decomposition) to yield Latent Semantic Analysis. represents the Number of topics.\nProbabilistic models assume that the observed data is generated by a generative probabilistic process that includes hidden variables. The hidden variable in topic modeling is the Thematic structure. The main task is to Infer hidden structure and Generalize to new data.LDA is the primary probabilistic model used (Blei, 2003).\nName Breakdown: Latent: Topic is unknown / Latent in the text.\nDirichlet: Refers to the Distribution of distributions. Documents are Distributions of topics, and Topics are Distributions of words.\nAllocation: Allocate topics to the words. Process/Intuition: Documents exhibit multiple topics. Topics are Distributions over words; Documents are a Mixture of topics; and words are Drawn from one of the topics. The major challenge is that Only documents are observed, while topics are hidden variables.\nGraphical Model: This model encodes assumptions and dependencies. Nodes represent random variables, and Shaded nodes () represent the Observed word. Plates indicate replications (e.g., for documents, for words within documents, for topics).\n<img alt=\"Pasted image 20251126030848.png\" src=\"attachments/pasted-image-20251126030848.png\" target=\"_self\">\nThe goal of inference is to compute the posterior distribution conditioned on the documents: .\nVariables to Infer: Per-word topic assignment (), Per-document topic proportions (), and Per-corpus topic distribution ().\nChallenge: The posterior distribution Cannot be computed exactly due to the intractable marginal likelihood. Even assuming the global variable (Topic, ) is fixed, local inference (for ) remains intractable.\nSolution: Approximate methods, such as Gibbs sampling, are necessary.\nGibbs sampling is an iterative Markov Chain Monte Carlo method used for approximation.\nProcedure: Start with random assignment of all random variables (topic-word allocation, topic distribution, document distribution).\nFor a given word, Keep everything except that word fixed.\nAssign a topic to this word based on current distribution.\nRepeat for several iterations. Sampling Formula: The probability of assigning topic to word is proportional to the product of two components: Document Likelihood: How much document likes topic (). This depends on (Number of times document uses topic ) and (Dirichlet parameter for document to topic distribution).\nTopic Likelihood: How much topic likes word (). This depends on (Number of times topic uses word type) and (Dirichlet parameter for topic to word distribution). Evaluating topic models (Unsupervised learning) differs from supervised learning.\nMeasure 1: Held-out Log Likelihood: A good model should assign a High probability for real data (held-out data).\nMeasure 2: Word Intrusion: This measure tests topic coherence. A user is presented with the most probable words for a topic, plus a high probability word from another topic (the intruder). The user is asked to find the word that does not belong, and the metric is the Percentage of users who selected the intruder.\nNote: Evaluation metrics do not always agree; it is necessary to Measure what you need.\n","aliases":[],"inlineTags":[],"frontmatterTags":[],"headers":[{"heading":"6. Topic Models","level":1,"id":"6._Topic_Models_0"},{"heading":"Motivation and Core Task","level":2,"id":"Motivation_and_Core_Task_0"},{"heading":"Representation","level":2,"id":"Representation_0"},{"heading":"Latent Semantic Analysis (LSA)","level":2,"id":"Latent_Semantic_Analysis_(LSA)_0"},{"heading":"Probabilistic Models: LDA and Inference","level":2,"id":"Probabilistic_Models_LDA_and_Inference_0"},{"heading":"Latent Dirichlet Allocation (LDA)","level":3,"id":"Latent_Dirichlet_Allocation_(LDA)_0"},{"heading":"Inference","level":3,"id":"Inference_0"},{"heading":"Gibbs Sampling","level":3,"id":"Gibbs_Sampling_0"},{"heading":"Quality Measures","level":2,"id":"Quality_Measures_0"}],"links":[],"author":"","coverImageURL":".","fullURL":"natural-language-processing/06.-topic-models.html","pathToRoot":"..","attachments":["attachments/pasted-image-20251126030848.png"],"createdTime":1764122742946,"modifiedTime":1764123016632,"sourceSize":6011,"sourcePath":"Natural Language Processing/06. Topic Models.md","exportPath":"natural-language-processing/06.-topic-models.html","showInTree":true,"treeOrder":6,"backlinks":[],"type":"markdown"},"natural-language-processing/07.-sentiment-analysis.html":{"title":"07. Sentiment Analysis","icon":"","description":"<img alt=\"Pasted image 20251126031330.png\" src=\"attachments/pasted-image-20251126031330.png\" target=\"_self\">Sentiment Analysis takes a text sequence with variable length as input and outputs a sentiment label. Tasks range from narrow to broad:\nPolarity classification.\nUser rating (e.g., 1 to 5 stars).\nFeature/aspect-based sentiment analysis.\nAgreement detection.\nSubjectivity/viewpoint detection.\nThe basic Deep Learning Model uses End-to-end optimization because the Whole network is differentiable.The model generally consists of three main stages:\nEncoder: Function to represent a sequence of words as a vector.\nFeed Forward Network (FFN): Provides a better representation of the sentence content.\nClassification Layer: Outputs the final sentiment label.\nThe Encoder is composed of three components: Word Embedding, Sequential Layers, and the Aggregation Layer.\nWord Embeddings map a word to a dense vector.\nThis layer often holds the largest number of features in the whole network.\nContrast with One-hot encoding: One-hot encoding results in a large number of features and makes all words equally similar.\nTraining/Initialization: A common strategy is to use a pre-trained model with fine-tuning. A \"no layer\" approach, or Bag-of-word representation, fails because Word order does not matter (e.g., \"Mary loves John\" vs. \"John loves Mary\").\nSince context is important, a model is needed to Process word separately AND Keep the context.\nArchitectures used for sequential context include Recurrent neural networks (RNNs), Convolution neural networks (CNNs), and Attention networks.\nThis layer addresses the challenge of converting Variable input size to Fixed output size. Common methods include:\nAverage word embeddings (meanpool).\nSum word embeddings.\nMax pooling ( for the -th dimension).\nLast element. Unit: The Vanilla RNN unit takes the Current input and the Previous hidden state .\nProperties: RNNs Store history in a vector and capture Global context.\nTraining: Involves Unfolding the network over time (weights are shared across time steps) and using Backpropagation through time (BPTT).\nIssues: RNNs suffer from Vanishing gradients and Exploding gradients (often controlled with clipping).\nAn Advanced RNN Architecture motivated by the need for a Memory cell.\nMechanism: Uses 1D convolution along the time dimension, also known as Time-delayed neural networks (TDNN).\nFilters (Kernels): Act as feature extractors. A filter is a vector in the word vector space that matches a particular region of the space. Filters can be used to capture Uni-gram, Bi-gram, or Tri-gram features (depending on kernel size).\nProperties: CNNs exhibit Shift Invariance and capture Local context.\nOutput: An Aggregation layer (e.g., max-pooling) is used to Reduce to fixed length.\nCNNs vs. RNNs: CNNs view context local to the filter width, while RNNs generally look globally. Feed Forward Network (FFN): Input is a Fixed-size representation of the sentence; Output is a Fixed-size representation. The parameters are the Weights of edges between nodes. Classification Layer: Binary Classification: Uses a Single Neuron with the Sigmoid activation function.\nMulticlass Classification: Uses One neuron per class with the Softmax activation function (to produce a probability distribution) and Cross-entropy as the loss function. Since the whole network is differentiable, training uses End-to-end optimization. Strategies depend on data and model:\nRandom initialization.\nFrozen pre-trained model.\nPre-trained model with fine-tuning.\n","aliases":[],"inlineTags":[],"frontmatterTags":[],"headers":[{"heading":"7. Sentiment Analysis","level":1,"id":"7._Sentiment_Analysis_0"},{"heading":"Part I: Task Definition &amp; Challenges","level":2,"id":"Part_I_Task_Definition_&_Challenges_0"},{"heading":"1.1 Sentiment Analysis Tasks","level":3,"id":"1.1_Sentiment_Analysis_Tasks_0"},{"heading":"1.2 Challenges","level":3,"id":"1.2_Challenges_0"},{"heading":"Part II: Deep Learning Architecture Overview","level":2,"id":"Part_II_Deep_Learning_Architecture_Overview_0"},{"heading":"Part III: The Encoder Components","level":2,"id":"Part_III_The_Encoder_Components_0"},{"heading":"3.1 Input Representation: Word Embeddings","level":3,"id":"3.1_Input_Representation_Word_Embeddings_0"},{"heading":"3.2 Sequential Layer (The Need for Context)","level":3,"id":"3.2_Sequential_Layer_(The_Need_for_Context)_0"},{"heading":"3.3 Aggregation Layer","level":3,"id":"3.3_Aggregation_Layer_0"},{"heading":"Part IV: Core Sequential Models","level":2,"id":"Part_IV_Core_Sequential_Models_0"},{"heading":"4.1 Recurrent Neural Networks (RNNs)","level":3,"id":"4.1_Recurrent_Neural_Networks_(RNNs)_0"},{"heading":"4.2 Long Short-term memory (LSTM)","level":3,"id":"4.2_Long_Short-term_memory_(LSTM)_0"},{"heading":"4.3 Convolutional Neural Networks (CNNs) in NLP","level":3,"id":"4.3_Convolutional_Neural_Networks_(CNNs)_in_NLP_0"},{"heading":"Part V: Final Output and Training","level":2,"id":"Part_V_Final_Output_and_Training_0"},{"heading":"5.1 Feed Forward Network &amp; Classification Layer","level":3,"id":"5.1_Feed_Forward_Network_&_Classification_Layer_0"},{"heading":"5.2 Training Strategies","level":3,"id":"5.2_Training_Strategies_0"}],"links":[],"author":"","coverImageURL":".","fullURL":"natural-language-processing/07.-sentiment-analysis.html","pathToRoot":"..","attachments":["attachments/pasted-image-20251126031330.png"],"createdTime":1764123052269,"modifiedTime":1764123212194,"sourceSize":5639,"sourcePath":"Natural Language Processing/07. Sentiment Analysis.md","exportPath":"natural-language-processing/07.-sentiment-analysis.html","showInTree":true,"treeOrder":7,"backlinks":[],"type":"markdown"},"model-driven-software-development/01.-introduction.html":{"title":"01. Introduction","icon":"","description":"<img alt=\"Pasted image 20251126031843.png\" src=\"attachments/pasted-image-20251126031843.png\" target=\"_self\">\nGenerated by NotebookLM.\nThe primary rationale for MDSD is to manage the increasing complexity of software development. MDSD specifically targets accidental complexity (such as platform complexity). It continues the historical trend of increasing abstraction by enabling models to replace objects.The main goals of MDSD include:\nAchieving a higher level of abstraction and platform independence.\nIncreasing development speed and software quality.\nImproving reuse, avoiding redundancy, and better managing technological changes.\nAutomation through model transformations.\nModeling is a fundamental part of informatics, serving a crucial epistemological role: the idea behind scientific modeling is to represent and increase information. Knowledge and information in informatics are always processed using models.The formal definition is derived from Herbert Stachowiak’s General Model Theory.Models, according to Stachowiak, are characterized by three features:\nMapping Feature: Models are mappings from, or representations of, natural or artificial originals.\nReduction Feature: Models capture only the attributes relevant to their users/creators, generally not all attributes of the original.\nPragmatic Feature: Models fulfill their function only for particular subjects (users), time intervals, and specific operations.\nIn MDSD, the system under development is the original, and different models represent different attributes. For example:\nA component model (PCM) represents the software architecture.\nA class diagram (UML) represents the object-oriented structure.\nProgram code represents the structure and behaviour (execution semantics) of the system.\nPerformance simulation results represent timing behaviour and resource usage.\nThese terms distinguish the scope and standardization level of model usage in development:<br><img alt=\"Pasted image 20251126031934.png\" src=\"attachments/pasted-image-20251126031934.png\" target=\"_self\">MDA is an OMG initiative proposing non-proprietary standards to realize model-driven development using automated transformations. The process is defined by three main model types:\nComputation Independent Model (CIM): Describes requirements and the system environment; details of the system are hidden. (Example: UML use case diagram).\nPlatform Independent Model (PIM): Focuses on system operation; platform-specific details are hidden. This part does not change between platforms. (Example: A component model).\nPlatform Specific Model (PSM): Adds focus on the details of using a specific platform. (Example: A class diagram tailored to a platform).\nApplication:\nThe MDA process involves automated transformations between PIMs and PSMs, often incorporating a separate Platform Model. Ultimately, the PSM is transformed into Code. The vision is that specifications should be machine readable and that models should be transformed into other models. While the ideal vision suggests that domain experts create models from which code is generated, the current pragmatic MDSD approach often relies heavily on partial code generation and separates generic, repetitive, and individual code.","aliases":[],"inlineTags":[],"frontmatterTags":[],"headers":[{"heading":"1. Introduction","level":1,"id":"1._Introduction_0"},{"heading":"Q&amp;A","level":2,"id":"Q&A_0"},{"heading":"1. What is the rationale behind Model-Driven Software Development (MDSD)?","level":3,"id":"1._What_is_the_rationale_behind_Model-Driven_Software_Development_(MDSD)?_0"},{"heading":"2. What is the definition of the term model?","level":3,"id":"2._What_is_the_definition_of_the_term_model?_0"},{"heading":"3. Identify properties of models in examples","level":3,"id":"3._Identify_properties_of_models_in_examples_0"},{"heading":"4. What is the difference between MDE, MDSD, and MDA?","level":3,"id":"4._What_is_the_difference_between_MDE,_MDSD,_and_MDA?_0"},{"heading":"5. What is the MDA process and how is it applied in software development?","level":3,"id":"5._What_is_the_MDA_process_and_how_is_it_applied_in_software_development?_0"}],"links":[],"author":"","coverImageURL":".","fullURL":"model-driven-software-development/01.-introduction.html","pathToRoot":"..","attachments":["attachments/pasted-image-20251126031843.png","attachments/pasted-image-20251126031934.png"],"createdTime":1764123454517,"modifiedTime":1764171898169,"sourceSize":4386,"sourcePath":"Model-Driven Software Development/01. Introduction.md","exportPath":"model-driven-software-development/01.-introduction.html","showInTree":true,"treeOrder":1,"backlinks":[],"type":"markdown"},"model-driven-software-development/02.-metamodelling.html":{"title":"02. Metamodelling","icon":"","description":"<img alt=\"Pasted image 20251126032239.png\" src=\"attachments/pasted-image-20251126032239.png\" target=\"_self\">\nGenerated by NotebookLM.\nMetamodels are special models that make statements about the process of modelling. They describe the possible structure of other models. The originals that a metamodel represents are themselves models. Metamodels are usually prescriptive, meaning they are created before any originals exist, and the creation of these originals is called instantiation.To completely specify a metamodel, its definition must cover four areas: abstract syntax, concrete syntax, static semantics, and dynamic semantics.\nAbstract Syntax: The abstract syntax definition describes the structure of models, specifying which constructs, properties, and relations a model consists of. This description is independent of how these constructs are visually presented.\nConcrete Syntax: This describes the presentation (e.g., graphical, textual, or file format) of the constructs defined in the abstract syntax. At least one concrete syntax definition is required, but there can be arbitrarily many.\nStatic Semantics: This describes modelling rules and constraints (such as \"no two stations may have the same name\") that cannot be expressed in the abstract syntax definition. These constraints are often formulated using languages like OCL, and checking them should be a decidable problem.\nDynamic Semantics: This describes the meaning of the constructs. This definition is often expressed in natural language, although it is possible to formally define dynamic semantics by mapping the metamodel to a formal language with defined semantics, such as finite automata or Petri nets.\nModelling layers represent the hierarchy between models and metamodels. Since a metamodel is itself a model, a metamodel for metamodels (a meta-metamodel) can be defined. In theory, an arbitrary number of layers can be constructed, but in practice, the most abstract layer will eventually become self-descriptive. Approaches exist with a fixed number of layers (e.g., UML) and with variable numbers (multi-level modelling).The four layers often used, particularly in UML and MOF, are distinguished by what they represent or instantiate:\nM3 (Meta-Metamodel): Contains concepts that define the structure of M2 (the metamodel layer), such as Class and Attribute. The MOF model is located here.\nM2 (Metamodel): Contains concepts that define the structure of M1 (the user model layer), such as Locomotive or Track vehicle. UML 2 is an example of an M2 layer.\nM1 (Model): Contains concrete instances that conform to the M2 structure, such as a specific :Locomotive with defined property values (e.g., series=215).\nM0 (Original): Represents the artifacts or components of the real world being modelled (e.g., the actual train).\nUML (Unified Modelling Language) is an OMG standard that defines a metamodel for software engineering purposes. It is a standard specifying modeling concepts and their relations. It is a graphical standard that includes notational conventions and the UML Diagram Interchange format. While its specification includes semantics definitions in natural language, UML is not a metamodel with formally defined semantics. In version 2.5, UML unified its Superstructure (user-applied constructs) and Infrastructure (basic language constructs) into a single document.UML's foundation is intrinsically linked to the Meta-Object Facility (MOF):\nMOF as the M3 Layer: MOF is an OMG standard metadata architecture that serves as the meta-metamodel (M3) for UML.\nMOF Specification: MOF includes Complete MOF (CMOF), which is the metamodel used to specify other metamodels, including UML 2.\nCyclic Dependency: There is a cyclic dependency between CMOF and UML, as CMOF is built from Essential MOF (EMOF) and selected elements of the UML metamodel, and simultaneously, UML is specified by CMOF.\nUML diagrams are used to model systems, primarily in software engineering, though they can be applied to non-software domains. Key diagrams used to describe systems include:\nClass Diagrams: Used to specify domain models and object-oriented designs, showing classes, attributes, operations, and relationships like associations and inheritance.\nObject Diagrams: Used to describe the system at a specific point in time by showing instances of classes (instance specifications) and the links between these instances.\nUse Case Diagrams: Used to specify the functional requirements of a system, detailing actors (users) and the use cases (functions) they interact with.\nActivity Diagrams: Illustrate the flow of an operation or a workflow by showing activities, actions, and control flow.\nSequence Diagrams: Describe the time-ordered message interactions and collaborations between objects or components (lifelines) in a system.\nComponent Diagrams: Describe the system's high-level physical structure by showing components (such as WebUI or UserManagement) and their dependencies.\n","aliases":[],"inlineTags":[],"frontmatterTags":[],"headers":[{"heading":"2. Metamodelling","level":1,"id":"2._Metamodelling_0"},{"heading":"Q&amp;A","level":2,"id":"Q&A_0"},{"heading":"1. What's the concept metamodel","level":3,"id":"1._What's_the_concept_metamodel_0"},{"heading":"2. Define metamodels with their syntax and semantics","level":3,"id":"2._Define_metamodels_with_their_syntax_and_semantics_0"},{"heading":"3. What's modelling layers and distinguish them","level":3,"id":"3._What's_modelling_layers_and_distinguish_them_0"},{"heading":"4. What's the foundations of UML and its relation to the MOF standard","level":3,"id":"4._What's_the_foundations_of_UML_and_its_relation_to_the_MOF_standard_0"},{"heading":"5. describe systems with the help of UML diagrams","level":3,"id":"5._describe_systems_with_the_help_of_UML_diagrams_0"}],"links":[],"author":"","coverImageURL":".","fullURL":"model-driven-software-development/02.-metamodelling.html","pathToRoot":"..","attachments":["attachments/pasted-image-20251126032239.png"],"createdTime":1764123583976,"modifiedTime":1764123778938,"sourceSize":5382,"sourcePath":"Model-Driven Software Development/02. Metamodelling.md","exportPath":"model-driven-software-development/02.-metamodelling.html","showInTree":true,"treeOrder":2,"backlinks":[],"type":"markdown"},"model-driven-software-development/03.-advanced-uml.html":{"title":"03. Advanced UML","icon":"","description":"\nCore PrimitiveTypes, pre-defined types Integer, Boolean, String, UnlimitedNatural Basic, central notions such as class, attributes, operation, package Abstractions,&nbsp;concepts such as&nbsp;generalization, instantiation, restriction, cardinality, etc. Generalization Generalization sets overlapping (default) / disjoint incomplete (default) / complete Power types Constructs, base concept - association Profiles stereotype metaclass Generated by NotebookLM.\nThe Unified Modeling Language (UML) utilizes profiles and stereotypes as built-in extension mechanisms because UML, while a general-purpose language, is not ideal for all purposes.UML Profiles: A profile is applied to extend a reference metamodel (such as UML) or to adapt it to a specific platform, domain, or method.\nDefinition and Constraint: A profile is a package that extends elements of the type Metaclass and may add additional constraints. Profiles are intrinsically tied to a reference metamodel created using the Meta Object Facility (MOF) (e.g., UML or PCM) and cannot be defined as standalone packages.\nApplication: Profile application is a type of package import. One or more profiles can be applied to a package. Profiles are optional, but if application is mandatory, the keyword {required} can be used.\nContent: A profile can contain data types, classes, stereotypes, primitive types, and enumerations. It also has the ability to re-use or extend parts of other profiles.\nUML Stereotypes: Stereotypes are considered the most crucial extension elements.\nDefinition: A stereotype is defined as a class within the profiles package that specifies how a class in the reference metamodel can be extended.\nApplication (Extension): When a profile is applied, the stereotypes it contains may be applied to classes. The application of a stereotype to a class is specifically termed extension, and it is graphically represented by a solid, filled arrow.\nProperties: Stereotypes can include attributes, which are referred to as tags. The corresponding values of a stereotype instance are known as tagged values. Stereotypes cannot be extended by other stereotypes.\n<img alt=\"Pasted image 20251126032448.png\" src=\"attachments/pasted-image-20251126032448.png\" target=\"_self\">The decision between extending the existing UML metamodel via profiles or creating a separate custom MOF-based metamodel often positions profiles as a middle path.Creating a UML Profile (Extension): Profiles are considered a \"light-weight\" method for adapting and extending existing metamodels at level M2. This approach is advantageous when:\nReuse is prioritized: Concepts such as components, classes, and others can be reused from the existing UML structure.\nValidity is critical: Models remain valid UML instances. The semantics of UML are also valid for the extended models.\nDynamic Application: Profiles can be applied dynamically to models.\nTool Compatibility: Existing UML tools can still be utilized for modeling the extended models.\nCreating a Custom Metamodel: This approach is necessary when greater flexibility and complete freedom in modeling are required.\nHigh Flexibility: Custom metamodels offer more flexibility compared to profiles.\nTotal Freedom: They provide total freedom in modeling.\nDrawbacks and Judgment:\nProfile Limitations: Profiles offer lower flexibility because all concepts of UML are still inherited and remain valid, even if those concepts have no meaning within the specific domain being modeled. Furthermore, profiles cannot modify existing metamodels; they can only extend them via stereotypes.\nCustom Metamodel Limitations: This approach leads to little re-use, meaning concepts (like the component concept) must be re-defined entirely.\nUltimately, there is no universal guideline for this decision; rather, it hinges entirely on the specific set of adaptations necessary for the existing reference metamodel.The basic structure of UML 2.4 is defined within the UML Infrastructure Library. This library defines a meta-language core that is employed to define UML itself and other related metamodels.The Infrastructure Library consists of two core packages: Core: Contains the basic concepts necessary for metamodeling. The Core package is further divided into several sub-packages: PrimitiveTypes: Defines pre-defined types such as Boolean, Integer, String, and UnlimitedNatural.\nBasic: Contains central notions like package, class, operation, and attribute.\nAbstractions: Includes concepts such as instantiation, generalization, cardinality, and restriction.\nConstructs: Contains the base concept of association. Profiles: Contains the necessary mechanisms for adaptation. This architecture ensures the architectural alignment of MOF, UML, and XMI (used for exchanging models).UML generalization techniques center on Generalization Sets, which define specific partitions of generalization associations. Generalization (or Inheritance) is a taxonomic relation where a more special classifier inherits all features of the more general classifier, meaning every instance of the special classifier is also an indirect instance of the general classifier.There are four partitionings available in UML 2 that can be used within a Generalization Set:Application of Generalization Sets: Generalization sets are utilized to model inheritance hierarchies that possess multiple dimensions and precise restrictions.For instance, consider a Locomotive class:\nMotive Power: The first dimension, motive power, might partition Locomotive into Steam Locomotive and Motor Locomotive. This set could be labeled {disjoint, complete} to indicate that a locomotive must belong to exactly one of these two categories.\nMotor Type: The Motor Locomotive class could then be partitioned by motor type into Electric Locomotive and Internal Combustion Locomotive. This set might be labeled {overlapping, complete}, indicating that while all types are specified, a locomotive could potentially belong to both (e.g., a hybrid locomotive).\nA power type is defined as a class whose instances are subclasses.\nInspiration: The concept was derived from the mathematical notion of a power set, which is a set whose instances are subsets.\nRelation to Generalization Sets: A Generalization Set can optionally be linked to a type, and this type is then referred to as a power type.\nFunction: The instances of this power type are the subclasses of the class that the generalization set describes in further detail.\nLayer Limitation: Power types are useful because they can help circumvent the restriction inherent in modeling with four layers (M0–M3).\nThe UML specification acknowledges the definition but does not provide an explanation on how to implement or check the power type mechanism.","aliases":[],"inlineTags":[],"frontmatterTags":[],"headers":[{"heading":"3. Advanced UML","level":1,"id":"3._Advanced_UML_0"},{"heading":"UML Infrastructure","level":2,"id":"UML_Infrastructure_0"},{"heading":"Q&amp;A","level":2,"id":"Q&A_0"},{"heading":"1. How to apply the extension mechanisms UML profiles and stereotypes","level":3,"id":"1._How_to_apply_the_extension_mechanisms_UML_profiles_and_stereotypes_0"},{"heading":"2. Judge in which case either an extension of the UML metamodel or the creation of a separate metamodel makes sense","level":3,"id":"2._Judge_in_which_case_either_an_extension_of_the_UML_metamodel_or_the_creation_of_a_separate_metamodel_makes_sense_0"},{"heading":"3. What's the basic structure of UML 2.4","level":3,"id":"3._What's_the_basic_structure_of_UML_2.4_0"},{"heading":"4. What are UML generalization techniques, and you can apply them","level":3,"id":"4._What_are_UML_generalization_techniques,_and_you_can_apply_them_0"},{"heading":"5. What are UML power types","level":3,"id":"5._What_are_UML_power_types_0"}],"links":[],"author":"","coverImageURL":".","fullURL":"model-driven-software-development/03.-advanced-uml.html","pathToRoot":"..","attachments":["attachments/pasted-image-20251126032448.png"],"createdTime":1764123788361,"modifiedTime":1764123889448,"sourceSize":8073,"sourcePath":"Model-Driven Software Development/03. Advanced UML.md","exportPath":"model-driven-software-development/03.-advanced-uml.html","showInTree":true,"treeOrder":3,"backlinks":[],"type":"markdown"},"software-test-&-quality-management/01.-introduction.html":{"title":"01. Introduction","icon":"","description":"Software frequently fails, often resulting in severe consequences.\nExamples of software failures include: 22 people were wrongly arrested in Australia due to failures in a new NZ $54.5 million courts computer system. A software failure caused 12 hours of delays for UK fliers. Toyota recalled the Newest Priuses over software. Elon Musk's Starlink experienced a global outage due to software failure.\nExpensive Historical Failures: NASA Earth Observation Satellites (1979-1985): The Ozone hole was not detected for 7 years. The reason was a software failure that interpreted the change of the ozone layer as sensor drift, which was then automatically averaged out by zero point correction.\nAriane 5 (1996): The rocket experienced self-destruction 39 seconds after takeoff on its maiden flight. The failure was caused by reusing the position control software of Ariane 4 without testing, which led to a conversion error.\nGemini V Manned NASA Space Capsule: Missed its landing spot by 160 kilometers because the software did not consider the earth’s rotation around the sun. Origin of the Term \"Bug\": The term originated from a moth found in the Mark II computer which caused an error.\n<img alt=\"Screenshot 2025-12-01 at 02.02.01.png\" src=\"attachments/screenshot-2025-12-01-at-02.02.01.png\" target=\"_self\">\nQuality: The degree to which a component, system, or process meets specified requirements and/or user/customer needs and expectations [20, ISO 24765].\nSoftware Quality: The totality of functionality and features of a software product that bear on its ability to satisfy stated or implied needs [20, After ISO 9126].\nQuality Requirements: These are part of the non-functional requirements in the functional specification document. Not all quality properties can be fulfilled equally (e.g., a tradeoff may exist between efficiency and maintainability), so priorities must be defined.\nSoftware quality is measured across eight main characteristics:\nFunctionality: The presence and appropriateness of functions for specified tasks. Includes Suitability, Accuracy (delivering the right results with the needed precision) [22, ISO 9126], and Completeness.\nReliability: The degree to which a system performs specified functions under specified conditions for a specified time [23, after ISO 25010]. Includes Maturity, Fault Tolerance (maintaining performance after a failure), and Recoverability (re-establishing performance and recovering data).\nUsability: Characteristics referring to the effort needed to use the software and the individual rating by users. Includes Understandability, Learnability, and Operability.\nSecurity: The suitability to prevent unauthorized access, protecting information and data based on authorization levels [27, ISO 25010].\nCompatibility: The degree to which a system can exchange information with others. Includes Interoperability (suitability to collaborate with preexisting systems) [28, ISO 25010].\nPerformance Efficiency: The degree to which a system uses time, resources, and capacity when accomplishing its designated functions [33, ISO 25010].\nChangeability (Maintainability): The effort required to implement specified modifications. Includes Analyzability, Modifiability, Stability (risk of unexpected effects of changes), and Testability (effectiveness and efficiency of testing the component/system) [32, ISO 25010].\nPortability: The suitability of the software to be ported from one environment to another. Includes Adaptability, Installability, and Replaceability.\n<br><img alt=\"Pasted image 20251201022626.png\" src=\"attachments/pasted-image-20251201022626.png\" target=\"_self\">\nSQA involves Constructive measures (Guidelines, Models) and Analytical measures (Audits, Testing).\nStatic Testing: The program is not executed (e.g., Reviews, Static Analysis).\nDynamic Testing: The program is executed (e.g., White-Box Testing, Black-Box Testing).\nTesting’s Role: Testing measures software quality and indirectly increases it by ensuring failures are detected and fixed before release. Inability to Prove Absence of Bugs: \"Program testing can be used to show the presence of bugs, but never to show their absence!\" (Edsger W. Dijkstra, 1970).\nComplete Testing is Not Possible: For a program accepting three 16-bit integer inputs, performing a full test (testing possible combinations) at a speed of 100,000 combinations per second would take about 90 years. This demonstrates that even a very simple program has many potential test cases. Start as Early as Possible: Testing is not just a late phase; the earlier a failure is found, the less the costs to fix it.\nClustering of Failures: A small amount of modules often holds a high rate of overall failures (the 80:20 rule). Test effort should be proportional to the expected failure density.\nPesticide Paradox: Simply repeating tests brings no new information; tests must be checked, modified, and updated. Repetitions have no efficiency.\nFallacy: Assuming that finding no failures means the software is viable is a fallacy, as the software may still fail to fit the users' expectations. Effort in Reality: Testing effort typically constitutes 25% - 50% of the total development effort. Successful testing (finding failures) reduces the overall development costs.\nPrioritizing Test Cases: Testing is restricted by resources, especially time. Test cases must therefore be prioritized.\nPrioritization Basis: Prioritization can be based upon Expected failure severity, Probability of occurrence, or the combination of both (Risk = failure severity * probability of occurrence). Priorities must be modifiable.\n","aliases":[],"inlineTags":[],"frontmatterTags":[],"headers":[{"heading":"1. Introduction","level":1,"id":"1._Introduction_0"},{"heading":"Motivation and Software Failures","level":2,"id":"Motivation_and_Software_Failures_0"},{"heading":"Terminology","level":2,"id":"Terminology_0"},{"heading":"Software Quality","level":2,"id":"Software_Quality_0"},{"heading":"Definitions and Requirements","level":3,"id":"Definitions_and_Requirements_0"},{"heading":"ISO 25010 Product Quality Characteristics","level":3,"id":"ISO_25010_Product_Quality_Characteristics_0"},{"heading":"Software Quality Assurance (SQA)","level":3,"id":"Software_Quality_Assurance_(SQA)_0"},{"heading":"Fundamentals of Testing","level":2,"id":"Fundamentals_of_Testing_0"},{"heading":"Testing Limitations","level":3,"id":"Testing_Limitations_0"},{"heading":"Testing Principles","level":3,"id":"Testing_Principles_0"},{"heading":"Testing Effort and Priorities","level":3,"id":"Testing_Effort_and_Priorities_0"}],"links":[],"author":"","coverImageURL":".","fullURL":"software-test-&-quality-management/01.-introduction.html","pathToRoot":"..","attachments":["attachments/screenshot-2025-12-01-at-02.02.01.png","attachments/pasted-image-20251201022626.png"],"createdTime":1764550992477,"modifiedTime":1764555140419,"sourceSize":9284,"sourcePath":"Software Test & Quality Management/01. Introduction.md","exportPath":"software-test-&-quality-management/01.-introduction.html","showInTree":true,"treeOrder":13,"backlinks":[],"type":"markdown"},"software-test-&-quality-management/02.-testing-process.html":{"title":"02. Testing Process","icon":"","description":"sThe General Testing Process is tightly interconnected with software development but remains an independent process. This process must be properly adapted for every testing phase. Every phase requires a specific testing schedule, and testing must be split into small tasks or activities.Contextual Factors Affecting the Process:\nUsed software development model.\nPossible testing level and test types.\nProduct and project risks.\nBusiness domain.\nCompany restrictions (budget, resources, deadlines, contractual and regulatory requirements).\nGuidelines and practices of the company, and stipulated internal and external standards.\nThe Activities (Cyclical Flow):The process involves Test Planning, Test Analysis, Test Design, Test Implementation, Test Execution, Test Completion, and continuous Test Monitoring and Control. Some activities are executed in parallel.<img alt=\"Screenshot 2025-12-01 at 03.45.29.png\" src=\"attachments/screenshot-2025-12-01-at-03.45.29.png\" target=\"_self\">Traceability:Traceability is the degree to which a relationship can be established between two or more work products (ISO 19506).\nVertical traceability: Tracing requirements through layers of development documentation to components.\nHorizontal traceability: Tracing requirements for a test level through the layers of test documentation (e.g., test plan, test design specification, test procedure specification).\nTraceability supports evaluation of test coverage, impact analysis of requirements, increase comprehensibility of reports, and IT-Governance-criteria.Testing in an automotive/Cyber-Physical Systems (CPS) context is complex because software runs on distributed Electronic Control Units (ECUs). Testing must cover both software and hardware, necessitating new steps to check integration of software onto hardware, hardware with hardware, etc.. This is often realized using “in-the-loop” processes.Test cases can be categorized based on their intended goal:\nPositive-Test: Checks for the specified and delivered results and reactions.\nNegative-Test: Checks expected false inputs and exceptional behavior. (It can be challenging to create certain effects, like network overload, to test this behavior).\nRobustness-Test: Checks unexpected test cases that are not exception handled (catastrophical). Abstract (Logical) Test Cases: Test cases defined without concrete values for input data and expected results. They are helpful to document the scope and can be used with different concrete data.\nConcrete Test Cases: Use specific, defined input values and corresponding expected results.\nTest cases in general should only consist of a small number of steps.After executing a test case, it must be decided whether a failure was found by comparing the actual result to the expected result (desired result).\nRequirement: The expected result must be specified for every test case beforehand.\nTest Oracles: These are the sources that must be consulted to gather this information and deliver the desired results. Expected results are derived from the specification.\nPossibilities for Deriving Expected Values:\nTester Derivation: The tester derives the expected value from the input value based on the specification (most common practice).\nExecutable Prototype: If a formal specification is available, an executable prototype can be generated, and its results can be used as the expected results for the real Software Under Test (SUT).\nBack-to-back Testing: The SUT is independently implemented by several developer groups and all versions are tested against each other with the same input values. If results differ, at least one version has a failure.\nOther Oracles: User manuals, (tested) predecessor versions, or programs with similar functions.\nSystem Itself: Using the system itself (e.g., creating user profiles) is considered the worst case.\nTolerance/Plausibility: When expected values cannot always be predicted or computed, a tolerance range must be defined, or plausibility must be checked. Experience is always important.\nTesting is defined as an extremely creative and intellectually challenging task. A core psychological challenge is that developers are human (\"Errare humanum est – but who does like to admit?\"). Development is constructive, whereas testing can be perceived as destructive.\nTests can be performed by the developer, colleagues within the same project, persons from other departments, or persons from other companies.\nTesting can/should always be performed tool supported.\nAllocation depends on the product and project.\nIt is important to combine independent testers and developers to test properly.\nFailures must be reported to developers and management. Reporting must use a neutral, objective, and constructive reporting style. Undisturbed and open communication is essential.Reproducibility is important. This requires documenting the testing environment and differences relative to the development environment. Mutual appreciation is also necessary.","aliases":[],"inlineTags":[],"frontmatterTags":[],"headers":[{"heading":"2. Testing Process","level":1,"id":"2._Testing_Process_0"},{"heading":"General Testing Process","level":2,"id":"General_Testing_Process_0"},{"heading":"In-the-loop Processes","level":2,"id":"In-the-loop_Processes_0"},{"heading":"Test Cases and Test Oracles","level":2,"id":"Test_Cases_and_Test_Oracles_0"},{"heading":"Test Case Criteria","level":3,"id":"Test_Case_Criteria_0"},{"heading":"Abstract vs. Concrete Test Cases","level":3,"id":"Abstract_vs._Concrete_Test_Cases_0"},{"heading":"Test Oracles","level":3,"id":"Test_Oracles_0"},{"heading":"Psychology of Testing","level":2,"id":"Psychology_of_Testing_0"},{"heading":"Developer Testing","level":3,"id":"Developer_Testing_0"},{"heading":"Independent Test Team","level":3,"id":"Independent_Test_Team_0"},{"heading":"Optimal Allocation","level":3,"id":"Optimal_Allocation_0"},{"heading":"Reporting Failures","level":3,"id":"Reporting_Failures_0"}],"links":[],"author":"","coverImageURL":".","fullURL":"software-test-&-quality-management/02.-testing-process.html","pathToRoot":"..","attachments":["attachments/screenshot-2025-12-01-at-03.45.29.png"],"createdTime":1764555236830,"modifiedTime":1764817089596,"sourceSize":10931,"sourcePath":"Software Test & Quality Management/02. Testing Process.md","exportPath":"software-test-&-quality-management/02.-testing-process.html","showInTree":true,"treeOrder":14,"backlinks":[],"type":"markdown"},"software-test-&-quality-management/03.-testing-phrases.html":{"title":"03. Testing Phrases","icon":"","description":"A software development lifecycle model describes the types of activities for each phase in a software project and how they are related chronologically and logically. Models fall into two main categories: Sequential development models and Iterative-Incremental development models.<img alt=\"Pasted image 20251204035604.png\" src=\"attachments/pasted-image-20251204035604.png\" target=\"_self\">The V-Model connects development phases on the left branch (Construction Phases) with testing phases on the right branch (Test Phases).Key Points:\nThe steps on the right branch represent test execution.\nAssociated test preparation (planning, specification) starts earlier and runs parallel to the development steps.\nThe rule of thumb is that finding failures on the same level of abstraction on which they are created is easiest.\n<br><img alt=\"Pasted image 20251204035633.png\" src=\"attachments/pasted-image-20251204035633.png\" target=\"_self\">Development takes place in small steps; the system is created through a planned series of versions and intermediate deliveries (increments).\nIncremental: Goals are specified from the beginning, and finished parts are assumed not to be changed anymore.\nIterative: The system emerges over time; each iteration (cycle) typically specifies, designs, implements, and tests a group of features, delivering a working software. Iterations can include changes to finished features.\nTesting in IIDMs: Construction phases and test phases interleave. Continuous integration tests and regression tests are necessary. Verification and validation are possible for each increment. Phase: The first testing phase.\nTest Object: Implemented software units (modules, classes) tested in isolation to exclude external influences, allowing failures to be clearly traced.\nGoals: Check if the component fulfills its specified functionality (input/output behavior). Other criteria include Robustness (capability to catch failure situations and keep working), Efficiency (economic resource usage, reaction times), and Maintainability (code structure, documentation).\nStrategy and Responsibility: Often performed by developers (developer test). Since source code is known, testing is often done as white-box test.\nEnvironment: Requires a Driver (calls services of the test object) and Placeholder (Dummy/Stub) (simulates services imported by the test object). Phase: The second testing phase, performed after unit testing. Components must be tested and failures fixed beforehand.\nGoal: To test if communication between components works. The primary goal is to find faults in interfaces and interaction between integrated components.\nFault Types: Interface incompatibility, missing data, contradictory interpretation of specification, and timing problems (data communicated too late or at the wrong time).\nTest Basis: Software design, System design, Sequence Diagrams, and specification of interfaces and communication protocols.\nTest Environment: Needs a Driver and Monitors to observe the interfaces and data traffic. Phase: The third test phase, performed after everything is integrated.\nTest Object: The completely integrated system.\nGoal: Test the system as a whole from the customer’s point of view to determine if it meets the specified system requirements. This involves Verification (system behavior meets design) and Validation (system is complete and works as expected).\nTest Basis: System and Software requirements specification, Use cases, and User stories.\nTest Environment: Should be very close to the real production environment, using real hardware and software products (instead of drivers and dummies).\nProblems: Vague customer specifications, or missing decisions regarding specified requirements. Phase: The final test phase; it focuses on the view and opinion of the customer.\nFocus: The focus is on gaining trust in the product, not failure finding. It is typically performed at the customer’s location.\nThe Agile Manifesto values working software, customer collaboration, and responding to change.\nTesting is embedded into the single sprints.\nThe team should choose suitable techniques, and test automation (CI/CD tool chains) should be introduced.\nManual testing should be viewed as exploratory testing (rapid cycle through test planning, without fixed test specifications).\nTest automation is very important in all testing phases.\nContinuous Integration (CI): Integrate and test changes frequently (after no more than a couple of hours).\nTest First Programming (Test-Driven-Development): Writing a failing automated test before changing any code, then improving the code until all tests pass.\nPair Programming: Writing all production code with two people at one machine.\nIncremental Design: Investing in the design of the system every day. Definition of Ready (DoR): A checklist used to create user stories and quality assurance. A story is ready only if test cases can be formulated and the expected results are clear.\nDefinition of Done (DoD): A checklist defining the goals for achieving a story. It specifies the testing goals, necessary testing techniques, test coverage, and test end criteria, ensuring product quality and customer satisfaction.\n","aliases":[],"inlineTags":[],"frontmatterTags":[],"headers":[{"heading":"3. Testing Phrases","level":1,"id":"3._Testing_Phrases_0"},{"heading":"I. Software Development Models and Testing","level":2,"id":"I._Software_Development_Models_and_Testing_0"},{"heading":"A. V-Model (Sequential Development Model)","level":3,"id":"A._V-Model_(Sequential_Development_Model)_0"},{"heading":"B. Iterative-Incremental Development Models (IIDMs)","level":3,"id":"B._Iterative-Incremental_Development_Models_(IIDMs)_0"},{"heading":"II. Core Testing Phases","level":2,"id":"II._Core_Testing_Phases_0"},{"heading":"A. Unit Testing (Component Testing)","level":3,"id":"A._Unit_Testing_(Component_Testing)_0"},{"heading":"B. Integration Testing","level":3,"id":"B._Integration_Testing_0"},{"heading":"C. System Testing","level":3,"id":"C._System_Testing_0"},{"heading":"D. Acceptance Testing","level":3,"id":"D._Acceptance_Testing_0"},{"heading":"III. Agile Testing in Scrum","level":2,"id":"III._Agile_Testing_in_Scrum_0"},{"heading":"A. Testing in Scrum","level":3,"id":"A._Testing_in_Scrum_0"},{"heading":"B. Agile Techniques","level":3,"id":"B._Agile_Techniques_0"},{"heading":"C. Agile Planning Definitions","level":3,"id":"C._Agile_Planning_Definitions_0"}],"links":[],"author":"","coverImageURL":".","fullURL":"software-test-&-quality-management/03.-testing-phrases.html","pathToRoot":"..","attachments":["attachments/pasted-image-20251204035604.png","attachments/pasted-image-20251204035633.png"],"createdTime":1764557647253,"modifiedTime":1764817054510,"sourceSize":8003,"sourcePath":"Software Test & Quality Management/03. Testing Phrases.md","exportPath":"software-test-&-quality-management/03.-testing-phrases.html","showInTree":true,"treeOrder":15,"backlinks":[],"type":"markdown"},"software-test-&-quality-management/04.-static-testing.html":{"title":"04. Static Testing","icon":"","description":"Static testing is the Analytical component within Software Quality Assurance (SQA).The primary goal of static testing is to find faults within a document by intensely observing the test object.\nFault Types: This includes violation of specifications or standards, errors in requirements and/or design, insufficient maintainability, wrong interface specifications, and evidence of project plan violation.\nBasic Idea: Prevention.\nCore Advantage: Detect faults and discrepancies as early as possible, because the earlier bugs are found, the less the effort to fix them.\nResult Use: Observations are used to improve the development process.\nReviews are the broad term for static inspection procedures that are performed by humans. Reviews are often the only possibility to check the semantics of a document.\nPlanning: Define the scope, estimate effort and timeframe, identify review characteristics, select participants and allocate roles, and define entry and exit criteria for more formal review types.\nInitiate Review: Distribute the work product and other material (e.g., issue log forms, checklists, related work products), and explain the scope, objectives, process, and roles to the participants. The review team needs additional data, such as guidelines or standards, to determine if a deviation or fault is present.\nIndividual Review: Every person on the team prepares individually for the session. Reviewers examine the document closely, potentially using checklists or selecting additional documents to restrict the review to certain aspects.\nIssue Communication and Analysis: Potential defects are communicated (e.g., in a review session), analyzed, and assigned ownership/status. Review findings are evaluated against the exit criteria. Review Sessions: Are guided by a moderator. Sessions are often fixed for a certain timespan (maximum 2 hours). The goal is the assessment of the review object with respect to compliance and standards. The review team gives a recommendation (Accept, Accept with changes, or Reject—requiring another review). Findings can be weighted (e.g., Critical fault, Main fault, Side fault). Fixing and Reporting: Create defect reports, fix defects (typically by the author), record the updated status of defects (in formal reviews), gather metrics (for formal reviews), and accept the work product once exit criteria are met.\nReviewers use these techniques during the preparation phase:\nAd-hoc Review: Little or no guidance, high dependence on reviewer’s skill, may lead to many duplicate reports.\nChecklist-based Review: A systematic technique where issues are detected based on checklists derived from experiences and potential defects. Checklists should be regularly maintained.\nScenario-based Reviews: Reviewers assess the work product based on scenarios (e.g., expected usage) and perform \"dry runs\".\nRole-based Reviews: Evaluate the work product from the perspective of individual stakeholder roles (e.g., specific end user types, administrators, or testers).\nPerspective-based Reading (PBR): The most effective general technique for reviewing requirements and technical work products. It is a mix of scenario-based and role-based review, where the reviewer takes on different stakeholder viewpoints (e.g., End user, Marketing, Designer, Tester).\nKey roles are defined within the review process:\nManagement: Responsible for planning, deciding on execution, assigning staff/budget, and monitoring cost-effectiveness.\nReview Leader: Takes overall responsibility, decides involvement, and organizes the time/place.\nModerator: Leads the session, ensures effective running, acts as an intermediary, must be free of prejudices, and cannot be a reviewer or the recorder.\nAuthor: Creates the reviewed document and fixes the defects found.\nReviewer (Inspector): Identifies potential defects, representing different perspectives (e.g., tester, user, business analyst).\nRecorder: Documents all results, problems, open points, and decisions.\nReviews range from informal to very formal, depending on factors like development process maturity or legal requirements.\nInformal Review: Low formalization; main purpose is detecting potential defects; commonly used in agile development.\nWalkthrough: A manual, informal method where the author presents the document to the reviewers in a meeting. The author often acts as the moderator. Main purposes include finding defects and improving the software product.\nTechnical Review: Reviewers are technical peers or experts. Main purposes are to gain consensus and detect potential defects. Individual preparation is required, but the review meeting is optional.\nInspection: Highest formalization. Follows a defined process with formal documented outputs based on rules and checklists, uses clearly defined roles, and specifies entry and exit criteria. Metrics are collected and used to improve the entire software development process.\nReviews can save real money:\nCost Efficiency: Reviews cost about 10%–15% of the overall budget but can save between 14% and 25% (even with review costs included). Failure-costs can be reduced by up to 75%.\nDefect Detection: If consistently used, about 70% of document faults can be revealed.\nOther Advantages: Shortened development time, reduced effort for dynamic testing, and knowledge transfer is facilitated as reviews are performed in teams.\nSoftware measurement quantifies and measures software processes and product features and their relationships.Measurements support three assignments:\nUnderstand: By exposing and quantifying features.\nControl: Analyzing previous experiences and adjusting future projects accordingly.\nImprove: Coherence between processes and achieved goals manifest as principles for future project planning.\nMetrics are measurements of certain features of software products, projects, and processes, used to assess, plan, and monitor.\nProduct Measures: Focus on system characteristics (e.g., Size, Complexity, Reliability, Maintainability).\nProject Measures: Focus on resources (e.g., Number of developers, Price, Speed).\nProcess Measures: Focus on development and maintenance (e.g., Duration, Effort, Cost, Failure reports, Number of releases).\nStatic Measures: Measure a feature at a certain point in time.\nDynamic Measures: Measure the development of a feature over time.\n","aliases":[],"inlineTags":[],"frontmatterTags":[],"headers":[{"heading":"4. Static Testing","level":1,"id":"4._Static_Testing_0"},{"heading":"I. Static Testing in General","level":2,"id":"I._Static_Testing_in_General_0"},{"heading":"1. Static Testing vs. Dynamic Testing","level":3,"id":"1._Static_Testing_vs._Dynamic_Testing_0"},{"heading":"2. Static Testing Goals and Principles","level":3,"id":"2._Static_Testing_Goals_and_Principles_0"},{"heading":"3. Implementation: Manual vs. Automated","level":3,"id":"3._Implementation_Manual_vs._Automated_0"},{"heading":"II. Reviews","level":2,"id":"II._Reviews_0"},{"heading":"1. The Five Basic Steps of the Review Process","level":3,"id":"1._The_Five_Basic_Steps_of_the_Review_Process_0"},{"heading":"2. Individual Review Techniques","level":3,"id":"2._Individual_Review_Techniques_0"},{"heading":"3. Review Roles","level":3,"id":"3._Review_Roles_0"},{"heading":"4. Types of Reviews (by Formalization)","level":3,"id":"4._Types_of_Reviews_(by_Formalization)_0"},{"heading":"5. Benefits of Reviews","level":3,"id":"5._Benefits_of_Reviews_0"},{"heading":"III. Metrics","level":2,"id":"III._Metrics_0"},{"heading":"1. Purposes of Measurement","level":3,"id":"1._Purposes_of_Measurement_0"},{"heading":"2. Types of Software Metrics","level":3,"id":"2._Types_of_Software_Metrics_0"},{"heading":"3. Example Metrics for Object-Oriented Programming (OOP)","level":3,"id":"3._Example_Metrics_for_Object-Oriented_Programming_(OOP)_0"}],"links":[],"author":"","coverImageURL":"","fullURL":"software-test-&-quality-management/04.-static-testing.html","pathToRoot":"..","attachments":[],"createdTime":1764818255989,"modifiedTime":1764818263596,"sourceSize":8722,"sourcePath":"Software Test & Quality Management/04. Static Testing.md","exportPath":"software-test-&-quality-management/04.-static-testing.html","showInTree":true,"treeOrder":16,"backlinks":[],"type":"markdown"},"software-test-&-quality-management/05.-black-box-testing.html":{"title":"05. Black-Box Testing","icon":"","description":"Dynamic Testing involves testing the resulting processes of a test object (Program / System under Test, SUT) by executing and \"interpreting\" it. This requires supplying input values and observing the output values. This contrasts with static testing, which examines static descriptions and artifacts of the development process (like source code or models).Dynamic Testing Procedure:\nDesign Tests: Investigate test requirements by analyzing test-related documents to determine what must be tested and under what conditions. This step enables traceability between specifications/requirements and test conditions, and allows for impact analysis and examination of current test coverage.\nSpecify Test Cases: Create and describe test cases and test data using test design approaches. Expected results must include outputs, changes of data and states, and all other ramifications of testing.\nSpecify Test Process Specification: Arrange test cases in executable order, taking pre- and post-conditions into account. This defines the order of tests and allows for automation.\nTest Execution Planning: Define the concrete order of execution, using criteria like regression testing, prioritization, and logical dependencies.\nTest design techniques are broadly categorized into Specification-based (Black-Box), Structure-based (White-Box), and Experience-based techniques.The primary focus of black-box testing is the functionality of the test object, which holds the greatest priority for the final product.These techniques use models and requirements to derive test cases. Functional testing is a synonym where test cases are derived using the functional system specification. Functionality is defined by ISO 25010 as Completeness, Correctness, and Adequacy.Basic Idea: The domain of input and output values is partitioned into Equivalence Classes. All values within a single EC are assumed to lead to the same behavior. A single arbitrary value is chosen from each class as a representative sample.Procedure for Defining ECs:\nDomain Constraint (e.g., range 1 to 100): Create one valid EC (1 &lt;= x &lt;= 100) and two invalid ECs (x &lt; 1 and x &gt; 100).\nMin/Max Number Constraint: Create one valid EC and two invalid ECs.\nSet of Values (treated differently): Create one valid EC for every specified value, plus one overall invalid EC for everything else (e.g., Badminton vs. Football).\nSituation Fulfillment Constraint: Create one valid EC and one invalid EC.\nTest Case Minimization and Failure Masking:\nThe minimal criteria require at least one representative of each EC to be included in at least one test case.\nCombining representatives of invalid ECs should be avoided because it can lead to potential failure masking.\nTest End Criteria: EC-Coverage is calculated as (No. of tested EC / Total no. of EC) * 100%.\nAdvice: For selecting powerful test data, combine EC with failure-oriented methods like boundary value analysis.\nCombinatorial Interaction Testing (CIT): CIT aims to minimize the test cases while covering combinations of ECs.\n1-wise testing: Each EC is part of at least one test case.\nPairwise (2-wise) testing: Covers all 2-way combinations of variable ECs.\nThe Greedy Set-Cover Algorithm can be used to calculate a minimum number of test cases required to cover all pairs.\nBasic Idea: Failures often occur at boundaries (where a constraint just holds or just fails to hold), leading to \"off by one\" errors. BVA tests these specific boundary values to increase the likelihood of finding failures.<img alt=\"Screenshot 2025-12-04 at 04.32.17.png\" src=\"attachments/screenshot-2025-12-04-at-04.32.17.png\" target=\"_self\">Procedure:\nBVA is best used in combination with Equivalence Classes.\nTest the lowest (l) and greatest (g) value of an EC.\nExtend the values to include inputs right and left of the boundary (e.g., valid and invalid values near the threshold).\nAlways test two values for every boundary: the boundary value itself, and the value immediately before/after the boundary.\nFor set-based domains (e.g., data structures), test the smallest and biggest valid quantities, and the smallest and biggest invalid quantities.\nAssessment:\nPro: Boundaries often contain more failures than values within the class.\nContra: Defining all boundary values can be very complex, and selecting test data requires creativity without a clear \"recipe\".\nTest End Criteria: BV-Coverage is calculated as (No. of tested BV / Total no. of BV) * 100%.\nApplicability: DT is applicable for complex rules and system requirements involving logical conditions, particularly in business processes.Structure and Components:\nConditions: Possible states of objects (can be True 'T', False 'F', or Insignificant '-').\nRules (Columns): Combinations of condition values.\nActions: Activities executed based on the rules (marked with 'X' for execute).\nAction Pointer: Allocates conditions with actions.\nAnalysis and Test Cases:\nThe decision table is complete if combinations are defined for conditions.\nThe DT is redundancy free if specific conditions lead to different actions.\nThe DT is consistent if the same conditions lead to the same actions.\nTest Cases: Every column (rule) in the decision table corresponds to one test case.\nAssessment:\nPro: Systematically formulates logical coherences and derives condition combinations that might not be executed otherwise. DTs are easily checked for redundancy, consistency, and completeness.\nContra: DTs become confusing if there are too many conditions. Use Case-Testing: Use cases describe a continuity of interactions between actors that result in a specific outcome. Test cases are derived from process operations based on the system’s actual usage, revealing failures in those processes. Useful for system/acceptance testing.\nCause-Effect-Graphs: A graphical method describing logical casual-correlations between Causes (inputs, data content) and Effects/Reactions (outputs, resulting system states).\nClassification-trees.\nSyntax Testing: Used when input syntax is formally specified. Test cases are derived from syntactical rules to test both compliance and violation. Mutation techniques (such as replacing, omitting, or adding elements) are often used to test invalid syntax.\nBlack-box testing methods are founded on the system's requirements and specifications. Consequently:\nThey cannot detect missing or incorrect requirements or specifications.\nDetection of non-specified functionality (additional, non-required functions) is likely only found by coincidence.\nBlack-box techniques are prioritized because they focus on the functionality of the test object, which is paramount for the final product.\n","aliases":[],"inlineTags":[],"frontmatterTags":[],"headers":[{"heading":"5. Black-Box Testing","level":1,"id":"5._Black-Box_Testing_0"},{"heading":"I. Dynamic Testing in General","level":2,"id":"I._Dynamic_Testing_in_General_0"},{"heading":"II. Black-Box Testing vs. White-Box Testing","level":2,"id":"II._Black-Box_Testing_vs._White-Box_Testing_0"},{"heading":"III. Specification-Based Black-Box Testing Techniques","level":2,"id":"III._Specification-Based_Black-Box_Testing_Techniques_0"},{"heading":"A. Equivalence Classes (EC)","level":3,"id":"A._Equivalence_Classes_(EC)_0"},{"heading":"B. Boundary Value Analysis (BVA)","level":3,"id":"B._Boundary_Value_Analysis_(BVA)_0"},{"heading":"C. Decision Table Testing (DT)","level":3,"id":"C._Decision_Table_Testing_(DT)_0"},{"heading":"IV. Other Black-Box Approaches","level":2,"id":"IV._Other_Black-Box_Approaches_0"},{"heading":"V. Assessment of Black-Box Testing","level":2,"id":"V._Assessment_of_Black-Box_Testing_0"}],"links":[],"author":"","coverImageURL":".","fullURL":"software-test-&-quality-management/05.-black-box-testing.html","pathToRoot":"..","attachments":["attachments/screenshot-2025-12-04-at-04.32.17.png"],"createdTime":1764819310712,"modifiedTime":1764819553189,"sourceSize":7781,"sourcePath":"Software Test & Quality Management/05. Black-Box Testing.md","exportPath":"software-test-&-quality-management/05.-black-box-testing.html","showInTree":true,"treeOrder":17,"backlinks":[],"type":"markdown"}},"fileInfo":{"natural-language-processing/01.-introduction.html":{"createdTime":1764119987596,"modifiedTime":1764120046435,"sourceSize":1351,"sourcePath":"Natural Language Processing/01. Introduction.md","exportPath":"natural-language-processing/01.-introduction.html","showInTree":true,"treeOrder":1,"backlinks":[],"type":"markdown","data":null},"index.html":{"createdTime":1764119564819,"modifiedTime":1764124249620,"sourceSize":49,"sourcePath":"index.md","exportPath":"index.html","showInTree":true,"treeOrder":12,"backlinks":[],"type":"markdown","data":null},"site-lib/fonts/94f2f163d4b698242fef.otf":{"createdTime":1764819704320,"modifiedTime":1764819704320,"sourceSize":66800,"sourcePath":"","exportPath":"site-lib/fonts/94f2f163d4b698242fef.otf","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/72505e6a122c6acd5471.woff2":{"createdTime":1764819704320,"modifiedTime":1764819704320,"sourceSize":104232,"sourcePath":"","exportPath":"site-lib/fonts/72505e6a122c6acd5471.woff2","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/2d5198822ab091ce4305.woff2":{"createdTime":1764819704320,"modifiedTime":1764819704320,"sourceSize":104332,"sourcePath":"","exportPath":"site-lib/fonts/2d5198822ab091ce4305.woff2","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/c8ba52b05a9ef10f4758.woff2":{"createdTime":1764819704320,"modifiedTime":1764819704320,"sourceSize":98868,"sourcePath":"","exportPath":"site-lib/fonts/c8ba52b05a9ef10f4758.woff2","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/cb10ffd7684cd9836a05.woff2":{"createdTime":1764819704320,"modifiedTime":1764819704320,"sourceSize":106876,"sourcePath":"","exportPath":"site-lib/fonts/cb10ffd7684cd9836a05.woff2","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/293fd13dbca5a3e450ef.woff2":{"createdTime":1764819704321,"modifiedTime":1764819704321,"sourceSize":105924,"sourcePath":"","exportPath":"site-lib/fonts/293fd13dbca5a3e450ef.woff2","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/085cb93e613ba3d40d2b.woff2":{"createdTime":1764819704321,"modifiedTime":1764819704321,"sourceSize":112184,"sourcePath":"","exportPath":"site-lib/fonts/085cb93e613ba3d40d2b.woff2","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/b5f0f109bc88052d4000.woff2":{"createdTime":1764819704321,"modifiedTime":1764819704321,"sourceSize":105804,"sourcePath":"","exportPath":"site-lib/fonts/b5f0f109bc88052d4000.woff2","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/cbe0ae49c52c920fd563.woff2":{"createdTime":1764819704321,"modifiedTime":1764819704321,"sourceSize":106108,"sourcePath":"","exportPath":"site-lib/fonts/cbe0ae49c52c920fd563.woff2","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/535a6cf662596b3bd6a6.woff2":{"createdTime":1764819704321,"modifiedTime":1764819704321,"sourceSize":111708,"sourcePath":"","exportPath":"site-lib/fonts/535a6cf662596b3bd6a6.woff2","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/70cc7ff27245e82ad414.ttf":{"createdTime":1764819704322,"modifiedTime":1764819704322,"sourceSize":192740,"sourcePath":"","exportPath":"site-lib/fonts/70cc7ff27245e82ad414.ttf","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/454577c22304619db035.ttf":{"createdTime":1764819704322,"modifiedTime":1764819704322,"sourceSize":161376,"sourcePath":"","exportPath":"site-lib/fonts/454577c22304619db035.ttf","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/52ac8f3034507f1d9e53.ttf":{"createdTime":1764819704323,"modifiedTime":1764819704323,"sourceSize":191568,"sourcePath":"","exportPath":"site-lib/fonts/52ac8f3034507f1d9e53.ttf","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/05b618077343fbbd92b7.ttf":{"createdTime":1764819704323,"modifiedTime":1764819704323,"sourceSize":155288,"sourcePath":"","exportPath":"site-lib/fonts/05b618077343fbbd92b7.ttf","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/4bb6ac751d1c5478ff3a.woff2":{"createdTime":1764819704316,"modifiedTime":1764819704316,"sourceSize":7876,"sourcePath":"","exportPath":"site-lib/fonts/4bb6ac751d1c5478ff3a.woff2","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/media/6155340132a851f6089e.svg":{"createdTime":1764819704316,"modifiedTime":1764819704316,"sourceSize":315,"sourcePath":"","exportPath":"site-lib/media/6155340132a851f6089e.svg","showInTree":false,"treeOrder":0,"backlinks":[],"type":"media","data":null},"site-lib/media/2308ab1944a6bfa5c5b8.svg":{"createdTime":1764819704316,"modifiedTime":1764819704316,"sourceSize":278,"sourcePath":"","exportPath":"site-lib/media/2308ab1944a6bfa5c5b8.svg","showInTree":false,"treeOrder":0,"backlinks":[],"type":"media","data":null},"site-lib/html/file-tree-content.html":{"createdTime":1764819704460,"modifiedTime":1764819704460,"sourceSize":8682,"sourcePath":"","exportPath":"site-lib/html/file-tree-content.html","showInTree":false,"treeOrder":0,"backlinks":[],"type":"html","data":null},"site-lib/scripts/webpage.js":{"createdTime":1764815953199,"modifiedTime":1764815953199,"sourceSize":110729,"sourcePath":"","exportPath":"site-lib/scripts/webpage.js","showInTree":false,"treeOrder":0,"backlinks":[],"type":"script","data":null},"site-lib/media/favicon.png":{"createdTime":1764819704261,"modifiedTime":1764819704261,"sourceSize":1105,"sourcePath":"","exportPath":"site-lib/media/favicon.png","showInTree":false,"treeOrder":0,"backlinks":[],"type":"media","data":null},"site-lib/styles/obsidian.css":{"createdTime":1764819704350,"modifiedTime":1764819704350,"sourceSize":205827,"sourcePath":"","exportPath":"site-lib/styles/obsidian.css","showInTree":false,"treeOrder":0,"backlinks":[],"type":"style","data":null},"site-lib/styles/global-variable-styles.css":{"createdTime":1764819704309,"modifiedTime":1764819704309,"sourceSize":305,"sourcePath":"","exportPath":"site-lib/styles/global-variable-styles.css","showInTree":false,"treeOrder":0,"backlinks":[],"type":"style","data":null},"site-lib/styles/main-styles.css":{"createdTime":1764815953214,"modifiedTime":1764815953214,"sourceSize":19521,"sourcePath":"","exportPath":"site-lib/styles/main-styles.css","showInTree":false,"treeOrder":0,"backlinks":[],"type":"style","data":null},"attachments/pasted-image-20251126022044.png":{"createdTime":1764120044427,"modifiedTime":1764120044427,"sourceSize":90037,"sourcePath":"attachments/Pasted image 20251126022044.png","exportPath":"attachments/pasted-image-20251126022044.png","showInTree":false,"treeOrder":0,"backlinks":[],"type":"media","data":null},"site-lib/rss.xml":{"createdTime":1764819705201,"modifiedTime":1764819705201,"sourceSize":84094,"sourcePath":"","exportPath":"site-lib/rss.xml","showInTree":false,"treeOrder":0,"backlinks":[],"type":"other","data":null},"natural-language-processing/02.-words.html":{"createdTime":1764120293371,"modifiedTime":1764120585497,"sourceSize":6983,"sourcePath":"Natural Language Processing/02. Words.md","exportPath":"natural-language-processing/02.-words.html","showInTree":true,"treeOrder":2,"backlinks":[],"type":"markdown","data":null},"natural-language-processing/03.-neural-word-representation.html":{"createdTime":1764120769803,"modifiedTime":1764121486799,"sourceSize":8614,"sourcePath":"Natural Language Processing/03. Neural Word Representation.md","exportPath":"natural-language-processing/03.-neural-word-representation.html","showInTree":true,"treeOrder":3,"backlinks":[],"type":"markdown","data":null},"natural-language-processing/04.-sentence-structure.html":{"createdTime":1764121582042,"modifiedTime":1764122251824,"sourceSize":4086,"sourcePath":"Natural Language Processing/04. Sentence Structure.md","exportPath":"natural-language-processing/04.-sentence-structure.html","showInTree":true,"treeOrder":4,"backlinks":[],"type":"markdown","data":null},"attachments/pasted-image-20251126025040.png":{"createdTime":1764121840043,"modifiedTime":1764121840043,"sourceSize":78874,"sourcePath":"attachments/Pasted image 20251126025040.png","exportPath":"attachments/pasted-image-20251126025040.png","showInTree":false,"treeOrder":0,"backlinks":[],"type":"media","data":null},"attachments/pasted-image-20251126025053.png":{"createdTime":1764121853728,"modifiedTime":1764121853728,"sourceSize":100088,"sourcePath":"attachments/Pasted image 20251126025053.png","exportPath":"attachments/pasted-image-20251126025053.png","showInTree":false,"treeOrder":0,"backlinks":[],"type":"media","data":null},"attachments/pasted-image-20251126025309.png":{"createdTime":1764121989941,"modifiedTime":1764121989941,"sourceSize":86923,"sourcePath":"attachments/Pasted image 20251126025309.png","exportPath":"attachments/pasted-image-20251126025309.png","showInTree":false,"treeOrder":0,"backlinks":[],"type":"media","data":null},"attachments/pasted-image-20251126025315.png":{"createdTime":1764121995701,"modifiedTime":1764121995701,"sourceSize":107061,"sourcePath":"attachments/Pasted image 20251126025315.png","exportPath":"attachments/pasted-image-20251126025315.png","showInTree":false,"treeOrder":0,"backlinks":[],"type":"media","data":null},"natural-language-processing/05.-semantics.html":{"createdTime":1764122256816,"modifiedTime":1764122620853,"sourceSize":8140,"sourcePath":"Natural Language Processing/05. Semantics.md","exportPath":"natural-language-processing/05.-semantics.html","showInTree":true,"treeOrder":5,"backlinks":[],"type":"markdown","data":null},"attachments/pasted-image-20251126025836.png":{"createdTime":1764122316387,"modifiedTime":1764122316387,"sourceSize":34217,"sourcePath":"attachments/Pasted image 20251126025836.png","exportPath":"attachments/pasted-image-20251126025836.png","showInTree":false,"treeOrder":0,"backlinks":[],"type":"media","data":null},"attachments/pasted-image-20251126025850.png":{"createdTime":1764122330094,"modifiedTime":1764122330094,"sourceSize":81628,"sourcePath":"attachments/Pasted image 20251126025850.png","exportPath":"attachments/pasted-image-20251126025850.png","showInTree":false,"treeOrder":0,"backlinks":[],"type":"media","data":null},"natural-language-processing/06.-topic-models.html":{"createdTime":1764122742946,"modifiedTime":1764123016632,"sourceSize":6011,"sourcePath":"Natural Language Processing/06. Topic Models.md","exportPath":"natural-language-processing/06.-topic-models.html","showInTree":true,"treeOrder":6,"backlinks":[],"type":"markdown","data":null},"attachments/pasted-image-20251126030848.png":{"createdTime":1764122928953,"modifiedTime":1764122928953,"sourceSize":312186,"sourcePath":"attachments/Pasted image 20251126030848.png","exportPath":"attachments/pasted-image-20251126030848.png","showInTree":false,"treeOrder":0,"backlinks":[],"type":"media","data":null},"natural-language-processing/07.-sentiment-analysis.html":{"createdTime":1764123052269,"modifiedTime":1764123212194,"sourceSize":5639,"sourcePath":"Natural Language Processing/07. Sentiment Analysis.md","exportPath":"natural-language-processing/07.-sentiment-analysis.html","showInTree":true,"treeOrder":7,"backlinks":[],"type":"markdown","data":null},"attachments/pasted-image-20251126031330.png":{"createdTime":1764123210174,"modifiedTime":1764123210175,"sourceSize":351629,"sourcePath":"attachments/Pasted image 20251126031330.png","exportPath":"attachments/pasted-image-20251126031330.png","showInTree":false,"treeOrder":0,"backlinks":[],"type":"media","data":null},"model-driven-software-development/01.-introduction.html":{"createdTime":1764123454517,"modifiedTime":1764171898169,"sourceSize":4386,"sourcePath":"Model-Driven Software Development/01. Introduction.md","exportPath":"model-driven-software-development/01.-introduction.html","showInTree":true,"treeOrder":1,"backlinks":[],"type":"markdown","data":null},"model-driven-software-development/02.-metamodelling.html":{"createdTime":1764123583976,"modifiedTime":1764123778938,"sourceSize":5382,"sourcePath":"Model-Driven Software Development/02. Metamodelling.md","exportPath":"model-driven-software-development/02.-metamodelling.html","showInTree":true,"treeOrder":2,"backlinks":[],"type":"markdown","data":null},"model-driven-software-development/03.-advanced-uml.html":{"createdTime":1764123788361,"modifiedTime":1764123889448,"sourceSize":8073,"sourcePath":"Model-Driven Software Development/03. Advanced UML.md","exportPath":"model-driven-software-development/03.-advanced-uml.html","showInTree":true,"treeOrder":3,"backlinks":[],"type":"markdown","data":null},"attachments/pasted-image-20251126032448.png":{"createdTime":1764123888605,"modifiedTime":1764123888605,"sourceSize":53878,"sourcePath":"attachments/Pasted image 20251126032448.png","exportPath":"attachments/pasted-image-20251126032448.png","showInTree":false,"treeOrder":0,"backlinks":[],"type":"media","data":null},"attachments/pasted-image-20251126032239.png":{"createdTime":1764123759268,"modifiedTime":1764123759269,"sourceSize":175092,"sourcePath":"attachments/Pasted image 20251126032239.png","exportPath":"attachments/pasted-image-20251126032239.png","showInTree":false,"treeOrder":0,"backlinks":[],"type":"media","data":null},"attachments/pasted-image-20251126031843.png":{"createdTime":1764123523441,"modifiedTime":1764123523441,"sourceSize":57646,"sourcePath":"attachments/Pasted image 20251126031843.png","exportPath":"attachments/pasted-image-20251126031843.png","showInTree":false,"treeOrder":0,"backlinks":[],"type":"media","data":null},"attachments/pasted-image-20251126031934.png":{"createdTime":1764123574101,"modifiedTime":1764123574102,"sourceSize":69633,"sourcePath":"attachments/Pasted image 20251126031934.png","exportPath":"attachments/pasted-image-20251126031934.png","showInTree":false,"treeOrder":0,"backlinks":[],"type":"media","data":null},"site-lib/styles/theme.css":{"createdTime":1764815953282,"modifiedTime":1764815953282,"sourceSize":161646,"sourcePath":"","exportPath":"site-lib/styles/theme.css","showInTree":false,"treeOrder":0,"backlinks":[],"type":"style","data":null},"software-test-&-quality-management/01.-introduction.html":{"createdTime":1764550992477,"modifiedTime":1764555140419,"sourceSize":9284,"sourcePath":"Software Test & Quality Management/01. Introduction.md","exportPath":"software-test-&-quality-management/01.-introduction.html","showInTree":true,"treeOrder":13,"backlinks":[],"type":"markdown","data":null},"site-lib/scripts/graph-wasm.wasm":{"createdTime":1764550947339,"modifiedTime":1764119648449.3892,"sourceSize":23655,"sourcePath":"","exportPath":"site-lib/scripts/graph-wasm.wasm","showInTree":false,"treeOrder":0,"backlinks":[],"type":"other","data":null},"site-lib/scripts/graph-wasm.js":{"createdTime":1764815953200,"modifiedTime":1764815953200,"sourceSize":12885,"sourcePath":"","exportPath":"site-lib/scripts/graph-wasm.js","showInTree":false,"treeOrder":0,"backlinks":[],"type":"script","data":null},"site-lib/scripts/graph-render-worker.js":{"createdTime":1764815953200,"modifiedTime":1764815953200,"sourceSize":5681,"sourcePath":"","exportPath":"site-lib/scripts/graph-render-worker.js","showInTree":false,"treeOrder":0,"backlinks":[],"type":"script","data":null},"attachments/screenshot-2025-12-01-at-02.02.01.png":{"createdTime":1764551004941,"modifiedTime":1764551004942,"sourceSize":330482,"sourcePath":"attachments/Screenshot 2025-12-01 at 02.02.01.png","exportPath":"attachments/screenshot-2025-12-01-at-02.02.01.png","showInTree":false,"treeOrder":0,"backlinks":[],"type":"media","data":null},"attachments/pasted-image-20251201022626.png":{"createdTime":1764552386750,"modifiedTime":1764552386750,"sourceSize":210835,"sourcePath":"attachments/Pasted image 20251201022626.png","exportPath":"attachments/pasted-image-20251201022626.png","showInTree":false,"treeOrder":0,"backlinks":[],"type":"media","data":null},"software-test-&-quality-management/02.-testing-process.html":{"createdTime":1764555236830,"modifiedTime":1764817089596,"sourceSize":10931,"sourcePath":"Software Test & Quality Management/02. Testing Process.md","exportPath":"software-test-&-quality-management/02.-testing-process.html","showInTree":true,"treeOrder":14,"backlinks":[],"type":"markdown","data":null},"software-test-&-quality-management/03.-testing-phrases.html":{"createdTime":1764557647253,"modifiedTime":1764817054510,"sourceSize":8003,"sourcePath":"Software Test & Quality Management/03. Testing Phrases.md","exportPath":"software-test-&-quality-management/03.-testing-phrases.html","showInTree":true,"treeOrder":15,"backlinks":[],"type":"markdown","data":null},"attachments/pasted-image-20251204035604.png":{"createdTime":1764816964764,"modifiedTime":1764816964764,"sourceSize":247374,"sourcePath":"attachments/Pasted image 20251204035604.png","exportPath":"attachments/pasted-image-20251204035604.png","showInTree":false,"treeOrder":0,"backlinks":[],"type":"media","data":null},"attachments/pasted-image-20251204035633.png":{"createdTime":1764816993251,"modifiedTime":1764816993252,"sourceSize":108878,"sourcePath":"attachments/Pasted image 20251204035633.png","exportPath":"attachments/pasted-image-20251204035633.png","showInTree":false,"treeOrder":0,"backlinks":[],"type":"media","data":null},"attachments/screenshot-2025-12-01-at-03.45.29.png":{"createdTime":1764557144162,"modifiedTime":1764557144163,"sourceSize":103921,"sourcePath":"attachments/Screenshot 2025-12-01 at 03.45.29.png","exportPath":"attachments/screenshot-2025-12-01-at-03.45.29.png","showInTree":false,"treeOrder":0,"backlinks":[],"type":"media","data":null},"software-test-&-quality-management/04.-static-testing.html":{"createdTime":1764818255989,"modifiedTime":1764818263596,"sourceSize":8722,"sourcePath":"Software Test & Quality Management/04. Static Testing.md","exportPath":"software-test-&-quality-management/04.-static-testing.html","showInTree":true,"treeOrder":16,"backlinks":[],"type":"markdown","data":null},"software-test-&-quality-management/05.-black-box-testing.html":{"createdTime":1764819310712,"modifiedTime":1764819553189,"sourceSize":7781,"sourcePath":"Software Test & Quality Management/05. Black-Box Testing.md","exportPath":"software-test-&-quality-management/05.-black-box-testing.html","showInTree":true,"treeOrder":17,"backlinks":[],"type":"markdown","data":null},"site-lib/fonts/mathjax_zero.woff":{"createdTime":1764819704314,"modifiedTime":1764819704314,"sourceSize":1368,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_zero.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/mathjax_main-regular.woff":{"createdTime":1764819704315,"modifiedTime":1764819704315,"sourceSize":34160,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_main-regular.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/mathjax_main-bold.woff":{"createdTime":1764819704315,"modifiedTime":1764819704315,"sourceSize":34464,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_main-bold.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/mathjax_math-italic.woff":{"createdTime":1764819704315,"modifiedTime":1764819704315,"sourceSize":19360,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_math-italic.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/mathjax_main-italic.woff":{"createdTime":1764819704315,"modifiedTime":1764819704315,"sourceSize":20832,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_main-italic.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/mathjax_math-bolditalic.woff":{"createdTime":1764819704315,"modifiedTime":1764819704315,"sourceSize":19776,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_math-bolditalic.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/mathjax_size1-regular.woff":{"createdTime":1764819704315,"modifiedTime":1764819704315,"sourceSize":5792,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_size1-regular.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/mathjax_size2-regular.woff":{"createdTime":1764819704315,"modifiedTime":1764819704315,"sourceSize":5464,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_size2-regular.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/mathjax_size3-regular.woff":{"createdTime":1764819704315,"modifiedTime":1764819704315,"sourceSize":3244,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_size3-regular.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/mathjax_size4-regular.woff":{"createdTime":1764819704315,"modifiedTime":1764819704315,"sourceSize":5148,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_size4-regular.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/mathjax_ams-regular.woff":{"createdTime":1764819704315,"modifiedTime":1764819704315,"sourceSize":40808,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_ams-regular.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/mathjax_calligraphic-regular.woff":{"createdTime":1764819704315,"modifiedTime":1764819704315,"sourceSize":9600,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_calligraphic-regular.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/mathjax_calligraphic-bold.woff":{"createdTime":1764819704315,"modifiedTime":1764819704315,"sourceSize":9908,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_calligraphic-bold.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/mathjax_fraktur-regular.woff":{"createdTime":1764819704315,"modifiedTime":1764819704315,"sourceSize":21480,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_fraktur-regular.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/mathjax_fraktur-bold.woff":{"createdTime":1764819704315,"modifiedTime":1764819704315,"sourceSize":22340,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_fraktur-bold.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/mathjax_sansserif-regular.woff":{"createdTime":1764819704315,"modifiedTime":1764819704315,"sourceSize":12660,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_sansserif-regular.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/mathjax_sansserif-bold.woff":{"createdTime":1764819704315,"modifiedTime":1764819704315,"sourceSize":15944,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_sansserif-bold.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/mathjax_sansserif-italic.woff":{"createdTime":1764819704315,"modifiedTime":1764819704315,"sourceSize":14628,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_sansserif-italic.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/mathjax_script-regular.woff":{"createdTime":1764819704315,"modifiedTime":1764819704315,"sourceSize":11852,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_script-regular.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/mathjax_typewriter-regular.woff":{"createdTime":1764819704315,"modifiedTime":1764819704315,"sourceSize":17604,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_typewriter-regular.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/mathjax_vector-regular.woff":{"createdTime":1764819704315,"modifiedTime":1764819704315,"sourceSize":1136,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_vector-regular.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/mathjax_vector-bold.woff":{"createdTime":1764819704315,"modifiedTime":1764819704315,"sourceSize":1116,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_vector-bold.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"attachments/screenshot-2025-12-04-at-04.32.17.png":{"createdTime":1764819552183,"modifiedTime":1764819552184,"sourceSize":109236,"sourcePath":"attachments/Screenshot 2025-12-04 at 04.32.17.png","exportPath":"attachments/screenshot-2025-12-04-at-04.32.17.png","showInTree":false,"treeOrder":0,"backlinks":[],"type":"media","data":null}},"sourceToTarget":{"Natural Language Processing/01. Introduction.md":"natural-language-processing/01.-introduction.html","index.md":"index.html","":"site-lib/rss.xml","attachments/Pasted image 20251126022044.png":"attachments/pasted-image-20251126022044.png","Natural Language Processing/02. Words.md":"natural-language-processing/02.-words.html","Natural Language Processing/03. Neural Word Representation.md":"natural-language-processing/03.-neural-word-representation.html","Natural Language Processing/04. Sentence Structure.md":"natural-language-processing/04.-sentence-structure.html","attachments/Pasted image 20251126025040.png":"attachments/pasted-image-20251126025040.png","attachments/Pasted image 20251126025053.png":"attachments/pasted-image-20251126025053.png","attachments/Pasted image 20251126025309.png":"attachments/pasted-image-20251126025309.png","attachments/Pasted image 20251126025315.png":"attachments/pasted-image-20251126025315.png","Natural Language Processing/05. Semantics.md":"natural-language-processing/05.-semantics.html","attachments/Pasted image 20251126025836.png":"attachments/pasted-image-20251126025836.png","attachments/Pasted image 20251126025850.png":"attachments/pasted-image-20251126025850.png","Natural Language Processing/06. Topic Models.md":"natural-language-processing/06.-topic-models.html","attachments/Pasted image 20251126030848.png":"attachments/pasted-image-20251126030848.png","Natural Language Processing/07. Sentiment Analysis.md":"natural-language-processing/07.-sentiment-analysis.html","attachments/Pasted image 20251126031330.png":"attachments/pasted-image-20251126031330.png","Model-Driven Software Development/01. Introduction.md":"model-driven-software-development/01.-introduction.html","Model-Driven Software Development/02. Metamodelling.md":"model-driven-software-development/02.-metamodelling.html","Model-Driven Software Development/03. Advanced UML.md":"model-driven-software-development/03.-advanced-uml.html","attachments/Pasted image 20251126032448.png":"attachments/pasted-image-20251126032448.png","attachments/Pasted image 20251126032239.png":"attachments/pasted-image-20251126032239.png","attachments/Pasted image 20251126031843.png":"attachments/pasted-image-20251126031843.png","attachments/Pasted image 20251126031934.png":"attachments/pasted-image-20251126031934.png","Software Test & Quality Management/01. Introduction.md":"software-test-&-quality-management/01.-introduction.html","attachments/Screenshot 2025-12-01 at 02.02.01.png":"attachments/screenshot-2025-12-01-at-02.02.01.png","attachments/Pasted image 20251201022626.png":"attachments/pasted-image-20251201022626.png","Software Test & Quality Management/02. Testing Process.md":"software-test-&-quality-management/02.-testing-process.html","Software Test & Quality Management/03. Testing Phrases.md":"software-test-&-quality-management/03.-testing-phrases.html","attachments/Pasted image 20251204035604.png":"attachments/pasted-image-20251204035604.png","attachments/Pasted image 20251204035633.png":"attachments/pasted-image-20251204035633.png","attachments/Screenshot 2025-12-01 at 03.45.29.png":"attachments/screenshot-2025-12-01-at-03.45.29.png","Software Test & Quality Management/04. Static Testing.md":"software-test-&-quality-management/04.-static-testing.html","Software Test & Quality Management/05. Black-Box Testing.md":"software-test-&-quality-management/05.-black-box-testing.html","attachments/Screenshot 2025-12-04 at 04.32.17.png":"attachments/screenshot-2025-12-04-at-04.32.17.png"},"featureOptions":{"backlinks":{"featureId":"backlinks","enabled":true,"unavailable":false,"alwaysEnabled":false,"hideSettingsButton":false,"featurePlacement":{"selector":".footer","type":"start","info_selector":{"show":true,"name":"","description":"CSS selector for an element. The feature will be placed relative to this element.","placeholder":""},"info_type":{"show":true,"name":"","description":"Will this feature be placed before, after, or inside (at the beggining or end).","placeholder":"","dropdownOptions":{"Before":"before","After":"after","Start":"start","End":"end"}}},"info_featurePlacement":{"show":true,"name":"","description":"Where to place this feature on the page. (Relative to the selector)","placeholder":""},"displayTitle":"Backlinks","info_displayTitle":{"show":true,"name":"","description":"Descriptive title to show above the feature","placeholder":""}},"tags":{"featureId":"tags","enabled":true,"unavailable":false,"alwaysEnabled":false,"hideSettingsButton":false,"featurePlacement":{"selector":".header .data-bar","type":"end","info_selector":{"show":true,"name":"","description":"CSS selector for an element. The feature will be placed relative to this element.","placeholder":""},"info_type":{"show":true,"name":"","description":"Will this feature be placed before, after, or inside (at the beggining or end).","placeholder":"","dropdownOptions":{"Before":"before","After":"after","Start":"start","End":"end"}}},"info_featurePlacement":{"show":true,"name":"","description":"Where to place this feature on the page. (Relative to the selector)","placeholder":""},"displayTitle":"","info_displayTitle":{"show":true,"name":"","description":"Descriptive title to show above the feature","placeholder":""},"showInlineTags":true,"showFrontmatterTags":true,"info_showInlineTags":{"show":true,"name":"","description":"Show tags defined inside the document at the top of the page.","placeholder":""},"info_showFrontmatterTags":{"show":true,"name":"","description":"Show tags defined in the frontmatter of the document at the top of the page.","placeholder":""}},"alias":{"featureId":"aliases","enabled":true,"unavailable":false,"alwaysEnabled":false,"hideSettingsButton":false,"featurePlacement":{"selector":".header .data-bar","type":"start","info_selector":{"show":true,"name":"","description":"CSS selector for an element. The feature will be placed relative to this element.","placeholder":""},"info_type":{"show":true,"name":"","description":"Will this feature be placed before, after, or inside (at the beggining or end).","placeholder":"","dropdownOptions":{"Before":"before","After":"after","Start":"start","End":"end"}}},"info_featurePlacement":{"show":true,"name":"","description":"Where to place this feature on the page. (Relative to the selector)","placeholder":""},"displayTitle":"Aliases","info_displayTitle":{"show":true,"name":"","description":"Descriptive title to show above the feature","placeholder":""}},"properties":{"featureId":"properties","enabled":true,"unavailable":false,"alwaysEnabled":false,"hideSettingsButton":false,"featurePlacement":{"selector":".header","type":"start","info_selector":{"show":true,"name":"","description":"CSS selector for an element. The feature will be placed relative to this element.","placeholder":""},"info_type":{"show":true,"name":"","description":"Will this feature be placed before, after, or inside (at the beggining or end).","placeholder":"","dropdownOptions":{"Before":"before","After":"after","Start":"start","End":"end"}}},"info_featurePlacement":{"show":true,"name":"","description":"Where to place this feature on the page. (Relative to the selector)","placeholder":""},"displayTitle":"Properties","info_displayTitle":{"show":true,"name":"","description":"Descriptive title to show above the feature","placeholder":""},"info_hideProperties":{"show":true,"name":"","description":"A list of properties to hide from the properties view","placeholder":""}},"fileNavigation":{"featureId":"file-navigation","enabled":true,"unavailable":false,"alwaysEnabled":false,"hideSettingsButton":false,"featurePlacement":{"selector":"#left-sidebar-content","type":"end","info_selector":{"show":true,"name":"","description":"CSS selector for an element. The feature will be placed relative to this element.","placeholder":""},"info_type":{"show":true,"name":"","description":"Will this feature be placed before, after, or inside (at the beggining or end).","placeholder":"","dropdownOptions":{"Before":"before","After":"after","Start":"start","End":"end"}}},"info_featurePlacement":{"show":true,"name":"","description":"Where to place this feature on the page. (Relative to the selector)","placeholder":""},"info_includePath":{"show":false,"name":"","description":"","placeholder":""},"showCustomIcons":false,"showDefaultFolderIcons":false,"showDefaultFileIcons":false,"defaultFolderIcon":"lucide//folder","defaultFileIcon":"lucide//file","defaultMediaIcon":"lucide//file-image","exposeStartingPath":true,"info_showCustomIcons":{"show":true,"name":"","description":"Show custom icons for files and folders","placeholder":""},"info_showDefaultFolderIcons":{"show":true,"name":"","description":"Show a default icon of a folder for every folder in the tree","placeholder":""},"info_showDefaultFileIcons":{"show":true,"name":"","description":"Show a default icon of a file for every file in the tree","placeholder":""},"info_defaultFolderIcon":{"show":true,"name":"","description":"The icon to use for folders. Prefix with 'lucide//' to use a Lucide icon","placeholder":""},"info_defaultFileIcon":{"show":true,"name":"","description":"The icon to use for files. Prefix with 'lucide//' to use a Lucide icon","placeholder":""},"info_defaultMediaIcon":{"show":true,"name":"","description":"The icon to use for media files. Prefix with 'lucide//' to use a Lucide icon","placeholder":""},"info_exposeStartingPath":{"show":true,"name":"","description":"Whether or not to show the current file in the file tree when the page is first loaded","placeholder":""},"includePath":"site-lib/html/file-tree.html"},"search":{"featureId":"search","enabled":true,"unavailable":false,"alwaysEnabled":false,"hideSettingsButton":false,"featurePlacement":{"selector":"#left-sidebar .topbar-content","type":"start","info_selector":{"show":true,"name":"","description":"CSS selector for an element. The feature will be placed relative to this element.","placeholder":""},"info_type":{"show":true,"name":"","description":"Will this feature be placed before, after, or inside (at the beggining or end).","placeholder":"","dropdownOptions":{"Before":"before","After":"after","Start":"start","End":"end"}}},"info_featurePlacement":{"show":true,"name":"","description":"Where to place this feature on the page. (Relative to the selector)","placeholder":""},"displayTitle":"Search...","info_displayTitle":{"show":true,"name":"","description":"Descriptive title to show above the feature","placeholder":""}},"outline":{"featureId":"outline","enabled":true,"unavailable":false,"alwaysEnabled":false,"hideSettingsButton":false,"featurePlacement":{"selector":"#right-sidebar-content","type":"end","info_selector":{"show":true,"name":"","description":"CSS selector for an element. The feature will be placed relative to this element.","placeholder":""},"info_type":{"show":true,"name":"","description":"Will this feature be placed before, after, or inside (at the beggining or end).","placeholder":"","dropdownOptions":{"Before":"before","After":"after","Start":"start","End":"end"}}},"info_featurePlacement":{"show":true,"name":"","description":"Where to place this feature on the page. (Relative to the selector)","placeholder":""},"displayTitle":"Outline","info_displayTitle":{"show":true,"name":"","description":"Descriptive title to show above the feature","placeholder":""},"startCollapsed":false,"minCollapseDepth":0,"info_startCollapsed":{"show":true,"name":"","description":"Should the outline start collapsed?","placeholder":""},"info_minCollapseDepth":{"show":true,"name":"","description":"Only allow outline items to be collapsed if they are at least this many levels deep in the tree.","placeholder":"","dropdownOptions":{"1":1,"2":2,"No Collapse":100}}},"themeToggle":{"featureId":"theme-toggle","enabled":true,"unavailable":false,"alwaysEnabled":false,"hideSettingsButton":false,"featurePlacement":{"selector":"#right-sidebar .topbar-content","type":"start","info_selector":{"show":true,"name":"","description":"CSS selector for an element. The feature will be placed relative to this element.","placeholder":""},"info_type":{"show":true,"name":"","description":"Will this feature be placed before, after, or inside (at the beggining or end).","placeholder":"","dropdownOptions":{"Before":"before","After":"after","Start":"start","End":"end"}}},"info_featurePlacement":{"show":true,"name":"","description":"Where to place this feature on the page. (Relative to the selector)","placeholder":""},"displayTitle":"","info_displayTitle":{"show":true,"name":"","description":"Descriptive title to show above the feature","placeholder":""}},"graphView":{"featureId":"graph-view","enabled":true,"unavailable":false,"alwaysEnabled":false,"hideSettingsButton":false,"featurePlacement":{"selector":"#right-sidebar-content","type":"start","info_selector":{"show":true,"name":"","description":"CSS selector for an element. The feature will be placed relative to this element.","placeholder":""},"info_type":{"show":true,"name":"","description":"Will this feature be placed before, after, or inside (at the beggining or end).","placeholder":"","dropdownOptions":{"Before":"before","After":"after","Start":"start","End":"end"}}},"info_featurePlacement":{"show":true,"name":"","description":"Where to place this feature on the page. (Relative to the selector)","placeholder":""},"displayTitle":"Graph View","info_displayTitle":{"show":true,"name":"","description":"Descriptive title to show above the feature","placeholder":""},"showOrphanNodes":true,"showAttachments":false,"allowGlobalGraph":true,"allowExpand":true,"attractionForce":1,"linkLength":15,"repulsionForce":80,"centralForce":2,"edgePruning":100,"minNodeRadius":3,"maxNodeRadius":7,"info_showOrphanNodes":{"show":true,"name":"","description":"Show nodes that are not connected to any other nodes.","placeholder":""},"info_showAttachments":{"show":true,"name":"","description":"Show attachments like images and PDFs as nodes in the graph.","placeholder":""},"info_allowGlobalGraph":{"show":true,"name":"","description":"Allow the user to view the global graph of all nodes.","placeholder":""},"info_allowExpand":{"show":true,"name":"","description":"Allow the user to pop-out the graph view to take up the whole screen","placeholder":""},"info_attractionForce":{"show":true,"name":"","description":"How much should linked nodes attract each other? This will make the graph appear more clustered.","placeholder":""},"info_linkLength":{"show":true,"name":"","description":"How long should the links between nodes be? The shorter the links the more connected nodes will cluster together.","placeholder":""},"info_repulsionForce":{"show":true,"name":"","description":"How much should nodes repel each other? This will make disconnected parts more spread out.","placeholder":""},"info_centralForce":{"show":true,"name":"","description":"How much should nodes be attracted to the center? This will make the graph appear more dense and circular.","placeholder":""},"info_edgePruning":{"show":true,"name":"","description":"Edges with a length above this threshold will not be rendered, however they will still contribute to the simulation. This can help large tangled graphs look more organised. Hovering over a node will still display these links.","placeholder":""},"info_minNodeRadius":{"show":true,"name":"","description":"How small should the smallest nodes be? The smaller a node is the less it will attract other nodes.","placeholder":""},"info_maxNodeRadius":{"show":true,"name":"","description":"How large should the largest nodes be? Nodes are sized by how many links they have. The larger a node is the more it will attract other nodes. This can be used to create a good grouping around the most important nodes.","placeholder":""}},"sidebar":{"featureId":"sidebar","enabled":true,"unavailable":false,"alwaysEnabled":false,"hideSettingsButton":false,"allowResizing":true,"allowCollapsing":true,"rightDefaultWidth":"20em","leftDefaultWidth":"20em","info_allowResizing":{"show":true,"name":"","description":"Whether or not to allow the sidebars to be resized","placeholder":""},"info_allowCollapsing":{"show":true,"name":"","description":"Whether or not to allow the sidebars to be collapsed","placeholder":""},"info_rightDefaultWidth":{"show":true,"name":"","description":"The default width of the right sidebar","placeholder":""},"info_leftDefaultWidth":{"show":true,"name":"","description":"The default width of the left sidebar","placeholder":""}},"customHead":{"featureId":"custom-head","enabled":true,"unavailable":false,"alwaysEnabled":false,"hideSettingsButton":false,"featurePlacement":{"selector":"head","type":"end","info_selector":{"show":true,"name":"","description":"CSS selector for an element. The feature will be placed relative to this element.","placeholder":""},"info_type":{"show":true,"name":"","description":"Will this feature be placed before, after, or inside (at the beggining or end).","placeholder":"","dropdownOptions":{"Before":"before","After":"after","Start":"start","End":"end"}}},"info_featurePlacement":{"show":true,"name":"","description":"Where to place this feature on the page. (Relative to the selector)","placeholder":""},"info_includePath":{"show":false,"name":"","description":"","placeholder":""},"sourcePath":"","info_sourcePath":{"show":true,"name":"","description":"The local path to the source .html file which will be included.","placeholder":"","fileInputOptions":{"makeRelativeToVault":true,"browseButton":true}},"includePath":"site-lib/html/custom-head.html"},"document":{"featureId":"obsidian-document","enabled":true,"unavailable":false,"alwaysEnabled":true,"hideSettingsButton":false,"allowFoldingLists":true,"allowFoldingHeadings":true,"documentWidth":"40em","info_allowFoldingLists":{"show":true,"name":"","description":"Whether or not to allow lists to be folded","placeholder":""},"info_allowFoldingHeadings":{"show":true,"name":"","description":"Whether or not to allow headings to be folded","placeholder":""},"info_documentWidth":{"show":true,"name":"","description":"The width of the document","placeholder":""}},"rss":{"featureId":"rss","enabled":true,"unavailable":false,"alwaysEnabled":false,"hideSettingsButton":false,"siteUrl":"","authorName":"","info_siteUrl":{"show":true,"name":"","description":"The url that this site will be hosted at","placeholder":"https://example.com/mysite"},"info_authorName":{"show":true,"name":"","description":"The name of the author of the site","placeholder":""}},"linkPreview":{"featureId":"link-preview","enabled":true,"unavailable":false,"alwaysEnabled":false,"hideSettingsButton":true}},"modifiedTime":1764819704354,"siteName":"Yulei's Notes","vaultName":"Yulei's Notes","exportRoot":"","baseURL":"","pluginVersion":"1.9.2","themeName":"","bodyClasses":"publish css-settings-manager mod-macos is-hidden-frameless show-inline-title show-ribbon show-view-header is-fullscreen is-focused","hasFavicon":false}