{"createdTime":1764120161180,"shownInTree":["natural-language-processing/01.-introduction.html","natural-language-processing/02.-words.html","natural-language-processing/03.-neural-word-representation.html","natural-language-processing/04.-sentence-structure.html","index.html"],"attachments":["site-lib/scripts/graph-wasm.wasm","site-lib/fonts/94f2f163d4b698242fef.otf","site-lib/fonts/72505e6a122c6acd5471.woff2","site-lib/fonts/2d5198822ab091ce4305.woff2","site-lib/fonts/c8ba52b05a9ef10f4758.woff2","site-lib/fonts/cb10ffd7684cd9836a05.woff2","site-lib/fonts/293fd13dbca5a3e450ef.woff2","site-lib/fonts/085cb93e613ba3d40d2b.woff2","site-lib/fonts/b5f0f109bc88052d4000.woff2","site-lib/fonts/cbe0ae49c52c920fd563.woff2","site-lib/fonts/535a6cf662596b3bd6a6.woff2","site-lib/fonts/70cc7ff27245e82ad414.ttf","site-lib/fonts/454577c22304619db035.ttf","site-lib/fonts/52ac8f3034507f1d9e53.ttf","site-lib/fonts/05b618077343fbbd92b7.ttf","site-lib/fonts/4bb6ac751d1c5478ff3a.woff2","site-lib/media/6155340132a851f6089e.svg","site-lib/media/2308ab1944a6bfa5c5b8.svg","site-lib/html/file-tree-content.html","site-lib/scripts/webpage.js","site-lib/scripts/graph-wasm.js","site-lib/scripts/graph-render-worker.js","site-lib/media/favicon.png","site-lib/styles/obsidian.css","site-lib/styles/global-variable-styles.css","site-lib/styles/main-styles.css","attachments/pasted-image-20251126022044.png","site-lib/rss.xml","site-lib/fonts/mathjax_zero.woff","site-lib/fonts/mathjax_main-regular.woff","site-lib/fonts/mathjax_main-bold.woff","site-lib/fonts/mathjax_math-italic.woff","site-lib/fonts/mathjax_main-italic.woff","site-lib/fonts/mathjax_math-bolditalic.woff","site-lib/fonts/mathjax_size1-regular.woff","site-lib/fonts/mathjax_size2-regular.woff","site-lib/fonts/mathjax_size3-regular.woff","site-lib/fonts/mathjax_size4-regular.woff","site-lib/fonts/mathjax_ams-regular.woff","site-lib/fonts/mathjax_calligraphic-regular.woff","site-lib/fonts/mathjax_calligraphic-bold.woff","site-lib/fonts/mathjax_fraktur-regular.woff","site-lib/fonts/mathjax_fraktur-bold.woff","site-lib/fonts/mathjax_sansserif-regular.woff","site-lib/fonts/mathjax_sansserif-bold.woff","site-lib/fonts/mathjax_sansserif-italic.woff","site-lib/fonts/mathjax_script-regular.woff","site-lib/fonts/mathjax_typewriter-regular.woff","site-lib/fonts/mathjax_vector-regular.woff","site-lib/fonts/mathjax_vector-bold.woff","attachments/pasted-image-20251126025040.png","attachments/pasted-image-20251126025053.png","attachments/pasted-image-20251126025309.png","attachments/pasted-image-20251126025315.png"],"allFiles":["natural-language-processing/04.-sentence-structure.html","attachments/pasted-image-20251126025315.png","attachments/pasted-image-20251126025309.png","attachments/pasted-image-20251126025053.png","attachments/pasted-image-20251126025040.png","natural-language-processing/03.-neural-word-representation.html","natural-language-processing/02.-words.html","natural-language-processing/01.-introduction.html","index.html","site-lib/scripts/graph-wasm.wasm","site-lib/fonts/94f2f163d4b698242fef.otf","site-lib/fonts/72505e6a122c6acd5471.woff2","site-lib/fonts/2d5198822ab091ce4305.woff2","site-lib/fonts/c8ba52b05a9ef10f4758.woff2","site-lib/fonts/cb10ffd7684cd9836a05.woff2","site-lib/fonts/293fd13dbca5a3e450ef.woff2","site-lib/fonts/085cb93e613ba3d40d2b.woff2","site-lib/fonts/b5f0f109bc88052d4000.woff2","site-lib/fonts/cbe0ae49c52c920fd563.woff2","site-lib/fonts/535a6cf662596b3bd6a6.woff2","site-lib/fonts/70cc7ff27245e82ad414.ttf","site-lib/fonts/454577c22304619db035.ttf","site-lib/fonts/52ac8f3034507f1d9e53.ttf","site-lib/fonts/05b618077343fbbd92b7.ttf","site-lib/fonts/4bb6ac751d1c5478ff3a.woff2","site-lib/media/6155340132a851f6089e.svg","site-lib/media/2308ab1944a6bfa5c5b8.svg","site-lib/fonts/mathjax_zero.woff","site-lib/fonts/mathjax_main-regular.woff","site-lib/fonts/mathjax_main-bold.woff","site-lib/fonts/mathjax_math-italic.woff","site-lib/fonts/mathjax_main-italic.woff","site-lib/fonts/mathjax_math-bolditalic.woff","site-lib/fonts/mathjax_size1-regular.woff","site-lib/fonts/mathjax_size2-regular.woff","site-lib/fonts/mathjax_size3-regular.woff","site-lib/fonts/mathjax_size4-regular.woff","site-lib/fonts/mathjax_ams-regular.woff","site-lib/fonts/mathjax_calligraphic-regular.woff","site-lib/fonts/mathjax_calligraphic-bold.woff","site-lib/fonts/mathjax_fraktur-regular.woff","site-lib/fonts/mathjax_fraktur-bold.woff","site-lib/fonts/mathjax_sansserif-regular.woff","site-lib/fonts/mathjax_sansserif-bold.woff","site-lib/fonts/mathjax_sansserif-italic.woff","site-lib/fonts/mathjax_script-regular.woff","site-lib/fonts/mathjax_typewriter-regular.woff","site-lib/fonts/mathjax_vector-regular.woff","site-lib/fonts/mathjax_vector-bold.woff","site-lib/html/file-tree-content.html","site-lib/scripts/webpage.js","site-lib/scripts/graph-wasm.js","site-lib/scripts/graph-render-worker.js","site-lib/media/favicon.png","site-lib/styles/obsidian.css","site-lib/styles/global-variable-styles.css","site-lib/styles/main-styles.css"],"webpages":{"natural-language-processing/01.-introduction.html":{"title":"01. Introduction","icon":"","description":"NLP: Algorithms to process, analyze and understand texts in natural language\nUnderstanding structure\nUnderstanding meaning Ambiguity, e.g., bank\nCompositionality, e.g., green thumb\nCo-reference, e.g., if the baby does not like the milk, boil it\nLiving language, e.g., Eyjafjallajökull\nRare events\n<img alt=\"Pasted image 20251126022044.png\" src=\"attachments/pasted-image-20251126022044.png\" target=\"_self\">\nCorpus = large collection of annotated texts (or speech files)\nLinguistics\nMachine learning\nNLP tasks: Information Extraction + Retrieval\nSummarization\nMachine translation\nQuestion Answering\nPersonal assistant NLP techniques (focus on deep learning-based): Data types Texts, e.g., Brown Corpus, Penn Treebank\nDictionaries/Ontologies, e.g., WordNet, GermaNet, EuroWordNet Data grows English Text Corpora (News)\nComputer MT or ASR systems train on &gt;&gt; 1GWords. News Shuffle, GigaWord, Europarl, VideoLectures, …\nHuman speaks 0.5 GigaWords in a Lifetime! Model types Classification, e.g., word sense disambiguation\nSequence Classification, e.g., sentiment analysis\nSequence labeling, e.g., named entity recognition\nSequence to Sequence model, e.g., summerization\nStructure prediction, e.g., parsing Evaluation: Human evaluation\nAutomatic evaluation ","aliases":[],"inlineTags":[],"frontmatterTags":[],"headers":[{"heading":"1. Introduction","level":1,"id":"1._Introduction_0"},{"heading":"Challenges","level":2,"id":"Challenges_0"},{"heading":"History","level":2,"id":"History_0"},{"heading":"Content","level":2,"id":"Content_0"}],"links":[],"author":"","coverImageURL":".","fullURL":"natural-language-processing/01.-introduction.html","pathToRoot":"..","attachments":["attachments/pasted-image-20251126022044.png"],"createdTime":1764119987596,"modifiedTime":1764120046435,"sourceSize":1351,"sourcePath":"Natural Language Processing/01. Introduction.md","exportPath":"natural-language-processing/01.-introduction.html","showInTree":true,"treeOrder":1,"backlinks":[],"type":"markdown"},"index.html":{"title":"Home","icon":"","description":"This is where I take notes.","aliases":[],"inlineTags":[],"frontmatterTags":[],"headers":[],"links":[],"author":"","coverImageURL":"","fullURL":"index.html","pathToRoot":".","attachments":[],"createdTime":1764119564819,"modifiedTime":1764119936865,"sourceSize":47,"sourcePath":"index.md","exportPath":"index.html","showInTree":true,"treeOrder":2,"backlinks":[],"type":"markdown"},"natural-language-processing/02.-words.html":{"title":"02. Words","icon":"","description":"Example (Chinese): 我看书 — “I read/look at a book.”. Morphemes:\n我 = I\n看 = read/look\n书 = book\nKey idea: Minimal or no inflection; morphemes usually stand alone.Example (Turkish): ev-ler-in-de — “in your houses”. Morphemes:\nev = house\n-ler = plural\n-in = your\n-de = in\nKey idea: Morphemes have clear boundaries and single meanings, attached in sequence.Example (Spanish): habl-o — “I speak”. Morphemes:\nhabl- = speak\n-o = 1st person + singular + present\nKey idea: A single morpheme typically encodes multiple grammatical features.Example (Inuktitut): tusaatsiarunnanngittualuujunga — “I really can’t hear well”. Simplified morphemes:\ntusaa- = hear\n-tsiaq- = well\n-junnaq- = be able\n-nngit- = not\n-tualuu- = very\n-junga = I\nKey idea: Many morphemes combine to express what would be a whole sentence.Example (Arabic): kitaab — “book”. Morphemes:\nk-t-b = root “write”\ni__a__ = vocalic pattern forming a noun\nKey idea: Words are formed by inserting vocalic patterns into consonantal roots.\nLexeme, e.g., SEE\nWord-form, e.g., saw, seeing, saws\nParadigm, e.g., I, my, mine, me\nWord family, e.g., act, action, actor, activate, active, activist Lexical/Content\nFunctional\nRoot Suffix\nPrefix\nInfix\nCircumfix Changes the grammatical form of a word without creating a new lexeme.\nDoes not change core meaning or word class.\nTypical categories: tense, number, case, agreement.\nExamples:\nwalk → walks (3sg)\ncat → cats (plural)\nsee → saw (past) Forms a new word (new lexeme) by adding derivational affixes.\nOften changes meaning and sometimes word class.\nExamples:\nhappy → unhappy\nnation → national\nmodern → modernize\nread → reader Combines two or more roots/words to form a new lexeme.\nThe components remain recognizable.\nExamples:\nblack + board → blackboard\nsun + light → sunlight\nice + cream → ice-cream\nHere’s a concise English note summarizing the morphological processes you listed, with clear examples:\nMaps a word form to its lemma (dictionary/base form).\nIgnores context.\nExample:\nsaw → see Lemma and Lexeme are different. Lexeme is an abstract concept, while lemma is a concrete concept. Breaks a word into (lemma + grammatical tag).\nDoes not consider context, so may produce multiple analyses.\nExample:\nsaw → {(see, verb.past), (saw, noun.sg)} Uses context to select the correct analysis.\nExample:\nSentence: Peter saw her\nsaw → {(see, verb.past)} Splits a word into its smallest meaningful units (morphemes).\nExample:\nde-nation-al-iz-ation → de + nation + al + iz + ation Produces a word form from a lemma + features.\nEssentially the reverse of lemmatization.\nExample:\n(see, verb.past) → saw\nBoth Feature Engineering (FE) and Representation Learning (RL) are methodologies designed to solve the critical challenge in machine learning models: how to map text into a fixed vector representation, or .However, they differ fundamentally in their approach, timeframe, and resulting data structure.Feature Engineering (FE) represents the dominant methods used over the last 25 years. This approach relies on manually defined templates to describe the important information of the text. FE is often decried as “costly, hand-crafted, expensive, domain-specific,” among other criticisms. While simple features typically give the bulk of the performance and can yield high accuracies, the feature set is still difficult to maintain.Representation Learning (RL) describes the methods developed over the last 10 years. The defining characteristic of RL is that the features are automatically learned. The result of this process is an approximation, meaning some information are lost, and the representation is typically task dependent.The methodologies lead to stark differences in the resulting vector format:\nFE commonly uses representations like the Bag of Words (BoW). This approach results in a Sparse matrix, where most entries are zero. BoW uses one feature per word, which can be a Binary feature (0 or 1) or a Count feature. Feature Importance and TF-IDF can help solve problems respectively about word importance and high-frequently used no-meaning words.\nRL generates a Neural representation, which is characterized as Dense. Negation: It's not a great monster movie.\nDifferent sense: There's a great deal of corny dialogue and preposterous moments.\nMultiple sentiments: A great ensemble cast can't lift this heartfelt enterprise out of the familiar.\nNumber of features: Too few. Hard to distinguish different inputs\nToo many. Overfitting Representation Learning evolved to better handle critical challenges inherent in text data that constrained Feature Engineering:\nWord Order and Length: FE methods like BoW ignore word position when dealing with variable length input. Although FE can use Higher-Order Binary Feature Templates (like bigrams or trigrams) to consider word order and maintain a fixed size vector representation, this introduces the challenge of an extremely large number of features. Conversely, RL must address the fact that word order is important and must handle variable length input.\nOpen Vocabulary: For FE, open vocabulary is a challenge that requires the use of a fixed vocab. RL also faces the open vocabulary challenge, but aims to solve it by being able to understand unknown words, such as the complex term Hippopotomonstrosesquipedaliophobia.\nGranularity: RL’s approach to solving vocabulary challenges involves identifying the best granularity—choosing among words, subwords, or characters. RL acknowledges that while using characters provides much training data and allows understanding of unknown words, it leads to long sequences for text, which is not efficient. Therefore, RL uses machine learning based subword segmentation to learn efficient representation. Techniques like Byte-Pair Encoding (BPE), which starts with an Initial vocabulary of characters to ensure every words can be represented, are employed to strike this balance.\n","aliases":[],"inlineTags":[],"frontmatterTags":[],"headers":[{"heading":"2. Words","level":1,"id":"2._Words_0"},{"heading":"Morphology","level":2,"id":"Morphology_0"},{"heading":"Morphology and Languages","level":3,"id":"Morphology_and_Languages_0"},{"heading":"1. Isolating Languages","level":4,"id":"1._Isolating_Languages_0"},{"heading":"2. Agglutinative Languages","level":4,"id":"2._Agglutinative_Languages_0"},{"heading":"3. Fusional (Inflectional) Languages","level":4,"id":"3._Fusional_(Inflectional)_Languages_0"},{"heading":"4. Polysynthetic Languages","level":4,"id":"4._Polysynthetic_Languages_0"},{"heading":"5. Root-and-Pattern Languages","level":4,"id":"5._Root-and-Pattern_Languages_0"},{"heading":"Concepts of morphology","level":3,"id":"Concepts_of_morphology_0"},{"heading":"Types of morphemes","level":3,"id":"Types_of_morphemes_0"},{"heading":"1. Stem","level":4,"id":"1._Stem_0"},{"heading":"2. Affixes","level":4,"id":"2._Affixes_0"},{"heading":"Word Formation","level":3,"id":"Word_Formation_0"},{"heading":"1. Inflection","level":4,"id":"1._Inflection_0"},{"heading":"2. Derivation","level":4,"id":"2._Derivation_0"},{"heading":"3. Compounding","level":4,"id":"3._Compounding_0"},{"heading":"Morphology Tasks","level":3,"id":"Morphology_Tasks_0"},{"heading":"1. Lemmatization","level":4,"id":"1._Lemmatization_0"},{"heading":"2. Morphological Analysis","level":4,"id":"2._Morphological_Analysis_0"},{"heading":"3. Tagging (Morphosyntactic Disambiguation)","level":4,"id":"3._Tagging_(Morphosyntactic_Disambiguation)_0"},{"heading":"4. Morpheme Segmentation","level":4,"id":"4._Morpheme_Segmentation_0"},{"heading":"5. Generation","level":4,"id":"5._Generation_0"},{"heading":"Machine Learning in NLP","level":2,"id":"Machine_Learning_in_NLP_0"},{"heading":"Feature Engineering vs. Representation Learning","level":3,"id":"Feature_Engineering_vs._Representation_Learning_0"},{"heading":"1. Core Philosophy and Timeframe","level":4,"id":"1._Core_Philosophy_and_Timeframe_0"},{"heading":"2. Representation Format and Structure","level":4,"id":"2._Representation_Format_and_Structure_0"},{"heading":"3. Issues of Feature Engineering","level":4,"id":"3._Issues_of_Feature_Engineering_0"},{"heading":"4. Handling Language Challenges","level":4,"id":"4._Handling_Language_Challenges_0"}],"links":[],"author":"","coverImageURL":"","fullURL":"natural-language-processing/02.-words.html","pathToRoot":"..","attachments":[],"createdTime":1764120293371,"modifiedTime":1764120585497,"sourceSize":6983,"sourcePath":"Natural Language Processing/02. Words.md","exportPath":"natural-language-processing/02.-words.html","showInTree":true,"treeOrder":2,"backlinks":[],"type":"markdown"},"natural-language-processing/03.-neural-word-representation.html":{"title":"03. Neural Word Representation","icon":"","description":"NLP has undergone a major transformation over the past few decades, shifting from traditional statistical methods to modern neural network-based approaches.Early NLP systems relied heavily on statistical language models (SLMs). These models estimate the probability of a word sequence based on observed frequencies in large text corpora. N-gram models is one of the most common approaches, which predict the next word given the previous n−1 words. For example, a trigram model predicts the next word based on the previous two words.However, SLMs have limitations about data sparsity, context window, and feature engineering (SLMs often required manual preprocessing and feature extraction).In the part, we will focus on neural network based methods.Word Embedding is one of Dense Embeddings. Dense vector has the following advantages: Short vectors may be easier to use as features in machine learning (less weights to tune) Dense vectors may generalize better than storing explicit counts They may do better at capturing synonymy: car and automobile are synonyms; but are distinct dimensions\na word with car as a neighbor and a word with automobile as a neighbor should be similar, but aren’t In practice, they appear to work better So can we convert one-hot (Sparse) to Dense Embeddings? Assume there is a matrix W. We can multiply our one-hot with W. This gives us the “embedding” for a word. W is what we need to learn (in the context of machine learning).\nPlease read Q&amp;A for more details. Word2Vec CBOW Skip-gram Negative sampling Fasttext character representation Glove Q: What is the relationship between the corpus-based approach and feature engineering? A: In traditional Corpus-based Approaches to NLP, feature extraction is an explicit process. This feature extraction defines the features used by the statistical model, such as the word ID, case, and POS tags (e.g., Word: 546; Case: Upper-case; POS: NN). In Deep Learning Approaches, the input text still undergoes feature extraction, but the output is a dense binary vector (e.g., 10010010010101). Therefore, feature engineering is the traditional method of explicit feature extraction from the corpus, which has been largely replaced by automatic feature learning in deep learning.Q: What is an important property of word embeddings? A: An important property of word embeddings is that semantic similar words should have similar representation. This concept is tied to J.R. Firth’s 1953 dictum: “You shall know a word by the company it keeps!”.Q: What determines the size of one-hot embeddings? A: The size, or dimension, of a one-hot encoding vector is determined by the vocabulary size.Q: What is an advantage of dense embeddings? A: Dense vectors have several advantages: they are short vectors, may generalize better, and appear to work better in practice, especially at capturing synonymy.Q: What is a problem with n-gram models? A: A major problem with statistical N-gram models is that most longer word sequences have not been seen in the corpus. This requires a non-satisfactory solution like back-off to a shorter sequence. N-gram models also operate in Discrete Space.Q: Why do we call the Feed Forward Neural Network here self-supervised? A: The Feed Forward Neural Network language model is considered self-supervised because training needs only unlabelled data (pure text). The model is trained to predict the next word given previous words. The meaning of the word is important for estimating the next word, and this meaning needs to be encoded in the embedding.Q: What is the advantage of a continuous space? A: The advantage of mapping words to a continuous word representation is generalization to similar n-grams. Unlike discrete space, which only allows for exact matching, continuous space enables the model to automatically learn optimal features and find the nearest neighbor, capturing syntactic similarities and semantic similarities.Q: Is the position of the input words important? A: For the Continuous Bag of Words Model (CBOW), the position of the input words is ignored. The model sums the surrounding words to predict the center word.Q: How many embeddings do we get for each word? A: For Word2Vec models (CBOW and Skip-gram), typically there is one embedding for each word.\nMore details: <a data-tooltip-position=\"top\" aria-label=\"https://lilianweng.github.io/posts/2017-10-15-word-embedding/\" rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://lilianweng.github.io/posts/2017-10-15-word-embedding/\" target=\"_self\">Learning Word Embedding</a> <br><a data-tooltip-position=\"top\" aria-label=\"https://medium.com/@fraidoonomarzai99/word2vec-cbow-skip-gram-in-depth-88d9cc340a50\" rel=\"noopener nofollow\" class=\"external-link is-unresolved\" href=\"https://medium.com/@fraidoonomarzai99/word2vec-cbow-skip-gram-in-depth-88d9cc340a50\" target=\"_self\">Word2Vec (CBOW, Skip-gram) In Depth</a> Q: What is the CBOW score function based on? A: The CBOW score function is based on the dot product to measure similarity.Q: What is the difference between CBOW and Skip-gram? A: CBOW and Skip-gram have opposite objectives:\nCBOW predicts the word based on surrounding words.\nSkip-gram predicts the surrounding words given the current word.\nQ: What is maximized with the Skip-gram objective? A: The Skip-gram objective is to maximize the probability of any context word given the current word. This objective uses a negative log loss.Q: Why is negative sampling necessary? A: Negative sampling is necessary because the standard Skip-gram objective requires normalization over the entire vocabulary, which is computationally demanding. Negative sampling resolves this by generating samples and summing over those samples instead of the entire vocabulary.Q: Why do we use sigmoid instead of softmax in the objective function? A: We use the Sigmoid function () because negative sampling converts the problem from a multiclass classifier to a binary classifier.Q: Where do we get negative examples from? A: Negative examples are sampled from the lexicon. The negative set typically contains 2 to 20 words sampled from some distribution, such as uniform, unigram, or a smoothed unigram. The smoothed unigram distribution is created by raising the probabilities to the power of and then renormalizing.Q: For a corpus with fixed size, are there more unique 6-grams or 3-grams? A: Based on the problem of N-gram models—that most longer word sequences have not been seen—it can be inferred that there would be more unique 6-grams than 3-grams, as longer sequences lead to higher sparsity.Q: How are context and target words represented with FastText? A: FastText uses character N-grams:A: FastText uses character N-grams:\nThe word embedding for the target word is the sum of character 3-grams to 6-grams and the whole word itself.\nThe word embedding for the context word is taken from the embedding table without adding character n-grams.\nQ: What is the difference between Word2Vec and FastText? A: FastText is an extension of Word2Vec that addresses challenges found in Word2Vec. FastText uses subword representation (character n-grams) to solve issues in morphologically rich languages and to create representations for words that have not been seen previously.Q: What is a key difference between Word2Vec and GloVe? A: The key difference lies in the perspective used for training: Word2Vec uses a Local view (predicting words within the context), while GloVe uses a Global view. GloVe leverages Word co-occurrence matrices and is motivated by the ratio of co-occurrence probabilities.Q: In which situations does GloVe likely produce unreliable word embeddings?\nRare words – too few co-occurrences to learn meaningful vectors.\nSmall corpus – global statistics are sparse and noisy.\nDomain mismatch – training domain differs from the target domain.\nPolysemous words – one vector cannot represent multiple senses.\nNo subword modeling – fails on morphology and misspellings.\nOut-of-vocabulary words – no embeddings for unseen words.\nBiased training data – co-occurrence statistics reflect and amplify bias.\n","aliases":[],"inlineTags":[],"frontmatterTags":[],"headers":[{"heading":"3. Neural Word Representation","level":1,"id":"3._Neural_Word_Representation_0"},{"heading":"Word Embeddings","level":2,"id":"Word_Embeddings_0"},{"heading":"Language Models","level":2,"id":"Language_Models_0"},{"heading":"Q&amp;A","level":2,"id":"Q&A_0"}],"links":[],"author":"","coverImageURL":"","fullURL":"natural-language-processing/03.-neural-word-representation.html","pathToRoot":"..","attachments":[],"createdTime":1764120769803,"modifiedTime":1764121486799,"sourceSize":8614,"sourcePath":"Natural Language Processing/03. Neural Word Representation.md","exportPath":"natural-language-processing/03.-neural-word-representation.html","showInTree":true,"treeOrder":3,"backlinks":[],"type":"markdown"},"natural-language-processing/04.-sentence-structure.html":{"title":"04. Sentence Structure","icon":"","description":"Here is the note again, now with math symbols wrapped in $...$ while preserving all content and keeping your previous bold formatting:Part-of-Speech (POS): POS tags classify words based on their grammatical relationship and functional category (e.g., noun, verb) in context. This differs from word sense (meaning).\nClassification: Words belong to Open classes (lexical words) (Nouns, Verbs, Adjectives, etc.) or Closed classes (functional) (Determiners, Pronouns, Conjunctions).\nUniversal Tag Set: Smaller, coarser sets (like the 12-tag Universal Tag Set) are used for cross-lingual purposes.\nChallenge (Ambiguity): Many word instances are ambiguous, meaning the same word type can have multiple POS tags (e.g., \"back\" can be JJ, NN, RB, or VB). POS tagging is the process of determining the correct tag for a word given its context.\nSyntax studies how words organize into hierarchical units called constituents (phrases). Only entire phrases, such as a Prepositional Phrase (PP), can be moved within a sentence. Context Free Grammar: Introduced by Chomsky, CFG is a formal system used to generate sentences and assign parse trees. Non-terminals () are phrase variables (NP, VP), and Terminals () are the actual words. Phrase Structure Grammar: This applies CFG rules to define natural language structures (e.g., Declarative sentences are NP VP). Subcategorization: Verbs enforce constraints on the required accompanying phrases; e.g., Transitive verbs require a direct object, while Intransitive verbs do not.\nAmbiguity: A sentence can have multiple correct parse trees (Structural Ambiguity). This includes Attachment ambiguity and Coordination ambiguity. Lexicalized Grammars (e.g., Combinatory Categorial Grammar): These models use a lexicon to encode complex grammatical dependencies like Agreement, Subcategorization, and Long-distance dependencies. Words are assigned detailed categories (e.g., the verb \"Cancel\" has the category ). Forward rule application ()\nBackward rule application ()\n<img alt=\"Pasted image 20251126025040.png\" src=\"attachments/pasted-image-20251126025040.png\" target=\"_self\"> Dependency Grammar: This approach describes structure using directed binary relations (typed relations) between a head and its dependent. Graph : Vertices correspond to words\n: Arcs corresponding to relations Restrictions: Connected\nDesignated root node\n<br>Acyclic (connected acyclic graph is a tree) or planar <img alt=\"Pasted image 20251126025053.png\" src=\"attachments/pasted-image-20251126025053.png\" target=\"_self\"> Language Models automatically learn sentence structure by assigning a Probability to a sentence.Simple counting fails due to sparse data; many valid but unseen sentences are assigned a probability of zero.Solution: Chain Rule.E.g.,Estimating the probability of a word from its full history is intractable.Solution: Markov Assumption.\nThe probability of a word depends only on the previous words.N-gram Models: Unigram, Bigram, Trigram, etc. Though insufficient for capturing long-distance dependencies, they are practical.<br><img alt=\"Pasted image 20251126025309.png\" src=\"attachments/pasted-image-20251126025309.png\" target=\"_self\">MLE estimates N-gram probabilities by maximizing the likelihood of training data.<br><img alt=\"Pasted image 20251126025315.png\" src=\"attachments/pasted-image-20251126025315.png\" target=\"_self\">A key challenge persists: if an N-gram is an unseen event (count = 0), its probability is 0, making the entire sentence probability 0.If you'd like, I can also format these into a printable PDF, add color themes, or convert into study flashcards.","aliases":[],"inlineTags":[],"frontmatterTags":[],"headers":[{"heading":"4. Sentence Structure","level":1,"id":"4._Sentence_Structure_0"},{"heading":"Word Classes","level":2,"id":"Word_Classes_0"},{"heading":"Syntax","level":2,"id":"Syntax_0"},{"heading":"Language Model","level":2,"id":"Language_Model_0"},{"heading":"Challenge","level":3,"id":"Challenge_0"},{"heading":"Another Challenge","level":3,"id":"Another_Challenge_0"},{"heading":"Maximum Likelihood Estimation (MLE)","level":3,"id":"Maximum_Likelihood_Estimation_(MLE)_0"}],"links":[],"author":"","coverImageURL":".","fullURL":"natural-language-processing/04.-sentence-structure.html","pathToRoot":"..","attachments":["attachments/pasted-image-20251126025040.png","attachments/pasted-image-20251126025053.png","attachments/pasted-image-20251126025309.png","attachments/pasted-image-20251126025315.png"],"createdTime":1764121582042,"modifiedTime":1764122058140,"sourceSize":4246,"sourcePath":"Natural Language Processing/04. Sentence Structure.md","exportPath":"natural-language-processing/04.-sentence-structure.html","showInTree":true,"treeOrder":4,"backlinks":[],"type":"markdown"}},"fileInfo":{"natural-language-processing/01.-introduction.html":{"createdTime":1764119987596,"modifiedTime":1764120046435,"sourceSize":1351,"sourcePath":"Natural Language Processing/01. Introduction.md","exportPath":"natural-language-processing/01.-introduction.html","showInTree":true,"treeOrder":1,"backlinks":[],"type":"markdown","data":null},"index.html":{"createdTime":1764119564819,"modifiedTime":1764119936865,"sourceSize":47,"sourcePath":"index.md","exportPath":"index.html","showInTree":true,"treeOrder":2,"backlinks":[],"type":"markdown","data":null},"site-lib/scripts/graph-wasm.wasm":{"createdTime":1764120054564,"modifiedTime":1764119648449.3892,"sourceSize":23655,"sourcePath":"","exportPath":"site-lib/scripts/graph-wasm.wasm","showInTree":false,"treeOrder":0,"backlinks":[],"type":"other","data":null},"site-lib/fonts/94f2f163d4b698242fef.otf":{"createdTime":1764122069118,"modifiedTime":1764122069118,"sourceSize":66800,"sourcePath":"","exportPath":"site-lib/fonts/94f2f163d4b698242fef.otf","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/72505e6a122c6acd5471.woff2":{"createdTime":1764122069119,"modifiedTime":1764122069119,"sourceSize":104232,"sourcePath":"","exportPath":"site-lib/fonts/72505e6a122c6acd5471.woff2","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/2d5198822ab091ce4305.woff2":{"createdTime":1764122069119,"modifiedTime":1764122069119,"sourceSize":104332,"sourcePath":"","exportPath":"site-lib/fonts/2d5198822ab091ce4305.woff2","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/c8ba52b05a9ef10f4758.woff2":{"createdTime":1764122069119,"modifiedTime":1764122069119,"sourceSize":98868,"sourcePath":"","exportPath":"site-lib/fonts/c8ba52b05a9ef10f4758.woff2","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/cb10ffd7684cd9836a05.woff2":{"createdTime":1764122069119,"modifiedTime":1764122069119,"sourceSize":106876,"sourcePath":"","exportPath":"site-lib/fonts/cb10ffd7684cd9836a05.woff2","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/293fd13dbca5a3e450ef.woff2":{"createdTime":1764122069119,"modifiedTime":1764122069119,"sourceSize":105924,"sourcePath":"","exportPath":"site-lib/fonts/293fd13dbca5a3e450ef.woff2","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/085cb93e613ba3d40d2b.woff2":{"createdTime":1764122069120,"modifiedTime":1764122069120,"sourceSize":112184,"sourcePath":"","exportPath":"site-lib/fonts/085cb93e613ba3d40d2b.woff2","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/b5f0f109bc88052d4000.woff2":{"createdTime":1764122069120,"modifiedTime":1764122069120,"sourceSize":105804,"sourcePath":"","exportPath":"site-lib/fonts/b5f0f109bc88052d4000.woff2","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/cbe0ae49c52c920fd563.woff2":{"createdTime":1764122069120,"modifiedTime":1764122069120,"sourceSize":106108,"sourcePath":"","exportPath":"site-lib/fonts/cbe0ae49c52c920fd563.woff2","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/535a6cf662596b3bd6a6.woff2":{"createdTime":1764122069119,"modifiedTime":1764122069119,"sourceSize":111708,"sourcePath":"","exportPath":"site-lib/fonts/535a6cf662596b3bd6a6.woff2","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/70cc7ff27245e82ad414.ttf":{"createdTime":1764122069120,"modifiedTime":1764122069120,"sourceSize":192740,"sourcePath":"","exportPath":"site-lib/fonts/70cc7ff27245e82ad414.ttf","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/454577c22304619db035.ttf":{"createdTime":1764122069120,"modifiedTime":1764122069120,"sourceSize":161376,"sourcePath":"","exportPath":"site-lib/fonts/454577c22304619db035.ttf","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/52ac8f3034507f1d9e53.ttf":{"createdTime":1764122069120,"modifiedTime":1764122069120,"sourceSize":191568,"sourcePath":"","exportPath":"site-lib/fonts/52ac8f3034507f1d9e53.ttf","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/05b618077343fbbd92b7.ttf":{"createdTime":1764122069120,"modifiedTime":1764122069120,"sourceSize":155288,"sourcePath":"","exportPath":"site-lib/fonts/05b618077343fbbd92b7.ttf","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/4bb6ac751d1c5478ff3a.woff2":{"createdTime":1764122069118,"modifiedTime":1764122069118,"sourceSize":7876,"sourcePath":"","exportPath":"site-lib/fonts/4bb6ac751d1c5478ff3a.woff2","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/media/6155340132a851f6089e.svg":{"createdTime":1764122069118,"modifiedTime":1764122069118,"sourceSize":315,"sourcePath":"","exportPath":"site-lib/media/6155340132a851f6089e.svg","showInTree":false,"treeOrder":0,"backlinks":[],"type":"media","data":null},"site-lib/media/2308ab1944a6bfa5c5b8.svg":{"createdTime":1764122069118,"modifiedTime":1764122069118,"sourceSize":278,"sourcePath":"","exportPath":"site-lib/media/2308ab1944a6bfa5c5b8.svg","showInTree":false,"treeOrder":0,"backlinks":[],"type":"media","data":null},"site-lib/html/file-tree-content.html":{"createdTime":1764122069200,"modifiedTime":1764122069200,"sourceSize":2951,"sourcePath":"","exportPath":"site-lib/html/file-tree-content.html","showInTree":false,"treeOrder":0,"backlinks":[],"type":"html","data":null},"site-lib/scripts/webpage.js":{"createdTime":1764120276964,"modifiedTime":1764120276964,"sourceSize":110729,"sourcePath":"","exportPath":"site-lib/scripts/webpage.js","showInTree":false,"treeOrder":0,"backlinks":[],"type":"script","data":null},"site-lib/scripts/graph-wasm.js":{"createdTime":1764120276964,"modifiedTime":1764120276964,"sourceSize":12885,"sourcePath":"","exportPath":"site-lib/scripts/graph-wasm.js","showInTree":false,"treeOrder":0,"backlinks":[],"type":"script","data":null},"site-lib/scripts/graph-render-worker.js":{"createdTime":1764120276964,"modifiedTime":1764120276964,"sourceSize":5681,"sourcePath":"","exportPath":"site-lib/scripts/graph-render-worker.js","showInTree":false,"treeOrder":0,"backlinks":[],"type":"script","data":null},"site-lib/media/favicon.png":{"createdTime":1764122069071,"modifiedTime":1764122069071,"sourceSize":1105,"sourcePath":"","exportPath":"site-lib/media/favicon.png","showInTree":false,"treeOrder":0,"backlinks":[],"type":"media","data":null},"site-lib/styles/obsidian.css":{"createdTime":1764122069151,"modifiedTime":1764122069151,"sourceSize":205827,"sourcePath":"","exportPath":"site-lib/styles/obsidian.css","showInTree":false,"treeOrder":0,"backlinks":[],"type":"style","data":null},"site-lib/styles/global-variable-styles.css":{"createdTime":1764122069112,"modifiedTime":1764122069112,"sourceSize":305,"sourcePath":"","exportPath":"site-lib/styles/global-variable-styles.css","showInTree":false,"treeOrder":0,"backlinks":[],"type":"style","data":null},"site-lib/styles/main-styles.css":{"createdTime":1764120276999,"modifiedTime":1764120276999,"sourceSize":19521,"sourcePath":"","exportPath":"site-lib/styles/main-styles.css","showInTree":false,"treeOrder":0,"backlinks":[],"type":"style","data":null},"attachments/pasted-image-20251126022044.png":{"createdTime":1764120044427,"modifiedTime":1764120044427,"sourceSize":90037,"sourcePath":"attachments/Pasted image 20251126022044.png","exportPath":"attachments/pasted-image-20251126022044.png","showInTree":false,"treeOrder":0,"backlinks":[],"type":"media","data":null},"site-lib/rss.xml":{"createdTime":1764122069527,"modifiedTime":1764122069527,"sourceSize":21168,"sourcePath":"","exportPath":"site-lib/rss.xml","showInTree":false,"treeOrder":0,"backlinks":[],"type":"other","data":null},"natural-language-processing/02.-words.html":{"createdTime":1764120293371,"modifiedTime":1764120585497,"sourceSize":6983,"sourcePath":"Natural Language Processing/02. Words.md","exportPath":"natural-language-processing/02.-words.html","showInTree":true,"treeOrder":2,"backlinks":[],"type":"markdown","data":null},"site-lib/fonts/mathjax_zero.woff":{"createdTime":1764121499557,"modifiedTime":1764121499557,"sourceSize":1368,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_zero.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/mathjax_main-regular.woff":{"createdTime":1764121499557,"modifiedTime":1764121499557,"sourceSize":34160,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_main-regular.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/mathjax_main-bold.woff":{"createdTime":1764121499557,"modifiedTime":1764121499557,"sourceSize":34464,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_main-bold.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/mathjax_math-italic.woff":{"createdTime":1764121499557,"modifiedTime":1764121499557,"sourceSize":19360,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_math-italic.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/mathjax_main-italic.woff":{"createdTime":1764121499557,"modifiedTime":1764121499557,"sourceSize":20832,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_main-italic.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/mathjax_math-bolditalic.woff":{"createdTime":1764121499557,"modifiedTime":1764121499557,"sourceSize":19776,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_math-bolditalic.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/mathjax_size1-regular.woff":{"createdTime":1764121499557,"modifiedTime":1764121499557,"sourceSize":5792,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_size1-regular.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/mathjax_size2-regular.woff":{"createdTime":1764121499557,"modifiedTime":1764121499557,"sourceSize":5464,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_size2-regular.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/mathjax_size3-regular.woff":{"createdTime":1764121499558,"modifiedTime":1764121499558,"sourceSize":3244,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_size3-regular.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/mathjax_size4-regular.woff":{"createdTime":1764121499558,"modifiedTime":1764121499558,"sourceSize":5148,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_size4-regular.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/mathjax_ams-regular.woff":{"createdTime":1764121499558,"modifiedTime":1764121499558,"sourceSize":40808,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_ams-regular.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/mathjax_calligraphic-regular.woff":{"createdTime":1764121499558,"modifiedTime":1764121499558,"sourceSize":9600,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_calligraphic-regular.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/mathjax_calligraphic-bold.woff":{"createdTime":1764121499558,"modifiedTime":1764121499558,"sourceSize":9908,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_calligraphic-bold.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/mathjax_fraktur-regular.woff":{"createdTime":1764121499558,"modifiedTime":1764121499558,"sourceSize":21480,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_fraktur-regular.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/mathjax_fraktur-bold.woff":{"createdTime":1764121499558,"modifiedTime":1764121499558,"sourceSize":22340,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_fraktur-bold.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/mathjax_sansserif-regular.woff":{"createdTime":1764121499558,"modifiedTime":1764121499558,"sourceSize":12660,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_sansserif-regular.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/mathjax_sansserif-bold.woff":{"createdTime":1764121499558,"modifiedTime":1764121499558,"sourceSize":15944,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_sansserif-bold.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/mathjax_sansserif-italic.woff":{"createdTime":1764121499558,"modifiedTime":1764121499558,"sourceSize":14628,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_sansserif-italic.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/mathjax_script-regular.woff":{"createdTime":1764121499558,"modifiedTime":1764121499558,"sourceSize":11852,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_script-regular.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/mathjax_typewriter-regular.woff":{"createdTime":1764121499558,"modifiedTime":1764121499558,"sourceSize":17604,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_typewriter-regular.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/mathjax_vector-regular.woff":{"createdTime":1764121499558,"modifiedTime":1764121499558,"sourceSize":1136,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_vector-regular.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"site-lib/fonts/mathjax_vector-bold.woff":{"createdTime":1764121499558,"modifiedTime":1764121499558,"sourceSize":1116,"sourcePath":"","exportPath":"site-lib/fonts/mathjax_vector-bold.woff","showInTree":false,"treeOrder":0,"backlinks":[],"type":"font","data":null},"natural-language-processing/03.-neural-word-representation.html":{"createdTime":1764120769803,"modifiedTime":1764121486799,"sourceSize":8614,"sourcePath":"Natural Language Processing/03. Neural Word Representation.md","exportPath":"natural-language-processing/03.-neural-word-representation.html","showInTree":true,"treeOrder":3,"backlinks":[],"type":"markdown","data":null},"natural-language-processing/04.-sentence-structure.html":{"createdTime":1764121582042,"modifiedTime":1764122058140,"sourceSize":4246,"sourcePath":"Natural Language Processing/04. Sentence Structure.md","exportPath":"natural-language-processing/04.-sentence-structure.html","showInTree":true,"treeOrder":4,"backlinks":[],"type":"markdown","data":null},"attachments/pasted-image-20251126025040.png":{"createdTime":1764121840043,"modifiedTime":1764121840043,"sourceSize":78874,"sourcePath":"attachments/Pasted image 20251126025040.png","exportPath":"attachments/pasted-image-20251126025040.png","showInTree":false,"treeOrder":0,"backlinks":[],"type":"media","data":null},"attachments/pasted-image-20251126025053.png":{"createdTime":1764121853728,"modifiedTime":1764121853728,"sourceSize":100088,"sourcePath":"attachments/Pasted image 20251126025053.png","exportPath":"attachments/pasted-image-20251126025053.png","showInTree":false,"treeOrder":0,"backlinks":[],"type":"media","data":null},"attachments/pasted-image-20251126025309.png":{"createdTime":1764121989941,"modifiedTime":1764121989941,"sourceSize":86923,"sourcePath":"attachments/Pasted image 20251126025309.png","exportPath":"attachments/pasted-image-20251126025309.png","showInTree":false,"treeOrder":0,"backlinks":[],"type":"media","data":null},"attachments/pasted-image-20251126025315.png":{"createdTime":1764121995701,"modifiedTime":1764121995701,"sourceSize":107061,"sourcePath":"attachments/Pasted image 20251126025315.png","exportPath":"attachments/pasted-image-20251126025315.png","showInTree":false,"treeOrder":0,"backlinks":[],"type":"media","data":null}},"sourceToTarget":{"Natural Language Processing/01. Introduction.md":"natural-language-processing/01.-introduction.html","index.md":"index.html","":"site-lib/rss.xml","attachments/Pasted image 20251126022044.png":"attachments/pasted-image-20251126022044.png","Natural Language Processing/02. Words.md":"natural-language-processing/02.-words.html","Natural Language Processing/03. Neural Word Representation.md":"natural-language-processing/03.-neural-word-representation.html","Natural Language Processing/04. Sentence Structure.md":"natural-language-processing/04.-sentence-structure.html","attachments/Pasted image 20251126025040.png":"attachments/pasted-image-20251126025040.png","attachments/Pasted image 20251126025053.png":"attachments/pasted-image-20251126025053.png","attachments/Pasted image 20251126025309.png":"attachments/pasted-image-20251126025309.png","attachments/Pasted image 20251126025315.png":"attachments/pasted-image-20251126025315.png"},"featureOptions":{"backlinks":{"featureId":"backlinks","enabled":true,"unavailable":false,"alwaysEnabled":false,"hideSettingsButton":false,"featurePlacement":{"selector":".footer","type":"start","info_selector":{"show":true,"name":"","description":"CSS selector for an element. The feature will be placed relative to this element.","placeholder":""},"info_type":{"show":true,"name":"","description":"Will this feature be placed before, after, or inside (at the beggining or end).","placeholder":"","dropdownOptions":{"Before":"before","After":"after","Start":"start","End":"end"}}},"info_featurePlacement":{"show":true,"name":"","description":"Where to place this feature on the page. (Relative to the selector)","placeholder":""},"displayTitle":"Backlinks","info_displayTitle":{"show":true,"name":"","description":"Descriptive title to show above the feature","placeholder":""}},"tags":{"featureId":"tags","enabled":true,"unavailable":false,"alwaysEnabled":false,"hideSettingsButton":false,"featurePlacement":{"selector":".header .data-bar","type":"end","info_selector":{"show":true,"name":"","description":"CSS selector for an element. The feature will be placed relative to this element.","placeholder":""},"info_type":{"show":true,"name":"","description":"Will this feature be placed before, after, or inside (at the beggining or end).","placeholder":"","dropdownOptions":{"Before":"before","After":"after","Start":"start","End":"end"}}},"info_featurePlacement":{"show":true,"name":"","description":"Where to place this feature on the page. (Relative to the selector)","placeholder":""},"displayTitle":"","info_displayTitle":{"show":true,"name":"","description":"Descriptive title to show above the feature","placeholder":""},"showInlineTags":true,"showFrontmatterTags":true,"info_showInlineTags":{"show":true,"name":"","description":"Show tags defined inside the document at the top of the page.","placeholder":""},"info_showFrontmatterTags":{"show":true,"name":"","description":"Show tags defined in the frontmatter of the document at the top of the page.","placeholder":""}},"alias":{"featureId":"aliases","enabled":true,"unavailable":false,"alwaysEnabled":false,"hideSettingsButton":false,"featurePlacement":{"selector":".header .data-bar","type":"start","info_selector":{"show":true,"name":"","description":"CSS selector for an element. The feature will be placed relative to this element.","placeholder":""},"info_type":{"show":true,"name":"","description":"Will this feature be placed before, after, or inside (at the beggining or end).","placeholder":"","dropdownOptions":{"Before":"before","After":"after","Start":"start","End":"end"}}},"info_featurePlacement":{"show":true,"name":"","description":"Where to place this feature on the page. (Relative to the selector)","placeholder":""},"displayTitle":"Aliases","info_displayTitle":{"show":true,"name":"","description":"Descriptive title to show above the feature","placeholder":""}},"properties":{"featureId":"properties","enabled":true,"unavailable":false,"alwaysEnabled":false,"hideSettingsButton":false,"featurePlacement":{"selector":".header","type":"start","info_selector":{"show":true,"name":"","description":"CSS selector for an element. The feature will be placed relative to this element.","placeholder":""},"info_type":{"show":true,"name":"","description":"Will this feature be placed before, after, or inside (at the beggining or end).","placeholder":"","dropdownOptions":{"Before":"before","After":"after","Start":"start","End":"end"}}},"info_featurePlacement":{"show":true,"name":"","description":"Where to place this feature on the page. (Relative to the selector)","placeholder":""},"displayTitle":"Properties","info_displayTitle":{"show":true,"name":"","description":"Descriptive title to show above the feature","placeholder":""},"info_hideProperties":{"show":true,"name":"","description":"A list of properties to hide from the properties view","placeholder":""}},"fileNavigation":{"featureId":"file-navigation","enabled":true,"unavailable":false,"alwaysEnabled":false,"hideSettingsButton":false,"featurePlacement":{"selector":"#left-sidebar-content","type":"end","info_selector":{"show":true,"name":"","description":"CSS selector for an element. The feature will be placed relative to this element.","placeholder":""},"info_type":{"show":true,"name":"","description":"Will this feature be placed before, after, or inside (at the beggining or end).","placeholder":"","dropdownOptions":{"Before":"before","After":"after","Start":"start","End":"end"}}},"info_featurePlacement":{"show":true,"name":"","description":"Where to place this feature on the page. (Relative to the selector)","placeholder":""},"info_includePath":{"show":false,"name":"","description":"","placeholder":""},"showCustomIcons":false,"showDefaultFolderIcons":false,"showDefaultFileIcons":false,"defaultFolderIcon":"lucide//folder","defaultFileIcon":"lucide//file","defaultMediaIcon":"lucide//file-image","exposeStartingPath":true,"info_showCustomIcons":{"show":true,"name":"","description":"Show custom icons for files and folders","placeholder":""},"info_showDefaultFolderIcons":{"show":true,"name":"","description":"Show a default icon of a folder for every folder in the tree","placeholder":""},"info_showDefaultFileIcons":{"show":true,"name":"","description":"Show a default icon of a file for every file in the tree","placeholder":""},"info_defaultFolderIcon":{"show":true,"name":"","description":"The icon to use for folders. Prefix with 'lucide//' to use a Lucide icon","placeholder":""},"info_defaultFileIcon":{"show":true,"name":"","description":"The icon to use for files. Prefix with 'lucide//' to use a Lucide icon","placeholder":""},"info_defaultMediaIcon":{"show":true,"name":"","description":"The icon to use for media files. Prefix with 'lucide//' to use a Lucide icon","placeholder":""},"info_exposeStartingPath":{"show":true,"name":"","description":"Whether or not to show the current file in the file tree when the page is first loaded","placeholder":""},"includePath":"site-lib/html/file-tree.html"},"search":{"featureId":"search","enabled":true,"unavailable":false,"alwaysEnabled":false,"hideSettingsButton":false,"featurePlacement":{"selector":"#left-sidebar .topbar-content","type":"start","info_selector":{"show":true,"name":"","description":"CSS selector for an element. The feature will be placed relative to this element.","placeholder":""},"info_type":{"show":true,"name":"","description":"Will this feature be placed before, after, or inside (at the beggining or end).","placeholder":"","dropdownOptions":{"Before":"before","After":"after","Start":"start","End":"end"}}},"info_featurePlacement":{"show":true,"name":"","description":"Where to place this feature on the page. (Relative to the selector)","placeholder":""},"displayTitle":"Search...","info_displayTitle":{"show":true,"name":"","description":"Descriptive title to show above the feature","placeholder":""}},"outline":{"featureId":"outline","enabled":true,"unavailable":false,"alwaysEnabled":false,"hideSettingsButton":false,"featurePlacement":{"selector":"#right-sidebar-content","type":"end","info_selector":{"show":true,"name":"","description":"CSS selector for an element. The feature will be placed relative to this element.","placeholder":""},"info_type":{"show":true,"name":"","description":"Will this feature be placed before, after, or inside (at the beggining or end).","placeholder":"","dropdownOptions":{"Before":"before","After":"after","Start":"start","End":"end"}}},"info_featurePlacement":{"show":true,"name":"","description":"Where to place this feature on the page. (Relative to the selector)","placeholder":""},"displayTitle":"Outline","info_displayTitle":{"show":true,"name":"","description":"Descriptive title to show above the feature","placeholder":""},"startCollapsed":false,"minCollapseDepth":0,"info_startCollapsed":{"show":true,"name":"","description":"Should the outline start collapsed?","placeholder":""},"info_minCollapseDepth":{"show":true,"name":"","description":"Only allow outline items to be collapsed if they are at least this many levels deep in the tree.","placeholder":"","dropdownOptions":{"1":1,"2":2,"No Collapse":100}}},"themeToggle":{"featureId":"theme-toggle","enabled":true,"unavailable":false,"alwaysEnabled":false,"hideSettingsButton":false,"featurePlacement":{"selector":"#right-sidebar .topbar-content","type":"start","info_selector":{"show":true,"name":"","description":"CSS selector for an element. The feature will be placed relative to this element.","placeholder":""},"info_type":{"show":true,"name":"","description":"Will this feature be placed before, after, or inside (at the beggining or end).","placeholder":"","dropdownOptions":{"Before":"before","After":"after","Start":"start","End":"end"}}},"info_featurePlacement":{"show":true,"name":"","description":"Where to place this feature on the page. (Relative to the selector)","placeholder":""},"displayTitle":"","info_displayTitle":{"show":true,"name":"","description":"Descriptive title to show above the feature","placeholder":""}},"graphView":{"featureId":"graph-view","enabled":true,"unavailable":false,"alwaysEnabled":false,"hideSettingsButton":false,"featurePlacement":{"selector":"#right-sidebar-content","type":"start","info_selector":{"show":true,"name":"","description":"CSS selector for an element. The feature will be placed relative to this element.","placeholder":""},"info_type":{"show":true,"name":"","description":"Will this feature be placed before, after, or inside (at the beggining or end).","placeholder":"","dropdownOptions":{"Before":"before","After":"after","Start":"start","End":"end"}}},"info_featurePlacement":{"show":true,"name":"","description":"Where to place this feature on the page. (Relative to the selector)","placeholder":""},"displayTitle":"Graph View","info_displayTitle":{"show":true,"name":"","description":"Descriptive title to show above the feature","placeholder":""},"showOrphanNodes":true,"showAttachments":false,"allowGlobalGraph":true,"allowExpand":true,"attractionForce":1,"linkLength":15,"repulsionForce":80,"centralForce":2,"edgePruning":100,"minNodeRadius":3,"maxNodeRadius":7,"info_showOrphanNodes":{"show":true,"name":"","description":"Show nodes that are not connected to any other nodes.","placeholder":""},"info_showAttachments":{"show":true,"name":"","description":"Show attachments like images and PDFs as nodes in the graph.","placeholder":""},"info_allowGlobalGraph":{"show":true,"name":"","description":"Allow the user to view the global graph of all nodes.","placeholder":""},"info_allowExpand":{"show":true,"name":"","description":"Allow the user to pop-out the graph view to take up the whole screen","placeholder":""},"info_attractionForce":{"show":true,"name":"","description":"How much should linked nodes attract each other? This will make the graph appear more clustered.","placeholder":""},"info_linkLength":{"show":true,"name":"","description":"How long should the links between nodes be? The shorter the links the more connected nodes will cluster together.","placeholder":""},"info_repulsionForce":{"show":true,"name":"","description":"How much should nodes repel each other? This will make disconnected parts more spread out.","placeholder":""},"info_centralForce":{"show":true,"name":"","description":"How much should nodes be attracted to the center? This will make the graph appear more dense and circular.","placeholder":""},"info_edgePruning":{"show":true,"name":"","description":"Edges with a length above this threshold will not be rendered, however they will still contribute to the simulation. This can help large tangled graphs look more organised. Hovering over a node will still display these links.","placeholder":""},"info_minNodeRadius":{"show":true,"name":"","description":"How small should the smallest nodes be? The smaller a node is the less it will attract other nodes.","placeholder":""},"info_maxNodeRadius":{"show":true,"name":"","description":"How large should the largest nodes be? Nodes are sized by how many links they have. The larger a node is the more it will attract other nodes. This can be used to create a good grouping around the most important nodes.","placeholder":""}},"sidebar":{"featureId":"sidebar","enabled":true,"unavailable":false,"alwaysEnabled":false,"hideSettingsButton":false,"allowResizing":true,"allowCollapsing":true,"rightDefaultWidth":"20em","leftDefaultWidth":"20em","info_allowResizing":{"show":true,"name":"","description":"Whether or not to allow the sidebars to be resized","placeholder":""},"info_allowCollapsing":{"show":true,"name":"","description":"Whether or not to allow the sidebars to be collapsed","placeholder":""},"info_rightDefaultWidth":{"show":true,"name":"","description":"The default width of the right sidebar","placeholder":""},"info_leftDefaultWidth":{"show":true,"name":"","description":"The default width of the left sidebar","placeholder":""}},"customHead":{"featureId":"custom-head","enabled":true,"unavailable":false,"alwaysEnabled":false,"hideSettingsButton":false,"featurePlacement":{"selector":"head","type":"end","info_selector":{"show":true,"name":"","description":"CSS selector for an element. The feature will be placed relative to this element.","placeholder":""},"info_type":{"show":true,"name":"","description":"Will this feature be placed before, after, or inside (at the beggining or end).","placeholder":"","dropdownOptions":{"Before":"before","After":"after","Start":"start","End":"end"}}},"info_featurePlacement":{"show":true,"name":"","description":"Where to place this feature on the page. (Relative to the selector)","placeholder":""},"info_includePath":{"show":false,"name":"","description":"","placeholder":""},"sourcePath":"","info_sourcePath":{"show":true,"name":"","description":"The local path to the source .html file which will be included.","placeholder":"","fileInputOptions":{"makeRelativeToVault":true,"browseButton":true}},"includePath":"site-lib/html/custom-head.html"},"document":{"featureId":"obsidian-document","enabled":true,"unavailable":false,"alwaysEnabled":true,"hideSettingsButton":false,"allowFoldingLists":true,"allowFoldingHeadings":true,"documentWidth":"40em","info_allowFoldingLists":{"show":true,"name":"","description":"Whether or not to allow lists to be folded","placeholder":""},"info_allowFoldingHeadings":{"show":true,"name":"","description":"Whether or not to allow headings to be folded","placeholder":""},"info_documentWidth":{"show":true,"name":"","description":"The width of the document","placeholder":""}},"rss":{"featureId":"rss","enabled":true,"unavailable":false,"alwaysEnabled":false,"hideSettingsButton":false,"siteUrl":"","authorName":"","info_siteUrl":{"show":true,"name":"","description":"The url that this site will be hosted at","placeholder":"https://example.com/mysite"},"info_authorName":{"show":true,"name":"","description":"The name of the author of the site","placeholder":""}},"linkPreview":{"featureId":"link-preview","enabled":true,"unavailable":false,"alwaysEnabled":false,"hideSettingsButton":true}},"modifiedTime":1764122069156,"siteName":"Lecture Notes","vaultName":"Lecture Notes","exportRoot":"","baseURL":"","pluginVersion":"1.9.2","themeName":"","bodyClasses":"publish css-settings-manager show-inline-title show-ribbon is-focused","hasFavicon":false}