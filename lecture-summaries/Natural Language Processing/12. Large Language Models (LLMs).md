
## 1 Introduction

### Natural Language Processing (NLP) Overview

Natural Language Processing (NLP) is a sub-field of artificial intelligence that deals with the **automatic analysis, processing, and generation of natural language**. NLP encompasses tasks such as text classification, translation, text summarization, text generation, and text analysis. Applications include voice control, automatic chatbots, machine learning, and search engines.

### Evolution of NLP Methods

The methodology of NLP has evolved significantly:

- **1960 (Rule-based):** Used manually created rules.
- **1990 (Statistical):** Employed corpus-based Machine-learning methods to learn from data.
- **2010 (Neural)**.
- **2020 (LLM):** Large Language Models represent a new paradigm for performing NLP tasks.

### 1.1 Multitasking and LLM Properties

LLMs possess distinct properties that allow them to perform NLP tasks under a new paradigm:

- Ability to **perform multiple tasks**.
- Reliance on **natural language task description**.
- **Zero-shot capability**, meaning they can perform unknown tasks without examples or gradient updates.
- LLMs are **pre-trained on large amounts of data**.

This contrasts with older **Single Task Models**, which required dedicated models for specific tasks (e.g., Named-Entity Recognition, Machine Translation) and necessitated learning everything for each task individually.

### Knowledge Sharing Evolution

The approach to sharing information between tasks developed through several methods:

- **Feature Representation:** Using cascaded models or adding annotations (like Named Entity annotations) to the input for downstream tasks.
- **Shared Architecture:** Training parts of the network jointly across tasks.
- **Specify Task in Input:** Including a discrete task description or a natural language description (the latter being characteristic of LLMs) within the input.

### 1.2 Application of LLMs

LLMs can be deployed in front-end or back-end configurations, each with different technical implications:

- **Back-end (Internal use):** The LLM performs a single task with a clear definition provided by the front-end. The developer optimizes the natural language prompt and must parse the LLM's response to generate the final output.
- **Front-end (User facing):** Typically involves multi-turn conversations. The user has no direct influence on the prompt; control is exerted mainly through a system prompt.

---

## 2 Model

### 2.1 Architecture

The sources highlight several sequence-to-sequence views used in LLMs:

- **Decoder-based models (Language Model):** Unidirectional models where the loss function is based on next word prediction.
- **Prefix LM:** A variation where attention is bidirectional for the prefix (input) but causal (unidirectional) for the generated output.
- **Encoder-Decoder models:** Feature a bidirectional Encoder and a unidirectional Decoder. The loss is based on next word prediction.
- **Decoder-only Architecture:** Relies on self-supervised learning, specifically next word prediction. This architecture allows for efficient training with several feedbacks per example. While it inherently lacks input/output separation and uses unidirectional processing, these limitations are mitigated by the use of large models.

### 2.2 Training (Unsupervised Pretraining)

LLMs are created by pre-training on vast amounts of data. Various unsupervised pretraining techniques exist for Encoder-Decoder architectures:

- **BART:** This approach involves **corruption of the input sequence** (e.g., Token Masking, Token Deletion, Text Infilling, Sentence Permutation, Document Rotation) and subsequent auto-regressive generation in the target text.
- **PEGASUS:** This model utilizes an Encoder-Decoder structure that incorporates both a Masked Language Model (MLM) objective and **Gap Sentence Generation (GSG)**. Gap sentences can be selected randomly, by taking the first $m$ sentences (Lead), or by using the top-$m$ scored sentences (Principal), where importance is approximated by token overlap.

---

## 3 Prompting

**Prompting** involves encouraging a pre-trained model to make specific predictions by providing a prompt that describes the task. This technique reformulates the traditional NLP task (Input X, Output Y) into a **sequence completion task**.

### Zero-shot Abilities

In zero-shot settings, LLMs perform tasks with **no examples** and **no gradient updates**, relying solely on their ability to predict the most probable next token.

- **Generative Tasks:** The task is transformed into a completion task (e.g., "The sentence 'I fly to New York' mentioned the city …").
- **Discriminative Tasks:** This involves comparing the probability of different possible text sequences.

### Prompting Process Flow

The typical prompting workflow involves several stages:

1. **Example X**
2. **Prompt Addition**
3. **Prompt**
4. **Answer Prediction**
5. **Prediction**
6. **Mapping**
7. **Answer**

### 3.1 Prompt Addition

This step involves generating a prompt using a template—a natural language description with defined slots for the Input ($\text{[X]}$) and the Answer ($\text{[Z]}$).

- **Prompt Types**:
    - **Prefix prompt:** The input text appears entirely before the answer slot $\text{[Z]}$ (e.g., "English: [X] German: [Z]"). This is typically used for sequence-to-sequence tasks like translation.
    - **Cloze prompt:** The answer slot $\text{[Z]}$ is positioned in the middle of the prompt (e.g., "[x] Overall, it was a [z] movie").

### 3.2 Answer Prediction

The LLM is used to predict the content of the answer slot $\text{[Z]}$.

- **Answer Space:** Possible answers $\text{Z}$ can be the entire vocabulary or a restricted, small subset (e.g., "Excellent, good, OK, bad, horrible").
- **Scoring Function:** The predicted likelihood of the language model is the most common scoring metric used to find the best filled prompt ($\hat{z}$). Additional scoring methods include Perplexity and the Channel method (conditional probability of the reverse direction, $P(x|c,z)$).

### 3.3 Answer Extraction

This step involves mapping the model's prediction $\text{[Z]}$ back to the desired output answer $\text{[Y]}$.

- **Answer Shape:** The predicted output can take the form of tokens (a single token), a span (short multi-token, common with cloze prompts), or a sentence (long prediction, common with prefix prompts for generation).
- **Mapping:** The prediction $\text{[Z]}$ is mapped to the final answer (Y). This can be a simple identity mapping or a complex mapping (e.g., mapping "fantastic," "interesting," or "happy" to the final sentiment label "Positive"). This process is sometimes referred to as **Answer Engineering**.
- **Discrete Answer Search:** Techniques to improve answer robustness include **Answer Paraphrasing** (summing the prediction probability over all paraphrases of the target answer, $\sum_{z' \in \text{para}(z)} P(z'|x)$), **Prune-to-search** (automatically finding restricted sets of possible answers or "verbalizations"), and **Label Decomposition**.

### 3.4 Expansion

Expanding the prompt provides additional context to improve prediction. Techniques include:

- **Prompt Ensemble:** Using multiple prompts in parallel to stabilize results and combine complementary strengths. Methods for combination include uniform averaging, weighted averaging, and majority vote for classification, or joint decoding for generation.
- **Prompt Decomposition:** Dividing a complex task into multiple sub-tasks and performing them using individual prompts.
- **Prompt Composition:** Using subprompts for sub-tasks within a composable task, such as relation extraction.

---

## 4 In-context Learning (ICL)

**In-context Learning (ICL)**, often referred to as **Few-shot learning**, involves demonstrating the answer with examples directly in the context. The model learns how to perform the task based on the provided examples, without requiring gradient updates.

- **Challenges:** The effectiveness of ICL depends on **sample selection** and **sample ordering**.
- **Sample Selection:** Choosing good examples for ICL can be done via unsupervised learning (e.g., L2 distance/cosine similarity between example and input), supervised learning (e.g., Dense Passage Retriever), or Reinforcement learning.
- **Sample Ordering:** Unsupervised methods suggest placing the most similar examples closest to the right (near the target prompt).
- ICL using few examples can achieve good performance on language understanding tasks like SuperGLUE.

---

## 5 Chain-of-Thought (COT)

Reasoning problems, such as Arithmetic Reasoning (AR), Symbolic Reasoning (SR), and Commonsense Reasoning (CR), are typically difficult for LLMs.

### Chain of Thought Concept

A **Chain of Thought (CoT)** is a series of intermediate natural language reasoning steps that lead to the final output. This intuition uses **<input, intermediate results, output> triples** instead of simple <input, output> pairs.

- **Benefits of CoT:** It leads to decomposition into easier intermediate problems, provides interpretability, and leverages the powerful prompting ability of LLMs.
- **Methods:**
    - **Few-shot CoT:** Providing the model with examples that explicitly include the intermediate reasoning steps.
    - **Zero-shot CoT:** This technique is activated by simply adding a phrase like **"Let's think step by step."** to the prompt, encouraging the model to generate the reasoning steps itself before producing the final answer. Zero-shot CoT often involves a two-step process: Reasoning Extraction followed by Answer Extraction.