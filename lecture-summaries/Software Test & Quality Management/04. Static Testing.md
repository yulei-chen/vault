

## I. Static Testing in General

Static testing is the **Analytical** component within **Software Quality Assurance (SQA)**.

### 1. Static Testing vs. Dynamic Testing

|Feature|Static Testing|Dynamic Testing|
|:--|:--|:--|
|**Program Execution**|Program is **not executed**|Program is **executed**|
|**Core Activities**|Static Analysis and **Review** (Manual)|Black-Box/White-Box Testing, Simulation, Prototyping, etc.|
|**Detection Result**|Often reveals **faults**|Often reveals failures|
|**Verification Object**|The test object is verified against a document from an **earlier construction phase**.|The resulting processes (from interpretation) are validated against a document from the construction phases.|

### 2. Static Testing Goals and Principles

The primary goal of static testing is to **find faults within a document** by intensely observing the test object.

- **Fault Types:** This includes violation of specifications or standards, errors in requirements and/or design, insufficient maintainability, wrong interface specifications, and evidence of project plan violation.
- **Basic Idea:** **Prevention**.
- **Core Advantage:** Detect faults and discrepancies as early as possible, because **the earlier bugs are found, the less the effort to fix them**.
- **Result Use:** Observations are used to improve the development process.

### 3. Implementation: Manual vs. Automated

|Method|Reviews|Static Analysis|
|:--|:--|:--|
|**Type**|**Manual** examination by one or several persons|**Automated** testing against given rules by tools|
|**Capabilities**|Uses analysis and reasoning capabilities to check and rate complex issues.|Tool supported.|
|**Applicability**|Can be used for **all types of documents** (e.g., contract, requirements specification, architecture description, source code, test specification).|Only possible for **formal documents** (e.g., source code or UML diagrams).|

---

## II. Reviews

Reviews are the broad term for static inspection procedures that are **performed by humans**. Reviews are often the only possibility to check the **semantics** of a document.

### 1. The Five Basic Steps of the Review Process

1. **Planning:** Define the scope, estimate effort and timeframe, identify review characteristics, select participants and allocate roles, and define entry and exit criteria for more formal review types.
2. **Initiate Review:** Distribute the work product and other material (e.g., issue log forms, checklists, related work products), and explain the scope, objectives, process, and roles to the participants. The review team needs additional data, such as guidelines or standards, to determine if a deviation or fault is present.
3. **Individual Review:** Every person on the team prepares individually for the session. Reviewers examine the document closely, potentially using checklists or selecting additional documents to restrict the review to certain aspects.
4. **Issue Communication and Analysis:** Potential defects are communicated (e.g., in a review session), analyzed, and assigned ownership/status. Review findings are evaluated against the exit criteria.
    - **Review Sessions:** Are guided by a **moderator**. Sessions are often fixed for a certain timespan (maximum 2 hours). The goal is the assessment of the review object with respect to compliance and standards. The **review team gives a recommendation** (Accept, Accept with changes, or Reject—requiring another review). Findings can be weighted (e.g., Critical fault, Main fault, Side fault).
5. **Fixing and Reporting:** Create defect reports, fix defects (typically by the author), record the updated status of defects (in formal reviews), gather metrics (for formal reviews), and accept the work product once exit criteria are met.

### 2. Individual Review Techniques

Reviewers use these techniques during the preparation phase:

- **Ad-hoc Review:** Little or no guidance, high dependence on reviewer’s skill, may lead to many duplicate reports.
- **Checklist-based Review:** A systematic technique where issues are detected based on checklists derived from experiences and potential defects. Checklists should be regularly maintained.
- **Scenario-based Reviews:** Reviewers assess the work product based on scenarios (e.g., expected usage) and perform "dry runs".
- **Role-based Reviews:** Evaluate the work product from the perspective of individual stakeholder roles (e.g., specific end user types, administrators, or testers).
- **Perspective-based Reading (PBR):** The **most effective general technique for reviewing requirements and technical work products**. It is a mix of scenario-based and role-based review, where the reviewer takes on different stakeholder viewpoints (e.g., End user, Marketing, Designer, Tester).

### 3. Review Roles

Key roles are defined within the review process:

- **Management:** Responsible for planning, deciding on execution, assigning staff/budget, and monitoring cost-effectiveness.
- **Review Leader:** Takes overall responsibility, decides involvement, and organizes the time/place.
- **Moderator:** Leads the session, ensures effective running, acts as an intermediary, must be free of prejudices, and **cannot be a reviewer** or the recorder.
- **Author:** Creates the reviewed document and fixes the defects found.
- **Reviewer (Inspector):** Identifies potential defects, representing different perspectives (e.g., tester, user, business analyst).
- **Recorder:** Documents all results, problems, open points, and decisions.

### 4. Types of Reviews (by Formalization)

Reviews range from informal to very formal, depending on factors like development process maturity or legal requirements.

![[Pasted image 20251205034346.png]]

1. **Informal Review:** Low formalization; main purpose is detecting potential defects; commonly used in agile development.
2. **Walkthrough:** A manual, informal method where the **author presents the document** to the reviewers in a meeting. The author often acts as the moderator. Main purposes include finding defects and improving the software product.
3. **Technical Review:** Reviewers are technical peers or experts. Main purposes are to **gain consensus** and detect potential defects. Individual preparation is required, but the review meeting is optional.
4. **Inspection:** **Highest formalization**. Follows a defined process with formal documented outputs based on rules and checklists, uses clearly defined roles, and specifies entry and exit criteria. **Metrics are collected** and used to improve the entire software development process.

### 5. Benefits of Reviews

Reviews can save real money:

- **Cost Efficiency:** Reviews cost about 10%–15% of the overall budget but can save between 14% and 25% (even with review costs included). Failure-costs can be reduced by up to 75%.
- **Defect Detection:** If consistently used, about **70% of document faults can be revealed**.
- **Other Advantages:** Shortened development time, reduced effort for dynamic testing, and knowledge transfer is facilitated as reviews are performed in teams.

---

## III. Metrics

Software measurement quantifies and measures software processes and product features and their relationships.

### 1. Purposes of Measurement

Measurements support three assignments:

1. **Understand:** By exposing and quantifying features.
2. **Control:** Analyzing previous experiences and adjusting future projects accordingly.
3. **Improve:** Coherence between processes and achieved goals manifest as principles for future project planning.

### 2. Types of Software Metrics

Metrics are measurements of certain features of software products, projects, and processes, used to assess, plan, and monitor.

- **Product Measures:** Focus on system characteristics (e.g., Size, Complexity, Reliability, Maintainability).
- **Project Measures:** Focus on resources (e.g., Number of developers, Price, Speed).
- **Process Measures:** Focus on development and maintenance (e.g., Duration, Effort, Cost, Failure reports, Number of releases).
- **Static Measures:** Measure a feature at a certain point in time.
- **Dynamic Measures:** Measure the development of a feature over time.

### 3. Example Metrics for Object-Oriented Programming (OOP)

|Abbreviation|Label|Description|
|:--|:--|:--|
|**NOV**|Number of Variables|Number of member variables of a class|
|**NOM**|Number of Methods|Number of methods / operations of a class|
|**WMC**|Weighted Method Complexity|Complexity of methods of a class (WMC = $\Sigma$C(i))|
|**NOC**|Number of Children|Number of direct sub-classes|
|**DIT**|Depth of Inheritance Tree|Maximum depth of generalization hierarchy|
|**LCOM**|Lack of Cohesion of Methods|Number of shared instance variables between methods of the class|
