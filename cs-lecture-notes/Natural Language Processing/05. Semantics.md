We learned from the part 1 that there are multiple NLP tasks. Most of them require the machine to understand the meaning of the sentence and generate corresponding answers. We learned Word2Vec to generate words from part 3. So, today we are going to dive into the study of meaning.

## Foundations & Motivation

**Semantics** is defined as the **Study of meaning**. It is distinct from **Morphology** (how words are built) and **Syntax** (how words form larger units like phrases/sentences).

The field is generally divided into two core branches:

1. **Lexical Semantics**: The study of **word meaning**.
2. **Compositional Semantics**: The study of the **meaning of sentences**.

## Lexical Semantics (Word Meaning)

Lexical semantics (5.1) studies the meaning of words.

### A. Core Concepts

- **Lexeme**: The **abstract representation** of a word (e.g., MOUSE, mice).
- **Sense**: A **discrete representation** of one aspect of the meaning. The meaning of a word can vary based on the given context (e.g., MOUSE as an animal versus a hand-operated device).

### B. Word Relations (5.1.1)

1. **Synonyms & Antonyms**:
    - **Synonyms**: Two words with (nearly) **identical senses** (e.g., couch/sofa). The **Principle of contrast** suggests that different linguistic forms are always associated with a difference in meaning (e.g., "H2O" is more scientific than "water").
    - **Antonyms**: Words with opposing meaning, mostly adjectives (e.g., Long/short, Rise/fall).
2. **Taxonomic Relations**:
    - **Hyponym**: A word that is **more specific** (e.g., Car is a hyponym of vehicle).
    - **Hypernym/Superordinate**: A word that is **less specific** (e.g., Vehicle is a hypernym of car).
	    ![[Pasted image 20251126025836.png]]
    - **Meronym**: Represents **part-whole relations** (e.g., Wheel is a meronym of car).
    - **The Basic Level**: Items are "human-sized," have distinctive actions, are learned earliest in childhood, and their names are shortest and most frequent (e.g., "chair" vs. its hypernym "furniture").
3. **Similarity & Relatedness**:
    - **Word similarity** refers to words with different but similar meanings (e.g., Dog and cat). **Word embeddings** can represent these relationships (e.g., Male-Female, Country-Capital).
    - **Word relatedness** refers to words belonging to the same **semantic field** (e.g., Waiter, Menu, Chef belong to the "restaurants" field).
4. **Homonymy**: Words that share a form but have **unrelated, distinct meanings** (e.g., bank1: financial institution; bank2: sloping land).
    - **Homographs**: Same spelling, different meanings (e.g., bank/bank).
    - **Homophones**: Same pronunciation, different meanings (e.g., write/right).

### C. Connotation / Affective Meaning (5.1.2)

Affective meaning involves aspects of a word related to emotion.

- **Valence**: Pleasantness of the stimulus (e.g., Happy/satisfied vs. unhappy/annoyed).
- **Arousal**: Intensity of emotion (e.g., Excited vs. calm).
- **Dominance**: Degree of control (e.g., Controlling vs. influenced).

### D. Lexical Resource: WordNet (5.1.3)

- **Description**: A **hierarchically organized lexical database** that acts as an on-line thesaurus and dictionary.
- **Definition of Sense**: Defined by a **Synset (synonym set)**, which is a set of near-synonyms that instantiates a sense or concept, with an accompanying gloss.
	![[Pasted image 20251126025850.png]]
- **Structure**: WordNet can be viewed as a graph where nodes are synsets and edges represent various relationships, such as "is-a" (hypernym/hyponym).
- **Supersenses**: Top-level hypernyms in the hierarchy (e.g., Noun supersenses include GROUP, PERSON, ARTIFACT).
- **Challenges**: Resolving **Ambiguity** (one form, multiple meanings $\rightarrow$ split form) and **Variability** (multiple forms, one meaning $\rightarrow$ merge forms).

## Compositional Semantics (Sentence Meaning)

Compositional semantics (5.2) studies the meaning of sentences. The central challenge is the **infinite number of sentences**.

### A. The Compositionality Principle

- **Frege's Principle of compositionality**: The meaning of an expression depends on **the meaning of its parts** and **how they are put together**.

### B. Formal Meaning Representation (5.2.1)

This involves structuring meaning using symbols, bridging the gap between language and common-sense knowledge.

- **Vocabulary**: Includes **Non-logical** (open-ended terms linked to a world model) and **Logical** (closed set of symbols, operators, quantifiers) elements.
- **Examples of Representations**: First-order logic, Abstract Meaning Representation (AMR), and Frame-based/slot-filling representation.
- **Requirements**:
    - **Verifiability**: Ability to compare the represented state to the state of the world (e.g., checking Serves(Maharani, VegetarianFood) against a knowledge base).
    - **Unambiguous representations**: The representation itself must be clear, even if the natural language sentence is vague.
    - **Canonical Form**: Distinct inputs with the same meaning must yield the same representation.
    - **Inference and Variables**: Variables are needed to make general statements, and the system must use world knowledge to draw conclusions.
    - **Expressiveness**: Must handle a wide range of expressions.

### C. First-order Logic (5.2.2)

This is a **flexible and well-understood** meaning representation. It uses **Terms** (objects), **Functions** (e.g., LocationOf(Frasca)), and **Variables** to make general statements.

### D. Shallow Semantics & Semantic Roles (5.2.3)

Shallow semantics aims to represent the **commonality** of an event despite its linguistic variability (e.g., different ways to describe a stock purchase).

- **Thematic Roles**: Identify common roles like **AGENT** (often the subject) and **THEME**.
- **Challenges**: **Fragmentations** (e.g., multiple types of INSTRUMENTS) and difficulty in defining roles (e.g., whether an Agent must be animate).
- **Alternatives**: Use broader roles like **PROTO-AGENT** (Agent-like properties) and **PROTO-PATIENT** (Patient-like properties).

### E. Semantic Role Resources

1. **PropBank (Proposition Bank) (5.2.4)**:
    - A dataset based on Penn TreeBank annotation, focusing primarily on **verbs**.
    - Uses numbered roles (Arg0, Arg1, etc.) specific to each verb sense. **Arg0** typically represents the PROTO-AGENT, and **Arg1** the PROTO-PATIENT.
    - **ArgMs** represent modifications like time (TMP), location (LOC), or reason (PRP/CAU).
2. **FrameNet (5.2.5)**:
    - Motivated by the need for **inference about situations** described by different verbs (e.g., _increased_ vs. _rose_).
    - Defines **Frames** as background knowledge structures containing common-sense information about a situation (e.g., _Change_position_on_a_scale_).
    - Uses **Core roles** that are specific to the frame, and **Non-core roles** (general properties) comparable to PropBank's Arg_M.

## Semantic Reasoning & Application

Reasoning (5.3) takes **Facts** and **Logic** as input to generate an **Answer**.

### A. Types of Reasoning (5.3.1)

- **Deductive Reasoning**: Moves from premise(s) to a **Firm conclusion** using logic (e.g., All whales are mammals $\rightarrow$ All whales have kidneys). ==(general -> special)==
- **Inductive Reasoning**: Moves from observation to a **Likely conclusion** (e.g., winged creatures are usually birds $\rightarrow$ this winged creature is likely a bird). ==(special -> general)==
- **Abductive Reasoning**: Moves from observation to a **Likely explanation**.
- **Formal Reasoning**: Follows formal rules/logic and is based on axiomatic knowledge.
- **Informal Reasoning**: Uses intuition, experience, and common sense.

### B. Natural Language Inference (NLI) (5.3.2)

- **Goal**: An **applied semantic inference** task aimed at identifying the **logical relationship** between a pair of text sequences (a **Premise** and a **Hypothesis**).
- **Also called**: **Textual Entailment**.
- **Labels**:
    - **Entailment**: Hypothesis is true.
    - **Contradiction**: Hypothesis is false.
    - **Neutral (Undetermined)**: Hypothesis is undetermined.